Spark/DataBricks Resources
Installing spark locally:
On Mac: http://genomegeek.blogspot.com/2014/11/how-to-install-apache-spark-on-mac-os-x.html

Configuring ipython notebook to work with pyspark:
http://ramhiser.com/2015/02/01/configuring-ipython-notebook-support-for-pyspark/

Simple examples:
http://spark.apache.org/examples.html

http://spark.apache.org/docs/latest/ml-features.html#pca

http://spark.apache.org/docs/latest/ml-ensembles.html#gradient-boosted-trees-gbts

https://en.wikipedia.org/wiki/Gradient_boosting

Inside the installation for Spark 1.6.0, under directory main, there are subdirectories for all of the languages (but not for notebook files).

Can be gotten from here:
https://github.com/apache/spark/tree/master/examples/src/main/python

spark.mllib contains the original API built on top of RDDs.
spark.ml provides higher-level API built on top of DataFrames for constructing ML pipelines.


Sentiment analysis:
http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/

Installing pyspark and notebooks:
http://blog.cloudera.com/blog/2014/08/how-to-use-ipython-notebook-with-apache-spark/

Code examples from “Learning Spark”:
https://github.com/databricks/learning-spark

Code examples for “Advanced analytics with spark” (Scala only)
https://github.com/sryza/aas

In DataBrick - workspace / Databricks Guide / MLLib / …  ( some python and some scala)


Spark Programming Guide: 
http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html#principal-component-analysis-pca
