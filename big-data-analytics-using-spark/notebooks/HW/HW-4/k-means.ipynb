{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means++\n",
    "\n",
    "In this notebook, we are going to implement [k-means++](https://en.wikipedia.org/wiki/K-means%2B%2B) algorithm with multiple initial sets. The original k-means++ algorithm will just sample one set of initial centroid points and iterate until the result converges. The only difference in this implementation is that we will sample `RUNS` sets of initial centroid points and update them in parallel. The procedure will finish when all centroid sets are converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Definition of some global parameters.\n",
    "K = 5  # Number of centroids\n",
    "RUNS = 25  # Number of K-means runs that are executed in parallel. Equivalently, number of sets of initial points\n",
    "RANDOM_SEED = 60295531\n",
    "converge_dist = 0.1 # The K-means algorithm is terminated when the change in the location \n",
    "                    # of the centroids is smaller than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from numpy.linalg import norm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def print_log(s):\n",
    "    sys.stdout.write(s + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def parse_data(row):\n",
    "    '''\n",
    "    Parse each pandas row into a tuple of (station_name, feature_vec),\n",
    "    where feature_vec is the concatenation of the projection vectors\n",
    "    of TAVG, TRANGE, and SNWD.\n",
    "    '''\n",
    "    return (row[0],\n",
    "            np.concatenate([row[1], row[2], row[3]]))\n",
    "\n",
    "\n",
    "def compute_entropy(d):\n",
    "    '''\n",
    "    Compute the entropy given the frequency vector `d`\n",
    "    '''\n",
    "    d = np.array(d)\n",
    "    d = 1.0 * d / d.sum()\n",
    "    return -np.sum(d * np.log2(d))\n",
    "\n",
    "\n",
    "def choice(p):\n",
    "    '''\n",
    "    Generates a random sample from [0, len(p)),\n",
    "    where p[i] is the probability associated with i. \n",
    "    '''\n",
    "    random = np.random.random()\n",
    "    r = 0.0\n",
    "    for idx in range(len(p)):\n",
    "        r = r + p[idx]\n",
    "        if r > random:\n",
    "            return idx\n",
    "    assert(False)\n",
    "\n",
    "\n",
    "def kmeans_init(rdd, K, RUNS, seed):\n",
    "    '''\n",
    "    Select `RUNS` sets of initial points for `K`-means++\n",
    "    '''\n",
    "    # the `centers` variable is what we want to return\n",
    "    n_data = rdd.count()\n",
    "    shape = rdd.take(1)[0][1].shape[0]\n",
    "    centers = np.zeros((RUNS, K, shape))\n",
    "\n",
    "    def update_dist(vec, dist, k):\n",
    "        new_dist = norm(vec - centers[:, k], axis=1)**2\n",
    "        return np.min([dist, new_dist], axis=0)\n",
    "\n",
    "\n",
    "    # The second element `dist` in the tuple below is the closest distance from\n",
    "    # each data point to the selected points in the initial set, where `dist[i]`\n",
    "    # is the closest distance to the points in the i-th initial set. Intitially,\n",
    "    # it is initialized to infinity.\n",
    "    data = rdd.map(lambda p: (p, [np.inf] * RUNS)) \\\n",
    "              .cache()\n",
    "\n",
    "    # Collect the feature vectors of all data points beforehand, might be\n",
    "    # useful in the following for-loop\n",
    "    local_data = rdd.map(lambda (name, vec): vec).collect()\n",
    "\n",
    "    # Randomly select the first point for every run of k-means++,\n",
    "    # i.e. randomly select `RUNS` points and add it to the `centers` variable\n",
    "    sample = [local_data[k] for k in np.random.randint(0, len(local_data), RUNS)]\n",
    "    centers[:, 0] = sample\n",
    "\n",
    "    for idx in range(K - 1):\n",
    "        ##############################################################################\n",
    "        # Insert your code here:\n",
    "        ##############################################################################\n",
    "        # In each iteration, you need to select one point for each set\n",
    "        # of initial points (so select `RUNS` points in total).\n",
    "        # For each data point x, let D_i(x) be the distance between x and\n",
    "        # the nearest center that has already been added to the i-th set.\n",
    "        # Choose a new data point for i-th set using a weighted probability\n",
    "        # where point x is chosen with probability proportional to D_i(x)^2\n",
    "        ##############################################################################\n",
    "        pass\n",
    "\n",
    "    return centers\n",
    "\n",
    "\n",
    "def get_closest(p, centers):\n",
    "    '''\n",
    "    Return the indices of the nearest centroids of `p`.\n",
    "    \n",
    "    `centers` contains sets of centroids, where `centers[i]` is\n",
    "    the i-th set of centroids.\n",
    "    '''\n",
    "    best = [0] * len(centers)\n",
    "    closest = [np.inf] * len(centers)\n",
    "    for idx in range(len(centers)):\n",
    "        for j in range(len(centers[0])):\n",
    "            temp_dist = norm(p - centers[idx][j])\n",
    "            if temp_dist < closest[idx]:\n",
    "                closest[idx] = temp_dist\n",
    "                best[idx] = j\n",
    "    return best\n",
    "\n",
    "\n",
    "def kmeans(rdd, K, RUNS, converge_dist, seed):\n",
    "    '''\n",
    "    Run K-means++ algorithm on `rdd`, where `RUNS` is the number of\n",
    "    initial sets to use.\n",
    "    '''\n",
    "    k_points = kmeans_init(rdd, K, RUNS, seed)\n",
    "    print_log(\"Initialized.\")\n",
    "    temp_dist = 1.0\n",
    "\n",
    "    iters = 0\n",
    "    st = time.time()\n",
    "    while temp_dist > converge_dist:\n",
    "        ##############################################################################\n",
    "        # INSERT YOUR CODE HERE\n",
    "        ##############################################################################\n",
    "        \n",
    "        # Update all `RUNS` sets of centroids using standard k-means algorithm\n",
    "        # Outline:\n",
    "        #   - For each point x, select its nearest centroid in i-th centroids set\n",
    "        #   - Average all points that are assigned to the same centroid\n",
    "        #   - Update the centroid with the average of all points that are assigned to it\n",
    "        \n",
    "        # Insert your code here\n",
    "\n",
    "        # You can modify this statement as long as `temp_dist` equals to\n",
    "        # max( sum(l2_norm of the movement of j-th centroid) in each centroids set)\n",
    "        ##############################################################################\n",
    "\n",
    "        temp_dist = np.max([\n",
    "                np.sum([norm(k_points[idx][j] - new_points[(idx, j)]) for j in range(K)])\n",
    "                    for idx in range(RUNS)])\n",
    "\n",
    "        iters = iters + 1\n",
    "        if iters % 5 == 0:\n",
    "            print_log(\"Iteration %d max shift: %.2f (time: %.2f)\" %\n",
    "                      (iters, temp_dist, time.time() - st))\n",
    "            st = time.time()\n",
    "\n",
    "        # update old centroids\n",
    "        # You modify this for-loop to meet your need\n",
    "        for ((idx, j), p) in new_points.items():\n",
    "            k_points[idx][j] = p\n",
    "\n",
    "    return k_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'USC00044534', array([  3.04796236e+03,   1.97434852e+03,   1.50560792e+02,\n",
       "          -2.90363288e+03,  -2.36907268e+02,   1.47021791e+02,\n",
       "           1.91503001e-01,   1.87262808e-01,  -4.01379553e-02]))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data\n",
    "data = pickle.load(open(\"../Data/Weather/stations_projections.pickle\", \"rb\"))\n",
    "rdd = sc.parallelize([parse_data(row[1]) for row in data.iterrows()])\n",
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized.\n",
      "Iteration 5 max shift: 3211.03 (time: 14.80)\n",
      "Iteration 10 max shift: 1928.05 (time: 14.75)\n",
      "Iteration 15 max shift: 693.41 (time: 14.86)\n",
      "Iteration 20 max shift: 348.29 (time: 15.00)\n",
      "Iteration 25 max shift: 235.29 (time: 15.28)\n",
      "Iteration 30 max shift: 185.35 (time: 14.78)\n",
      "Iteration 35 max shift: 51.71 (time: 15.10)\n",
      "Iteration 40 max shift: 45.07 (time: 14.90)\n",
      "Iteration 45 max shift: 26.03 (time: 14.80)\n",
      "Iteration 50 max shift: 15.59 (time: 14.87)\n",
      "Iteration 55 max shift: 0.85 (time: 14.97)\n",
      "Time takes to converge: 171.567047119\n"
     ]
    }
   ],
   "source": [
    "# main code\n",
    "\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "centroids = kmeans(rdd, K, RUNS, converge_dist, np.random.randint(1000))\n",
    "group = rdd.mapValues(lambda p: get_closest(p, centroids)) \\\n",
    "           .collect()\n",
    "\n",
    "print \"Time takes to converge:\", time.time() - st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify your results\n",
    "Verify your results by computing the objective function of the k-means clustering problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cost(rdd, centers):\n",
    "    '''\n",
    "    Compute the square of l2 norm from each data point in `rdd`\n",
    "    to the centroids in `centers`\n",
    "    '''\n",
    "    def _get_cost(p, centers):\n",
    "        best = [0] * len(centers)\n",
    "        closest = [np.inf] * len(centers)\n",
    "        for idx in range(len(centers)):\n",
    "            for j in range(len(centers[0])):\n",
    "                temp_dist = norm(p - centers[idx][j])\n",
    "                if temp_dist < closest[idx]:\n",
    "                    closest[idx] = temp_dist\n",
    "                    best[idx] = j\n",
    "        return np.array(closest)**2\n",
    "    \n",
    "    cost = rdd.map(lambda (name, v): _get_cost(v, centroids)).collect()\n",
    "    return np.array(cost).sum(axis=0)\n",
    "\n",
    "cost = get_cost(rdd, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.825490212333918, 33.757533252505837, 33.779023610859163)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2 = np.log2\n",
    "\n",
    "log2(np.max(cost)), log2(np.min(cost)), log2(np.mean(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the increase of entropy after multiple runs of k-means++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Remove this cell before submitting to PyBolt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8799771938634473"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc700c55cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "entropy = []\n",
    "\n",
    "for i in range(RUNS):\n",
    "    count = {}\n",
    "    for g, sig in group:\n",
    "        _s = ','.join(map(str, sig[:(i + 1)]))\n",
    "        count[_s] = count.get(_s, 0) + 1\n",
    "    entropy.append(compute_entropy(count.values()))\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.plot(range(1, RUNS + 1), entropy)\n",
    "2**entropy[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 2952.76608   ,  1933.02980077,    92.424188  , -2547.74851278,\n",
      "         144.84123959,   154.0172669 ,    18.40817384,     7.84926361,\n",
      "           5.11113863]), array([  428.4738994 ,  1807.58033164,    35.14799298, -2574.43476306,\n",
      "        -180.39839191,   263.09089521,  6048.90511888,  -743.20856056,\n",
      "         256.68319372]), array([ 1492.0570036 ,  1954.30230067,    94.48584365, -2567.99675086,\n",
      "        -112.2682711 ,   152.28015089,   395.84574671,   131.09390181,\n",
      "          73.10315542]), array([  750.10763916,  2067.97627806,    35.34601332, -2398.58742321,\n",
      "        -138.36631381,   233.32209536,  2268.85311051,   245.99611499,\n",
      "         125.46432194]), array([   408.29696084,   1353.92836359,     56.37619358,  -2206.17029272,\n",
      "         -221.37785013,    183.25193705,  18757.57406286,  -5513.4828535 ,\n",
      "         1476.58182765])]\n"
     ]
    }
   ],
   "source": [
    "print 'entropy=',entropy\n",
    "best = np.argmin(cost)\n",
    "print 'best_centers=',list(centroids[best])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
