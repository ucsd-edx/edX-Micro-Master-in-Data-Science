{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "256be925e1ac2c20b5ab673064b06652",
     "grade": false,
     "grade_id": "r1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Setup Notebook for Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d72124b8b8b7912fc81741aac8df6a1",
     "grade": false,
     "grade_id": "r2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "##### <span style=\"color:red\">IMPORTANT: Only modify cells which have the following comment:</span>\n",
    "```python\n",
    "# Modify this cell\n",
    "```\n",
    "##### <span style=\"color:red\">Do not add any new cells when you submit the homework</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "df20595a79a3974e238ddaa7cb4d5f3c",
     "grade": false,
     "grade_id": "r3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7ca7393082f42efd9e2175acff15b3ba",
     "grade": false,
     "grade_id": "r4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext(master=\"local[4]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6038be84bab50376d26837c931521955",
     "grade": false,
     "grade_id": "r5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "pickleFile=\"Tester/SparkBasics1.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "220968c71bd17202be296e3eb0d9f6f8",
     "grade": false,
     "grade_id": "r6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Importing all packages necessary to complete the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8add22aecc9b4d22dfd7a6b009cc5ab5",
     "grade": false,
     "grade_id": "r7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f65ce84ea6762f8e645dd37c17485884",
     "grade": false,
     "grade_id": "Excercise1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "Write a function called **mapcos** that has a single paramater: an RDD of numbers. Use **map** to return an RRD that is the `cos()` (cosine) of the input.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "A=sc.parallelize( range(3) )\n",
    "print mapcos(A)\n",
    "print mapcos(A).collect()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "[1.0, 0.54030..., -0.41614...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def mapcos(A):\n",
    "    # Write code that will perform the task outlined in exercise 1\n",
    "    return \"returns a spark RDD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f3423b57b423cd352c053dc8cb6b3a6",
     "grade": true,
     "grade_id": "ex_1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0, 1, 2]\n",
      "Correct Output: [1.0, 0.54030230586813977, -0.41614683654714241]\n",
      "\n",
      "Error: Function returned incorrect output\n",
      "Your Output:  [0.0, 0.8414709848078965, 0.90929742682568171]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Your Answer is Incorrect",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-87609e7ced50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkBasics1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexercise1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapcos\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/SparkBasics1.pyc\u001b[0m in \u001b[0;36mexercise1_1\u001b[0;34m(pickleFile, func_student, sc)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexercise1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestRDD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexercise1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestRDDStr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.pyc\u001b[0m in \u001b[0;36mcheckExerciseFromPickle\u001b[0;34m(pickleFile, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mcheckExercise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexerciseNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.pyc\u001b[0m in \u001b[0;36mcheckExercise\u001b[0;34m(inputs, outputs, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mnoError\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorAns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnoError\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your Answer is Incorrect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Your Answer is Incorrect"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_1(pickleFile, mapcos ,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "462802cefbb3134799228e9a14a92772",
     "grade": false,
     "grade_id": "r8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Write a function called **mapwords** that has a single paramater: an RDD of strings, and returns an RDD that contains a list of words for each string.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "stringRDD=sc.parallelize([\"Spring quarter\", \"Learning spark basics\", \"Big data analytics with Spark\"])\n",
    "print mapwords(stringRDD).collect()\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "[['Spring', 'quarter'], ['Learning', 'spark', 'basics'], ['Big', 'data', 'analytics', 'with', 'Spark']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def mapwords(stringRDD):\n",
    "    # Write code that will perform the task outlined in exercise 2\n",
    "    return \"return spark RDD, so to get a list run: mapwords(stringRDD).collect() \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "94a53e5ae76eda480faaad6ba357a255",
     "grade": true,
     "grade_id": "ex_2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_2(pickleFile, mapwords, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c6e0dfc6ef9f72c5738386464f5a938d",
     "grade": false,
     "grade_id": "r9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "Write a function **getMax** that uses **reduce** to find the maximum number from a list of numbers. \n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "RDD=sc.parallelize([0,2,1])\n",
    "print getMax(RDD)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def getMax(C):\n",
    "    # Write the code that will perform the task outlined in exercise 3\n",
    "    return \"return spark NUMBER here, example, to get a number run mapwords(C)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "527ebe2d4d242bb8708ee9eadd7847f0",
     "grade": true,
     "grade_id": "ex_3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_3(pickleFile, getMax, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f8fdf7150154f9b563bfa4556f48e14",
     "grade": false,
     "grade_id": "r10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 4\n",
    "\n",
    "Write a function called **reducewords** that uses **reduce** to create a single string which is the concatenation of all the strings in stringRDD(with a space between each string). Example:\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "stringRDD=sc.parallelize([\"Spring quarter\", \"Learning spark basics\", \"Big data analytics with Spark\"])\n",
    "print reducewords(stringRDD)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "'Spring quarter Learning spark basics Big data analytics with Spark'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def reducewords(stringRDD):\n",
    "    return \"return concatenation of all strings using spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5040444c2e6480830adb7e459bb9db0a",
     "grade": true,
     "grade_id": "ex_4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_4(pickleFile, reducewords, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da12ed801c802a0d343f89edc233fc03",
     "grade": false,
     "grade_id": "r11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 5\n",
    "\n",
    "Write a non-Spark function **maxFunc** that when called by the **reduce** command outputs the maximum element from a set of lists.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "listRDD=sc.parallelize([[3,4],[2,1],[7,9]])\n",
    "print listRDD.reduce(maxFunc)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    " [9]\n",
    "\n",
    "     Note: The output is a list containing a single number rather than just a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def maxFunc(x,y):\n",
    "    # x,y are lists of numbers\n",
    "    # write code here for exercise 5\n",
    "    \n",
    "    return \"returns a list to be used possibly again by the reduce command\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3578507332d264c0043cdff5473a744c",
     "grade": true,
     "grade_id": "ex_5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_5(pickleFile, maxFunc, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54aeb98a1c64f24ebde33767001721da",
     "grade": false,
     "grade_id": "r12",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
