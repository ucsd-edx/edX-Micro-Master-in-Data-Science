{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "256be925e1ac2c20b5ab673064b06652",
     "grade": false,
     "grade_id": "r1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    }
   },
   "source": [
    "# Setup Notebook for Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d72124b8b8b7912fc81741aac8df6a1",
     "grade": false,
     "grade_id": "r2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    }
   },
   "source": [
    "##### <span style=\"color:red\">IMPORTANT: Only modify cells which have the following comment:</span>\n",
    "```python\n",
    "# Modify this cell\n",
    "```\n",
    "##### <span style=\"color:red\">Do not add any new cells when you submit the homework</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "df20595a79a3974e238ddaa7cb4d5f3c",
     "grade": false,
     "grade_id": "r3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7ca7393082f42efd9e2175acff15b3ba",
     "grade": false,
     "grade_id": "r4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext(master=\"local[4]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6038be84bab50376d26837c931521955",
     "grade": false,
     "grade_id": "r5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "pickleFile=\"Tester/SparkBasics1.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "220968c71bd17202be296e3eb0d9f6f8",
     "grade": false,
     "grade_id": "r6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    }
   },
   "source": [
    "Importing all packages necessary to complete the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8add22aecc9b4d22dfd7a6b009cc5ab5",
     "grade": false,
     "grade_id": "r7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f65ce84ea6762f8e645dd37c17485884",
     "grade": false,
     "grade_id": "Excercise1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "Write a function called **mapcos** that has a single paramater: an RDD of numbers. Use **map** to return an RRD that is the `cos()` (cosine) of the input.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "A=sc.parallelize( range(3) )\n",
    "print mapcos(A)\n",
    "print mapcos(A).collect()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "[1.0, 0.54030..., -0.41614...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "from math import cos\n",
    "def mapcos(A):\n",
    "    \n",
    "    return A.map(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f3423b57b423cd352c053dc8cb6b3a6",
     "grade": true,
     "grade_id": "ex_1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0, 1, 2]\n",
      "Correct Output: [1.0, 0.54030230586813977, -0.41614683654714241]\n",
      "Great Job!\n",
      "\n",
      "Input: [4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Correct Output: [-0.65364362086361194, 0.28366218546322625, 0.96017028665036597, 0.7539022543433046, -0.14550003380861354, -0.91113026188467694, -0.83907152907645244, 0.0044256979880507854]\n",
      "Great Job!\n",
      "\n",
      "Input: [-4, -3, -2, -1]\n",
      "Correct Output: [-0.65364362086361194, -0.98999249660044542, -0.41614683654714241, 0.54030230586813977]\n",
      "Great Job!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_1(pickleFile, mapcos ,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "462802cefbb3134799228e9a14a92772",
     "grade": false,
     "grade_id": "r8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Write a function called **mapwords** that has a single paramater: an RDD of strings, and returns an RDD that contains a list of words for each string.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "stringRDD=sc.parallelize([\"Spring quarter\", \"Learning spark basics\", \"Big data analytics with Spark\"])\n",
    "print mapwords(stringRDD).collect()\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "[['Spring', 'quarter'], ['Learning', 'spark', 'basics'], ['Big', 'data', 'analytics', 'with', 'Spark']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def mapwords(stringRDD):\n",
    "    # Write code that will perform the task outlined in exercise 2\n",
    "    return \"return spark RDD, so to get a list run: mapwords(stringRDD).collect() \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Tester/SparkBasics1.py\n",
    "from Tester import *\n",
    "\n",
    "def exercise1_1(pickleFile, func_student, sc):\n",
    "    checkExerciseFromPickle(pickleFile, func_student,TestRDD,'ex1_1',sc)\n",
    "def exercise1_2(pickleFile, func_student, sc):\n",
    "    checkExerciseFromPickle(pickleFile, func_student,TestRDDStr,'ex1_2',sc)\n",
    "def exercise1_3(pickleFile, func_student, sc):\n",
    "    checkExerciseFromPickle(pickleFile, func_student,TestNumber,'ex1_3',sc)\n",
    "def exercise1_4(pickleFile, func_student, sc):\n",
    "    checkExerciseFromPickle(pickleFile, func_student,TestListStr,'ex1_4',sc)\n",
    "def exercise1_5(pickleFile, func_student, sc):  \n",
    "    checkExerciseFromPickle(pickleFile, lambda x: x.reduce(func_student),TestList,'ex1_5',sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load Tester/Tester.py\n",
    "import pickle\n",
    "\n",
    "\n",
    "def GenPickle(sc, func_teacher, inputs, filename, ex, isRDD=True,twoInputs=False ):\n",
    "    try:\n",
    "        f = open(filename,'r')\n",
    "        toPickle = pickle.load(f)\n",
    "        f.close()\n",
    "    except:\n",
    "        toPickle = {}\n",
    "    \n",
    "    exData = []\n",
    "    for input in inputs:\n",
    "        if twoInputs:\n",
    "            tmpAns = func_teacher(sc.parallelize(input[0]),sc.parallelize(input[1]))\n",
    "        else:\n",
    "            i = sc.parallelize(input)\n",
    "            tmpAns = func_teacher(i)\n",
    "        if isRDD:\n",
    "            exData.append([ tmpAns.collect()  , \n",
    "                      type(tmpAns) ]) \n",
    "        else:\n",
    "            exData.append([ tmpAns, \n",
    "                      type(tmpAns) ]) \n",
    "    toPickle[ex] = {'inputs': inputs, 'outputs':exData}\n",
    "    \n",
    "    f = open(filename,'w')\n",
    "    pickle.dump(toPickle,f)\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "def GenPickle_RDD(sc, func_teacher, inputRDD, filename, ex,  outRDD=True, takes=1 ):\n",
    "    try:\n",
    "        f = open(filename,'r')\n",
    "        toPickle = pickle.load(f)\n",
    "        f.close()\n",
    "    except:\n",
    "        toPickle = {}    \n",
    "    \n",
    "    exData = []\n",
    "    tmpAns = func_teacher(inputRDD)\n",
    "    if outRDD:\n",
    "        exData.append([  tmpAns.take(takes),type(tmpAns)  ]) \n",
    "    else:\n",
    "        exData.append([   tmpAns,type(tmpAns)   ]) \n",
    "        \n",
    "    toPickle[ex] = {'inputs':type(inputRDD), 'outputs':exData}\n",
    "    \n",
    "    f = open(filename,'w')\n",
    "    pickle.dump(toPickle,f)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "#      ***   WE MUST CHANGE VERY_CLOSE FUNCTION   ***\n",
    "def very_close(A,B,tol=0.000001):\n",
    "    ''' Check that the two firs parameters are lists of equal length \n",
    "    and then check'''\n",
    "    if (not type(A)==list and type(B) ==list) or len(A)!=len(B):\n",
    "        return False\n",
    "    for i in range(len(A)):\n",
    "        a=A[i]; b=B[i]\n",
    "        if abs(a-b)>tol:\n",
    "            return False\n",
    "    return True \n",
    "\n",
    "def TestList(data, func_student, corAns, corType, isNum=True, toPrint=True):\n",
    "    studentAns = func_student(data)\n",
    "    \n",
    "    if toPrint: print \"Input: \" + str( data.collect() )\n",
    "    print \"Correct Output: \" + str(corAns)\n",
    "    \n",
    "    try: assert( type(studentAns) == corType )\n",
    "    except AssertionError as e:\n",
    "        print \"\\nError: Incorrect return type. The return type of your function should be: \" + str(corType)\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        if isNum:  assert( very_close(studentAns,corAns))\n",
    "        else:      assert(studentAns == corAns)\n",
    "    except AssertionError as e:\n",
    "        print \"\\nError: Function returned incorrect output\"\n",
    "        print \"Your Output: \", studentAns\n",
    "        return False\n",
    "    print \"Great Job!\"\n",
    "    return True\n",
    "\n",
    "def TestListStr(data, func_student, corAns, corType):\n",
    "    return TestList(data, func_student, corAns, corType, isNum=False)\n",
    "\n",
    "\n",
    "def TestNumber(data, func_student, corAns, corType, toPrint=True):\n",
    "    studentAns = func_student(data)\n",
    "    if toPrint: print \"Input: \" + str( data.collect() )\n",
    "    print \"Correct Output: \" + str(corAns)\n",
    "    \n",
    "    try: assert( type(studentAns) == corType )\n",
    "    except AssertionError as e:\n",
    "        print \"\\nError: Incorrect return type. The return type of your function should be: \"+str(corType)\n",
    "        return False\n",
    "    \n",
    "    try: assert( very_close([studentAns],[corAns]) )\n",
    "    except AssertionError as e:\n",
    "        print \"\\nError: Function returned incorrect output\"\n",
    "        print \"Your Output: \", studentAns\n",
    "        return False\n",
    "    print \"Great Job!\"\n",
    "    return True\n",
    "\n",
    "def TestRDDStr2(data, func_student, corAns, corType):\n",
    "    return TestRDD( data, func_student, corAns, corType, isNum=False,twoInputs=True)\n",
    "\n",
    "def TestRDDStr(data, func_student, corAns, corType,twoInputs=False):\n",
    "    return TestRDD( data, func_student, corAns, corType, isNum=False)\n",
    "    \n",
    "def TestRDDK(data, func_student, corAns, corType,takeK,toPrint=True):\n",
    "    return TestRDD( data, func_student, corAns, corType, isNum=False, takeK=takeK, toPrint=toPrint)\n",
    "    \n",
    "def TestRDD( data, func_student, corAns, corType, isNum=True,twoInputs=False, takeK=0, toPrint=True):\n",
    "    #if takeK == 0:\n",
    "    if twoInputs:\n",
    "        if takeK>0: AssertionError('We have not coded case for twoInputs=True, takeK>1. Please code this up!')\n",
    "        initDebugStr = data[0].toDebugString()\n",
    "        studentRDD = func_student(data[0], data[1])\n",
    "        print \"Input: \" + str(data[0].collect())\n",
    "        if toPrint: print data[1].collect()\n",
    "    else:\n",
    "        initDebugStr = data.toDebugString()\n",
    "        studentRDD = func_student(data)\n",
    "        if takeK==0: \n",
    "            if toPrint: print \"Input: \" + str(data.collect())\n",
    "        else: \n",
    "            if toPrint: print \"Input: \"+ str(type(data)) \n",
    "\n",
    "    print \"Correct Output: \" + str(corAns)\n",
    "    \n",
    "    try: assert( type(studentRDD) == corType )\n",
    "    except AssertionError as e:\n",
    "        print \"\\nError: Incorrect return type. The return type of your function should be: \" + str(corType)\n",
    "        return False\n",
    "    \n",
    "    newDebugStr  = studentRDD.toDebugString()\n",
    "    initDebugStr = ' '.join(initDebugStr.split(' ')[1:])\n",
    "\n",
    "    try: assert( initDebugStr.replace(' ','') in newDebugStr.replace(' ','') )\n",
    "    except AssertionError as e:\n",
    "        print \"\\nError: Did you use only Spark commands? Original RDD is not found in execution path.\"\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        if takeK == 0:\n",
    "            if isNum:  assert( very_close(studentRDD.collect(),corAns))\n",
    "            else:      assert(studentRDD.collect() == corAns)\n",
    "        else:\n",
    "            if isNum:  assert( very_close(studentRDD.take(takeK),corAns))\n",
    "            else:      assert(studentRDD.take(takeK) == corAns)\n",
    "    except AssertionError as e:\n",
    "        print \"\\nError: Function returned incorrect output\"\n",
    "        if takeK == 0:\n",
    "            print \"Your Output: \",studentRDD.collect()\n",
    "        else:\n",
    "            print \"Your Output: \",studentRDD.take(takeK)\n",
    "        return False\n",
    "    \n",
    "    print \"Great Job!\"\n",
    "    return True\n",
    "\n",
    "def RddReduce(func):\n",
    "    return lambda RDD: RDD.reduce(func)\n",
    "\n",
    "def getPickledData(pickleFileName):\n",
    "    f = open( pickleFileName )\n",
    "    data = pickle.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def checkExercise(inputs, outputs, func_student, TestFunction, exerciseNumber, sc, twoInputs=False):\n",
    "    for input,case in zip( inputs, outputs ):\n",
    "        if twoInputs:\n",
    "            input = [sc.parallelize(input[0]), sc.parallelize(input[1])]\n",
    "        else:\n",
    "            input = sc.parallelize(input)\n",
    "        noError= TestFunction( data=input, func_student=func_student, corAns=case[0], corType=case[1]  )\n",
    "        if noError == False: raise AssertionError('Your Answer is Incorrect') \n",
    "        print \n",
    "\n",
    "def checkExerciseFromPickle(pickleFile, func_student, TestFunction, exerciseNumber, sc, twoInputs=False):\n",
    "    data = getPickledData(pickleFile)\n",
    "    inputs = data[exerciseNumber]['inputs']\n",
    "    outputs = data[exerciseNumber]['outputs']\n",
    "    checkExercise(inputs, outputs, func_student, TestFunction, exerciseNumber, sc,twoInputs=twoInputs)\n",
    "    \n",
    "        \n",
    "def checkExerciseCorrectAns(inputs, func_teacher, func_student, TestFunction, exerciseNumber, sc,\n",
    "                            twoInputs=False,isRDD=True):\n",
    "    outputs = []\n",
    "    for input in inputs:\n",
    "        if twoInputs:\n",
    "            tmpAns = func_teacher(sc.parallelize(input[0]), sc.parallelize(input[1]))\n",
    "        else:\n",
    "            tmpAns = func_teacher(sc.parallelize(input))\n",
    "        if isRDD:\n",
    "            ty = type(tmpAns)\n",
    "            tmpAns = tmpAns.collect()\n",
    "            outputs.append([tmpAns,ty])\n",
    "        else:\n",
    "            outputs.append([tmpAns, type(tmpAns)])\n",
    "    checkExercise(inputs, outputs, func_student, TestFunction, exerciseNumber, sc,twoInputs=twoInputs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "94a53e5ae76eda480faaad6ba357a255",
     "grade": true,
     "grade_id": "ex_2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['Spring quarter', 'Learning spark basics', 'Big data analytics with Spark']\n",
      "Correct Output: [['Spring', 'quarter'], ['Learning', 'spark', 'basics'], ['Big', 'data', 'analytics', 'with', 'Spark']]\n",
      "\n",
      "Error: Incorrect return type. The return type of your function should be: <class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Your Answer is Incorrect",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9fe1ba97d5a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkBasics1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexercise1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/SparkBasics1.py\u001b[0m in \u001b[0;36mexercise1_2\u001b[0;34m(pickleFile, func_student, sc)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestRDD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexercise1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestRDDStr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexercise1_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestNumber\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.py\u001b[0m in \u001b[0;36mcheckExerciseFromPickle\u001b[0;34m(pickleFile, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mcheckExercise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexerciseNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.py\u001b[0m in \u001b[0;36mcheckExercise\u001b[0;34m(inputs, outputs, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mnoError\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorAns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnoError\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your Answer is Incorrect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Your Answer is Incorrect"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_2(pickleFile, mapwords, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c6e0dfc6ef9f72c5738386464f5a938d",
     "grade": false,
     "grade_id": "r9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "Write a function **getMax** that uses **reduce** to find the maximum number from a list of numbers. \n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "RDD=sc.parallelize([0,2,1])\n",
    "print getMax(RDD)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def getMax(C):\n",
    "    # Write the code that will perform the task outlined in exercise 3\n",
    "    return \"return spark NUMBER here, example, to get a number run mapwords(C)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "527ebe2d4d242bb8708ee9eadd7847f0",
     "grade": true,
     "grade_id": "ex_3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0, 4, 2, 3, 1]\n",
      "Correct Output: 4\n",
      "\n",
      "Error: Incorrect return type. The return type of your function should be: <type 'int'>\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Your Answer is Incorrect",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ac386427ccd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkBasics1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexercise1_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetMax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/SparkBasics1.py\u001b[0m in \u001b[0;36mexercise1_3\u001b[0;34m(pickleFile, func_student, sc)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestRDDStr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexercise1_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestNumber\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexercise1_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestListStr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.py\u001b[0m in \u001b[0;36mcheckExerciseFromPickle\u001b[0;34m(pickleFile, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mcheckExercise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexerciseNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.py\u001b[0m in \u001b[0;36mcheckExercise\u001b[0;34m(inputs, outputs, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mnoError\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorAns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnoError\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your Answer is Incorrect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Your Answer is Incorrect"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_3(pickleFile, getMax, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f8fdf7150154f9b563bfa4556f48e14",
     "grade": false,
     "grade_id": "r10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 4\n",
    "\n",
    "Write a function called **reducewords** that uses **reduce** to create a single string which is the concatenation of all the strings in stringRDD(with a space between each string). Example:\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "stringRDD=sc.parallelize([\"Spring quarter\", \"Learning spark basics\", \"Big data analytics with Spark\"])\n",
    "print reducewords(stringRDD)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "'Spring quarter Learning spark basics Big data analytics with Spark'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def reducewords(stringRDD):\n",
    "    return \"return concatenation of all strings using spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5040444c2e6480830adb7e459bb9db0a",
     "grade": true,
     "grade_id": "ex_4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['Spring quarter', 'Learning spark basics', 'Big data analytics with Spark']\n",
      "Correct Output: Spring quarter Learning spark basics Big data analytics with Spark\n",
      "\n",
      "Error: Function returned incorrect output\n",
      "Your Output:  return concatenation of all strings using spark\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Your Answer is Incorrect",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-003d3b7d6a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkBasics1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexercise1_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreducewords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/SparkBasics1.py\u001b[0m in \u001b[0;36mexercise1_4\u001b[0;34m(pickleFile, func_student, sc)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestNumber\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexercise1_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestListStr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexercise1_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.py\u001b[0m in \u001b[0;36mcheckExerciseFromPickle\u001b[0;34m(pickleFile, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mcheckExercise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexerciseNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.py\u001b[0m in \u001b[0;36mcheckExercise\u001b[0;34m(inputs, outputs, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mnoError\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorAns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnoError\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your Answer is Incorrect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Your Answer is Incorrect"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_4(pickleFile, reducewords, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da12ed801c802a0d343f89edc233fc03",
     "grade": false,
     "grade_id": "r11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 5\n",
    "\n",
    "Write a non-Spark function **maxFunc** that when called by the **reduce** command outputs the maximum element from a set of lists.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "listRDD=sc.parallelize([[3,4],[2,1],[7,9]])\n",
    "print listRDD.reduce(maxFunc)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    " [9]\n",
    "\n",
    "     Note: The output is a list containing a single number rather than just a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def maxFunc(x,y):\n",
    "    # x,y are lists of numbers\n",
    "    # write code here for exercise 5\n",
    "    \n",
    "    return \"returns a list to be used possibly again by the reduce command\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3578507332d264c0043cdff5473a744c",
     "grade": true,
     "grade_id": "ex_5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[15, 20], [21, 14], [18, 4, 20]]\n",
      "Correct Output: [21]\n",
      "\n",
      "Error: Incorrect return type. The return type of your function should be: <type 'list'>\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Your Answer is Incorrect",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d62fd95372c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkBasics1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSparkBasics1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexercise1_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/SparkBasics1.py\u001b[0m in \u001b[0;36mexercise1_5\u001b[0;34m(pickleFile, func_student, sc)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestListStr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexercise1_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcheckExerciseFromPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickleFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTestList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ex1_5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.py\u001b[0m in \u001b[0;36mcheckExerciseFromPickle\u001b[0;34m(pickleFile, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexerciseNumber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mcheckExercise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexerciseNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwoInputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/1.BasicSpark/Tester/Tester.py\u001b[0m in \u001b[0;36mcheckExercise\u001b[0;34m(inputs, outputs, func_student, TestFunction, exerciseNumber, sc, twoInputs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mnoError\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mTestFunction\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_student\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_student\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorAns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnoError\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your Answer is Incorrect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Your Answer is Incorrect"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_5(pickleFile, maxFunc, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54aeb98a1c64f24ebde33767001721da",
     "grade": false,
     "grade_id": "r12",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
