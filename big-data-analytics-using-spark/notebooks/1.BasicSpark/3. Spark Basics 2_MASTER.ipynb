{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Setup Notebook for Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">IMPORTANT: Only modify cells which have the following comment:</span>\n",
    "```python\n",
    "# Modify this cell\n",
    "```\n",
    "##### <span style=\"color:red\">Do not add any new cells when you submit the homework</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext(master=\"local[4]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2 as SparkBasics2\n",
    "pickleFile=\"Tester/SparkBasics2.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Importing all packages necessary to complete the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Teacher Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2_MASTER as SparkBasics2_MASTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SparkBasics2_MASTER.gen_exercise1(pickleFile, sc)\n",
    "SparkBasics2_MASTER.gen_exercise2(pickleFile, sc)\n",
    "SparkBasics2_MASTER.gen_exercise3(pickleFile, sc)\n",
    "SparkBasics2_MASTER.gen_exercise4(pickleFile, sc)\n",
    "SparkBasics2_MASTER.gen_exercise5(pickleFile, sc)\n",
    "SparkBasics2_MASTER.gen_exercise6(pickleFile, sc)\n",
    "SparkBasics2_MASTER.gen_exercise7(pickleFile, sc)\n",
    "SparkBasics2_MASTER.gen_exercise8(pickleFile, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SparkBasics2_MASTER.exercise1(pickleFile, SparkBasics2_MASTER.func_ex1, sc)\n",
    "SparkBasics2_MASTER.exercise2(pickleFile, SparkBasics2_MASTER.func_ex2, sc)\n",
    "SparkBasics2_MASTER.exercise3(pickleFile, SparkBasics2_MASTER.func_ex3, sc)\n",
    "SparkBasics2_MASTER.exercise4(pickleFile, SparkBasics2_MASTER.func_ex4, sc)\n",
    "SparkBasics2_MASTER.exercise5(pickleFile, SparkBasics2_MASTER.func_ex5, sc)\n",
    "SparkBasics2_MASTER.exercise6(pickleFile, SparkBasics2_MASTER.func_ex6, sc)\n",
    "SparkBasics2_MASTER.exercise7(pickleFile, SparkBasics2_MASTER.func_ex7, sc)\n",
    "SparkBasics2_MASTER.exercise8(pickleFile, SparkBasics2_MASTER.func_ex8, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SparkBasics2.exercise1(pickleFile, SparkBasics2_MASTER.func_ex1, sc)\n",
    "SparkBasics2.exercise2(pickleFile, SparkBasics2_MASTER.func_ex2, sc)\n",
    "SparkBasics2.exercise3(pickleFile, SparkBasics2_MASTER.func_ex3, sc)\n",
    "SparkBasics2.exercise4(pickleFile, SparkBasics2_MASTER.func_ex4, sc)\n",
    "SparkBasics2.exercise5(pickleFile, SparkBasics2_MASTER.func_ex5, sc)\n",
    "SparkBasics2.exercise6(pickleFile, SparkBasics2_MASTER.func_ex6, sc)\n",
    "SparkBasics2.exercise7(pickleFile, SparkBasics2_MASTER.func_ex7, sc)\n",
    "SparkBasics2.exercise8(pickleFile, SparkBasics2_MASTER.func_ex8, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "Write a function called **maxSum** which finds the maximum of each list and sums them all together. \n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "listRDD=sc.parallelize([[3,4],[2,1],[7,9]]) \n",
    "print maxSum(listRDD)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "15 \n",
    "\n",
    "    Note: 15 = 4 + 2 + 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def maxSum(A):\n",
    "    # Write code that will perform the task outlined in exercise 1\n",
    "    return \"returns the sum of maximum numbers of all lists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2 as SparkBasics2\n",
    "SparkBasics2.exercise1(pickleFile, maxSum,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Write a function called **positiveCos** which uses **filter** to output elements whose cosine is positive. \n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "    RDD=sc.parallelize([0,2,1])\n",
    "    print positiveCos(RDD)\n",
    "    print positiveCos(RDD).collect()\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "[0,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def positiveCos(A):\n",
    "    # Write code that will perform the task outlined in exercise 2\n",
    "    return \"returns a spark RDD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2 as SparkBasics2\n",
    "SparkBasics2.exercise2(pickleFile, positiveCos,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 3\n",
    "Write a function called **longWords** which uses **filter** to output all words whose length is greater than or equal to 4. \n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "wordRDD=sc.parallelize(['this','is','the','best','mac','ever'])\n",
    "print longWords(RDD)\n",
    "print longWords(RDD).collect()\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "['this', 'best', 'ever']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def longWords(A):\n",
    "    # Write code that will perform the task outlined in exercise 3\n",
    "    return \"returns a spark RDD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2 as SparkBasics2\n",
    "SparkBasics2.exercise3(pickleFile, longWords,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 4\n",
    "\n",
    "Write a function **collectRange** which uses **flatMap** to collect all the elements from 1 to x for each element x in the given listRDD. \n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "RDD=sc.parallelize([2,3,5])\n",
    "print collectRange(RDD)\n",
    "print collectRange(RDD).collect()\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "[1, 2, 1, 2, 3, 1, 2, 3, 4, 5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def collectRange(A):\n",
    "    # Write code that will perform the task outlined in exercise 4\n",
    "    return \"returns a spark RDD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2 as SparkBasics2\n",
    "SparkBasics2.exercise4(pickleFile, collectRange,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Consider the following RDDs: \n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "RDD1=sc.parallelize([\"spark basics\", \"big data analysis\", \"spring\"]) \n",
    "RDD2=sc.parallelize([\"spark using pyspark\", \"big data\"]) \n",
    "```\n",
    "\n",
    "Use set operations for the following exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise 5\n",
    "\n",
    "Write a function **transform1(RDD1,RDD2)**\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "print transform1(RDD1,RDD2)\n",
    "print transform1(RDD1,RDD2).collect()\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "\n",
    "\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "['spark', 'basics', 'big', 'data', 'analysis', 'spring', 'spark', 'using', 'pyspark', 'big', 'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def transform1(RDD1,RDD2):\n",
    "    # Write code that will perform the task outlined in exercise 5\n",
    "    return \"returns a spark RDD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2 as SparkBasics2\n",
    "SparkBasics2.exercise5(pickleFile, transform1,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise 6\n",
    "\n",
    "Write a function **transform2(RDD1,RDD2)**\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "print transform2(RDD1,RDD2)\n",
    "print transform2(RDD1,RDD2).collect()\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "['data', 'big', 'spark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def transform2(RDD1,RDD2):\n",
    "    # Write code that will perform the task outlined in exercise 6\n",
    "    return \"returns a spark RDD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2 as SparkBasics2\n",
    "SparkBasics2.exercise6(pickleFile, transform2,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise 7\n",
    "\n",
    "Write a function **transform3(RDD1,RDD2)**\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "print transform3(RDD1,RDD2)\n",
    "print transform3(RDD1,RDD2).collect()\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "['spring', 'analysis', 'basics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def transform3(RDD1,RDD2):\n",
    "    # Write code that will perform the task outlined in exercise 7\n",
    "    return \"returns a spark RDD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2 as SparkBasics2\n",
    "SparkBasics2.exercise7(pickleFile, transform3,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 8\n",
    "\n",
    "Write a function **transform4(RDD1,RDD2)**\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "print transform4(RDD1,RDD2)\n",
    "print transform4(RDD1,RDD2).collect()\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "[('spark', 'spark'), ('spark', 'using'), ('spark', 'pyspark'), ('basics', 'spark'), ('basics', 'using'), ('basics', 'pyspark'), ('spark', 'big'), ('spark', 'data'), ('basics', 'big'), ('basics', 'data'), ('big', 'spark'), ('big', 'using'), ('big', 'pyspark'), ('data', 'spark'), ('analysis', 'spark'), ('data', 'using'), ('data', 'pyspark'), ('analysis', 'using'), ('analysis', 'pyspark'), ('spring', 'spark'), ('spring', 'using'), ('spring', 'pyspark'), ('big', 'big'), ('big', 'data'), ('data', 'big'), ('analysis', 'big'), ('data', 'data'), ('analysis', 'data'), ('spring', 'big'), ('spring', 'data')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def transform4(RDD1,RDD2):\n",
    "    # Write code that will perform the task outlined in exercise 8\n",
    "    return \"returns a spark RDD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics2 as SparkBasics2\n",
    "SparkBasics2.exercise8(pickleFile, transform4,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
