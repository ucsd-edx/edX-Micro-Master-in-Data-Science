{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# From Spark Basics 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Exercise 1.\n",
    "Consider the following RDD\n",
    "    \n",
    "    listRDD=sc.parallelize([[3,4],[2,1],[7,9]]) \n",
    "    \n",
    "Find the sum of maximum numbers of all lists. Your output should be:\n",
    "\n",
    "    Output:  15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def maxSum(A):\n",
    "    # Write code that will perform the task outlined in exercise 1\n",
    "    return \"returns the sum of maximum numbers of all lists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SparkBasics2.exercise3_1(pickleFile, maxSum,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Exercise 2\n",
    "\n",
    "Write a `filter` command to output elements whose cosine is positive. On the input \n",
    "\n",
    "    RDD=sc.parallelize([0,2,1]):\n",
    "\n",
    "positiveCos(RDD) should produce some output approximately like:\n",
    "\n",
    "    PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "positiveCos(RDD).collect() should produce:\n",
    "\n",
    "     [0,1] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def positiveCos(A):\n",
    "    # Write code that will perform the task outlined in exercise 2\n",
    "    return \"returns a spark RDD, so to get a list do: positiveCos(A).collect()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SparkBasics2.exercise3_2(pickleFile, SparkBasics2_Teacher.func_ex3_2,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Exercise 3\n",
    "Write a `filter` command to output all words whose length is greater than or equal to 4. On the input: ` wordRDD=sc.parallelize(['this','is','the','best','mac','ever']) `\n",
    "\n",
    "longWords(RDD) should produce some output approximately like:\n",
    "\n",
    "    PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "longWords(RDD).collect() should produce:\n",
    "\n",
    "    ['this', 'best', 'ever']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def longWords(A):\n",
    "    # Write code that will perform the task outlined in exercise 3\n",
    "    return \"returns a spark RDD, so to get a list do: longWords(A).collect()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SparkBasics2.exercise3_3(pickleFile, longWords,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Exercise 4\n",
    "\n",
    "Write a `flatMap` command to collect all the elements from 1 to x for each element x in a list. On input `RDD=sc.parallelize([2,3,5])`\n",
    "\n",
    "collectRange(RDD) should produce some output approximately like:\n",
    "\n",
    "    PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "collectRange(RDD).collect() should produce:\n",
    "\n",
    "     [1, 2, 1, 2, 3, 1, 2, 3, 4, 5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def collectRange(A):\n",
    "    # Write code that will perform the task outlined in exercise 4\n",
    "    return \"returns a spark RDD, so to get a list do: collectRange(A).collect()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SparkBasics2.exercise3_4(pickleFile, collectRange,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Exercise \n",
    "\n",
    "Consider the following RDDs: \n",
    "\n",
    "` RDD1=sc.parallelize([\"spark basics\", \"big data analysis\", \"spring\"]) `\n",
    "\n",
    "` RDD2=sc.parallelize([\"spark using pyspark\", \"big data\"]) `\n",
    "\n",
    "Use the set operations for the following exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Exercise 5\n",
    "\n",
    "transform1(RDD1,RDD2) should produce some output approximately like:\n",
    "\n",
    "    PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "transform1(RDD1,RDD2).collect() should produce:\n",
    "\n",
    "* ` ['spark', 'basics', 'big', 'data', 'analysis', 'spring', 'spark', 'using', 'pyspark', 'big', 'data'] `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def transform1(RDD1,RDD2):\n",
    "    # Write code that will perform the task outlined in exercise 5\n",
    "    return \"returns a spark RDD, so to get a list do: transform1(RDD1,RDD2).collect()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SparkBasics2.exercise3_5(pickleFile, transform1,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Exercise 6\n",
    "\n",
    "transform2(RDD1,RDD2) should produce some output approximately like:\n",
    "\n",
    "    PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "transform2(RDD1,RDD2).collect() should produce:\n",
    "\n",
    "* ` ['data', 'big', 'spark'] `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def transform2(RDD1,RDD2):\n",
    "    # Write code that will perform the task outlined in exercise 6\n",
    "    return \"returns a spark RDD, so to get a list do: transform2(RDD1,RDD2).collect()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SparkBasics2.exercise3_6(pickleFile, transform2,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Exercise 7\n",
    "\n",
    "transform3(RDD1,RDD2) should produce some output approximately like:\n",
    "\n",
    "    PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "transform3(RDD1,RDD2).collect() should produce:\n",
    "\n",
    "* ` ['spring', 'analysis', 'basics'] `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def transform3(RDD1,RDD2):\n",
    "    # Write code that will perform the task outlined in exercise 7\n",
    "    return \"returns a spark RDD, so to get a list do: transform3(RDD1,RDD2).collect()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SparkBasics2.exercise3_7(pickleFile, transform3,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Exercise 8\n",
    "\n",
    "transform4(RDD1,RDD2) should produce some output approximately like:\n",
    "\n",
    "    PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "transform4(RDD1,RDD2).collect() should produce:\n",
    "\n",
    "* ` [('spark', 'spark'), ('spark', 'using'), ('spark', 'pyspark'), ('basics', 'spark'), ('basics', 'using'), ('basics', 'pyspark'), ('spark', 'big'), ('spark', 'data'), ('basics', 'big'), ('basics', 'data'), ('big', 'spark'), ('big', 'using'), ('big', 'pyspark'), ('data', 'spark'), ('analysis', 'spark'), ('data', 'using'), ('data', 'pyspark'), ('analysis', 'using'), ('analysis', 'pyspark'), ('spring', 'spark'), ('spring', 'using'), ('spring', 'pyspark'), ('big', 'big'), ('big', 'data'), ('data', 'big'), ('analysis', 'big'), ('data', 'data'), ('analysis', 'data'), ('spring', 'big'), ('spring', 'data')]\n",
    " `    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def transform4(RDD1,RDD2):\n",
    "    # Write code that will perform the task outlined in exercise 8\n",
    "    return \"returns a spark RDD, so to get a list do: transform4(RDD1,RDD2).collect()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SparkBasics2.exercise3_8(pickleFile, transform4,sc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "210px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
