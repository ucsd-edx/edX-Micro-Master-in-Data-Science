{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word Count\n",
    "Counting the number of occurances of words in a text is one of the most popular first eercises when learning Map-Reduce Programming. It is the equivalent to `Hello World!` in regular programming.\n",
    "\n",
    "We will do it two way, a simpler way where sorting is done after the RDD is collected, and a more sparky way, where the sorting is also done using an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "testPath = '/'.join(os.getcwd().split('/')[:-1]) + \"/Tester\"\n",
    "sys.path.insert(0, testPath )\n",
    "pickleFile = testPath+ \"/WordCount.pkl\"\n",
    "\n",
    "import WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#start the SparkContext\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master=\"local[3]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Teacher Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import WordCount_Teacher\n",
    "WordCount_Teacher.gen_exercise(pickleFile,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "WordCount_Teacher.exercise(pickleFile, map_kmers, count_kmers, sort_counts, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Download data file from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import urllib\n",
    "data_dir='../../Data'\n",
    "filename='Moby-Dick.txt'\n",
    "f = urllib.urlretrieve (\"https://mas-dse-open.s3.amazonaws.com/\"+filename, data_dir+'/'+filename)\n",
    "\n",
    "# First, check that the text file is where we expect it to be\n",
    "!ls -l $data_dir/$filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define an RDD that will read the file\n",
    "Note that, as execution is Lazy, this does not necessarily mean that actual reading of the file content has occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "text_file = sc.textFile(data_dir+'/'+filename)\n",
    "type(text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Define the code for counting the words\n",
    "* split line by spaces.\n",
    "* map `word` to `(word,1)`\n",
    "* count the number of occurances of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "             .filter(lambda x: x!='')\\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "type(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Have a look a the execution plan\n",
    "Note that the earliest node in the dependency graph is the file `../../Data/Moby-Dick.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print counts.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Count!\n",
    "Finally we count the number of times each word has occured.\n",
    "Now, finally, the Lazy execution model finally performs some actual work, which takes a significant amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Count=counts.count()\n",
    "Sum=counts.map(lambda (w,i): i).reduce(lambda x,y:x+y)\n",
    "print 'Count=%f, sum=%f, mean=%f'%(Count,Sum,float(Sum)/Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finding the most common words\n",
    "* `counts`: RDD with 33301 pairs of the form `(word,count)`. \n",
    "* Find the 2 most frequent words. \n",
    "* **Method1:** `collect` and sort on head node.\n",
    "* **Method2:** Pure Spark, `collect` only at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Method1: `collect` and sort on head node \n",
    "### Collect the RDD into the driver node\n",
    "* Collect can take significant time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "C=counts.collect()\n",
    "print type(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sort \n",
    "* RDD collected into list in driver node.\n",
    "* No longer using spark parallelism.\n",
    "* Sort in python\n",
    "* will nor scale to very large documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "C.sort(key=lambda x:x[1])\n",
    "print 'most common words\\n','\\n'.join(['%s:\\t%d'%c for c in C[-5:]])\n",
    "print '\\nLeast common words\\n','\\n'.join(['%s:\\t%d'%c for c in C[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Compute the mean number of occurances per word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "Count2=len(C)\n",
    "Sum2=sum([i for w,i in C])\n",
    "print 'count2=%f, sum2=%f, mean2=%f'%(Count2,Sum2,float(Sum2)/Count2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Method2:** Pure Spark, `collect` only at the end.\n",
    "* Collect into the head node only the more frquent words.\n",
    "* Requires multiple **stages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Step 1** split, clean and map to `(word,1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "RDD=text_file.flatMap(lambda x: x.split(' '))\\\n",
    "    .filter(lambda x: x!='')\\\n",
    "    .map(lambda word: (word,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Step 2** Count occurances of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "RDD1=RDD.reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Step 3** Reverse `(word,count)` to `(count,word)` and sort by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "RDD2=RDD1.map(lambda (c,v):(v,c))\n",
    "RDD3=RDD2.sortByKey(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Full execution plan\n",
    "\n",
    "We now have a complete plan to compute the most common words in the text. Nothing has been executed yet! Not even one one bye has been read from the file `Moby-Dick.txt` !\n",
    "\n",
    "For more on execution plans and lineage see [jace Klaskowski's blog](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-rdd-lineage.html#toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print 'RDD3:'\n",
    "print RDD3.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Step 4** Take the top 5 words. **only now the computer executes the plan!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "C=RDD3.take(5)\n",
    "print 'most common words\\n','\\n'.join(['%d:\\t%s'%c for c in C])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**HW Below **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Exercise\n",
    "A `k`-mer is a sequence of `k` consecutive words. \n",
    "\n",
    "For example, the `3`-mers in the line `you are my sunshine my only sunsine` are\n",
    "\n",
    "* `you are my`\n",
    "* `are my sunshine`\n",
    "* `my sunshine my`\n",
    "* `sunshine my only`\n",
    "* `my only sunsine`\n",
    "\n",
    "For the sake of simplicity we consider only the `k`-mers that appear in a single line. In other words, we ignore `k`-mers that span more than one line.\n",
    "\n",
    "Write a function, using spark all the way to the end, to find to top 10 `k`-mers in a given text for a given `k`.\n",
    "\n",
    "Specifically write functions with the following signatures:\n",
    "```python\n",
    "def map_kmers(text,k):\n",
    "    \\\\ text: an RDD of text lines. Lines contain only lower-case letters and spaces. Spaces should be ignored.\n",
    "    \\\\ k: length of `k`-mers\n",
    "    return  singles\n",
    "    \\\\ singles: an RDD of pairs of the form (tuple of k words,1)\n",
    "def count_kmers(singles):\n",
    "    \\\\ singles: as above\n",
    "    return counts\n",
    "    \\\\ count: RDD of the form: (tuple of k words, number of occurances)\n",
    "def sort_counts(count):\n",
    "    \\\\ count: as above\n",
    "    return sorted_counts\n",
    "    \\\\ sorted_counts: RDD of the form (number of occurances, tuple of k words) sorted in decreasing number of occurances.\n",
    "```\n",
    "Combining these operations as follows:\n",
    "```python \n",
    "k=3\n",
    "singles=map_kmers(text,k)\n",
    "count=count_kmers(singles)\n",
    "sorted_counts=sort_counts(count)\n",
    "C=sorted_counts.take(5)\n",
    "print 'most common %d-mers\\n'%k,'\\n'.join(['%d:\\t%s'%c for c in C])\n",
    "```\n",
    "\n",
    "Should print the 5 most common 3-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def map_kmers(text,k):\n",
    "    # text: an RDD of text lines. Lines contain only lower-case letters and spaces. Spaces should be ignored.\n",
    "    # k: length of `k`-mers\n",
    "    return  singles\n",
    "    # singles: an RDD of pairs of the form (tuple of k words,1)\n",
    "def count_kmers(singles):\n",
    "    # singles: as above\n",
    "    return count\n",
    "    # count: RDD of the form: (tuple of k words, number of occurances)\n",
    "def sort_counts(count):\n",
    "    # count: as above\n",
    "    return sorted_count\n",
    "    # sorted_counts: RDD of the form (number of occurances, tuple of k words) sorted in decreasing number of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def getkmers(text_file, l,k, map_kmers, count_kmers, sort_counts):\n",
    "    # text_file: the text_file RDD read above\n",
    "    # k: k-mers\n",
    "    # l: l most common k-mers\n",
    "    \n",
    "    # Do Not modify this function\n",
    "    import re\n",
    "    def removePunctuation(text):\n",
    "        return re.sub(\"[^0-9a-zA-Z ]\", \" \", text)\n",
    "    print text_file.toDebugString()\n",
    "    text = text_file.map(removePunctuation)\\\n",
    "                    .map(lambda x: x.lower())\n",
    "    print text.toDebugString()\n",
    "    singles=map_kmers(text,k)\n",
    "    print singles.toDebugString()\n",
    "    count=count_kmers(singles)\n",
    "    print count.toDebugString()\n",
    "    sorted_counts=sort_counts(count)\n",
    "    print sorted_counts.toDebugString()\n",
    "    C=sorted_counts.take(l)\n",
    "    print 'most common %d-mers\\n'%k,'\\n'.join(['%d:\\t%s'%c for c in C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_file = sc.textFile(u'../../Data/Moby-Dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "getkmers(text_file,5,3, map_kmers, count_kmers, sort_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "WordCount.exercise(pickleFile, map_kmers, count_kmers, sort_counts, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "349px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
