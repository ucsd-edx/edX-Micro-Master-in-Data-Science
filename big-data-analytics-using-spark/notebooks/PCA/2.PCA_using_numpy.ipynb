{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing PCA on vectors with NaNs\n",
    "This notebook demonstrates the use of numpy arrays as the content of RDDs\n",
    "\n",
    "The reason that we use numpy arrays instead of dataframes is that numpy is better in handling `nan` etries.\n",
    "\n",
    "In numpy `5+nan=5` while in dataframes `5+nan=nan`\n",
    "\n",
    "Suppose that the data vectors are the column vectors denoted $x$ then the covariance matrix is defined to be\n",
    "$$\n",
    "E(x x^T)-E(x)E(x)^T\n",
    "$$\n",
    "\n",
    "Where $x x^T$ is the **outer product** of $x$ with itself.\n",
    "\n",
    "If the data that we have is $x_1,x_2,x_n$ then the estimates we use are:\n",
    "$$\n",
    "\\hat{E}(x x^T) = \\frac{1}{n} \\sum_{i=1}^n x_i x_i^T,\\;\\;\\;\\;\\;\n",
    "\\hat{E}(x) = \\frac{1}{n} \\sum_{i=1}^n x_i\n",
    "$$\n",
    "\n",
    "As it happens, we often get vectors $x$ in which some, but not all, of the entries are `nan`. In such cases we sum the elements that are defined and keep a seperate counter for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def outerProduct(X):\n",
    "  \"\"\"Computer outer product and indicate which locations in matrix are undefined\"\"\"\n",
    "  O=np.outer(X,X)\n",
    "  N=1-np.isnan(O)\n",
    "  return (O,N)\n",
    "def sumWithNan(M1,M2):\n",
    "  \"\"\"Add two pairs of matrix,count\"\"\"\n",
    "  (X1,N1)=M1\n",
    "  (X2,N2)=M2\n",
    "  N=N1+N2\n",
    "  X=np.nansum(np.dstack((X1,X2)),axis=2)\n",
    "  return (X,N)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# computeCov recieves as input an RDD of np arrays, all of the same length, and computes the covariance matrix for that set of vectors\n",
    "def computeCov(RDDin):\n",
    "  RDD=RDDin.map(lambda v:np.insert(v,0,1)) # insert a 1 at the beginning of each vector so that the same \n",
    "                                           #calculation also yields the mean vector\n",
    "  OuterRDD=RDD.map(outerProduct)   # separating the map and the reduce does not matter because of Spark uses lazy execution.\n",
    "  (S,N)=OuterRDD.reduce(sumWithNan)\n",
    "  # Unpack result and compute the covariance matrix\n",
    "  #print 'RDD=',RDD.collect()\n",
    "  print 'shape of S=',S.shape,'shape of N=',N.shape\n",
    "  #print 'S=',S\n",
    "  #print 'N=',N\n",
    "  E=S[0,1:]\n",
    "  NE=N[0,1:]\n",
    "  print 'shape of E=',E.shape,'shape of NE=',NE.shape\n",
    "  Mean=E/NE\n",
    "  O=S[1:,1:]\n",
    "  NO=N[1:,1:]\n",
    "  Cov=O/NO - np.outer(Mean,Mean)\n",
    "  return Cov,Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstration on a small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A=np.array([1,2,3,4,np.nan,5,6])\n",
    "B=np.array([2,np.nan,1,1,1,1,1])\n",
    "np.nansum(np.dstack((A,B)),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RDD=sc.parallelize([A,B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computeCov(RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstration on real data\n",
    "The following cells demonstrate the use of the code we wrote on the maximal-dayly temperature records for the state of california."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMAX = sqlContext.sql(\"select * from weather where measurement = 'TMAX'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print type(TMAX)\n",
    "print TMAX.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /Users/yfreund@ucsd.edu/Vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AWS_BUCKET_NAME = \"mas-dse-public\" \n",
    "MOUNT_NAME = \"NCDC-weather\"\n",
    "dbutils.fs.unmount(\"/mnt/%s\" % MOUNT_NAME)\n",
    "output_code=dbutils.fs.mount(\"s3n://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\n",
    "print 'Mount output status=',output_code\n",
    "file_list=dbutils.fs.ls('/mnt/%s/Weather'%MOUNT_NAME)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "US_Weather_parquet='/mnt/NCDC-weather/Weather/US_Weather.parquet/'\n",
    "df = sqlContext.sql(\"SELECT * FROM  parquet.`%s`  where measurement=='TMAX'\"%US_Weather_parquet)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We transform the dataframe into an RDD of numpy arrays\n",
    "# remove the entries that do not correspond to temperature and devide by 10 so that the result is in centigrates.\n",
    "rdd=df.map(lambda v:np.array(v[3:-4])/10).cache()\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows=rdd.take(5)\n",
    "len(rows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "UnDef=rdd.map(lambda row:sum(np.isnan(row))).collect()\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(UnDef,bins=36)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove entries that have 10 or more nan's\n",
    "rdd=rdd.filter(lambda row:sum(np.isnan(row))<1)\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUT=computeCov(rdd)\n",
    "OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(i,OUT[i].shape) for i in range(len(OUT))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(Cov,Mean)=OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cov[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "w,v=LA.eig(Cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from numpy import shape\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as py\n",
    "from pylab import ylabel,grid,title\n",
    "\n",
    "dates=[date.fromordinal(i) for i in range(1,366)]\n",
    "def YearlyPlots(T,ttl='',size=(10,7)):\n",
    "    fig=plt.figure(1,figsize=size,dpi=300)\n",
    "    fig, ax = plt.subplots(1)\n",
    "    if shape(T)[0] != 365:\n",
    "        raise ValueError(\"First dimension of T should be 365. Shape(T)=\"+str(shape(T)))\n",
    "    ax.plot(dates,T);\n",
    "    # rotate and align the tick labels so they look better\n",
    "    fig.autofmt_xdate()\n",
    "    ylabel('temperature')\n",
    "    grid()\n",
    "    title(ttl)\n",
    "    return fig\n",
    "fig=YearlyPlots(v[:,:4],'Eigen-Vectors')\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig=YearlyPlots(Mean,'Mean')\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Var=np.cumsum(w)\n",
    "Var=Var/Var[-1]\n",
    "fig, ax = plt.subplots()\n",
    "#ax.plot(x, Mean, 'r')\n",
    "ax.plot(x,Var)\n",
    "ax.grid()\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": "PCA_using_numpy",
  "notebookId": 63332
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
