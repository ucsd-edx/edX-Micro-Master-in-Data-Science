{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction using top eigen-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Enable automiatic reload of libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2 # means that all modules are reloaded before every command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pandas as    pd \tversion=0.19.2 \trequired version>=0.19.2\n",
      "     numpy as    np \tversion=1.12.0 \trequired version>=1.12.0\n",
      "   sklearn as    sk \tversion=0.18.1 \trequired version>=0.18.1\n",
      "    urllib as urllib \tversion=1.17 \trequired version>=1.17\n",
      "module pyspark has no version\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./lib')\n",
    "from import_modules import import_modules,modules\n",
    "import_modules(modules)\n",
    "\n",
    "from numpy_pack import packArray,unpackArray\n",
    "from spark_PCA import computeCov\n",
    "from computeStats import computeOverAllDist, STAT_Descriptions\n",
    "from recon_plot import recon_plot\n",
    "from Eigen_decomp import Eigen_decomp\n",
    "from YearPlotter import YearPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1e15a15ded01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#sc.stop()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"local[3]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpyFiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lib/numpy_pack.py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lib/spark_PCA.py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lib/computeStats.py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lib/recon_plot.py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lib/Eigen_decomp.py'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoavfreund/spark-latest/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/Users/yoavfreund/spark-latest/python/pyspark/context.pyc\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoavfreund/spark-latest/python/pyspark/java_gateway.pyc\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mgateway_port\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# (seconds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mreadable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback_socket\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_socket\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mgateway_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "#sc.stop()\n",
    "sc = SparkContext(master=\"local[3]\",pyFiles=['lib/numpy_pack.py','lib/spark_PCA.py','lib/computeStats.py','lib/recon_plot.py','lib/Eigen_decomp.py'])\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read Statistics File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_dir='../../Data/Weather'\n",
    "file_index='BBBSBBBB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "#read statistics\n",
    "filename=data_dir+'/STAT_%s.pickle'%file_index\n",
    "STAT,STAT_Descriptions = load(open(filename,'rb'))\n",
    "measurements=STAT.keys()\n",
    "print 'keys from STAT=',measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read data file into a spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "filename=data_dir+'/US_Weather_BBBSBBBB.csv'\n",
    "List=load(open(filename,'rb'))\n",
    "print 'length of List=',len(List)\n",
    "\n",
    "df=sqlContext.createDataFrame(List)\n",
    "print df.count()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Look at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "m='SNWD'\n",
    "sqlContext.registerDataFrameAsTable(df,'weather')\n",
    "Query=\"SELECT * FROM weather\\n\\tWHERE measurement='%s'\"%(m)\n",
    "print Query\n",
    "df1 = sqlContext.sql(Query)\n",
    "print df1.count(),'rows'\n",
    "df1.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Create a matrix with all of the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rows=df1.rdd.map(lambda row:unpackArray(row['vector'],np.float16)).collect()\n",
    "T=np.vstack(rows)\n",
    "T=T # scaling to make the temperature be in centingrates\n",
    "shape(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plot two time series\n",
    "`SNWD` stands for `snow-depth`, which explains why it is zero during the summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from YearPlotter import YearPlotter\n",
    "fig, ax = plt.subplots(figsize=(6,4));\n",
    "YP=YearPlotter()\n",
    "YP.plot(T[16:18].transpose(),fig,ax,title=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot Reconstructions\n",
    "\n",
    "Construct approximations of a time series using the mean and the $k$ top eigen-vectors\n",
    "First, we plot the mean and the top $k$ eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "k=3\n",
    "EigVec=np.matrix(STAT[m]['eigvec'][:,:k])\n",
    "Mean=STAT[m]['Mean']\n",
    "fig=plt.figure(figsize=(6,4))\n",
    "ax=fig.add_axes([0,0,1,.5])\n",
    "YearPlotter().plot(Mean,fig,ax,label='Mean',title=m)\n",
    "ax=fig.add_axes([0,.5,1,.5])\n",
    "YearPlotter().plot(EigVec,fig,ax,title=m,labels=['eig'+str(i+1) for i in range(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### plot the percent of residual variance on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#  x=0 in the graphs below correspond to the fraction of the variance explained by the mean alone\n",
    "#  x=1,2,3,... are the residuals for eig1, eig1+eig2, eig1+eig2+eig3 ...\n",
    "figure(figsize=[10,4]); subplot(121)\n",
    "eigvals=STAT[m]['eigval']; eigvals/=sum(eigvals); cumvar=cumsum(eigvals)\n",
    "plot(1-cumvar[:10]); grid(); title('average residuals')\n",
    "subplot(122)\n",
    "v=[np.array(EigVec[:,i]).flatten() for i in range(shape(EigVec)[1])]\n",
    "target=T[16,:]\n",
    "eigen_decomp=Eigen_decomp(None,target,Mean,v)\n",
    "total_var,residuals,reductions,_coeff=eigen_decomp.compute_var_explained()\n",
    "plot(list(residuals[1])); grid(); title('single series residuals');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interactive plot of reconstruction\n",
    "\n",
    "Following is an interactive widget which lets you change the coefficients of the eigen-vectors to see the effect on the approximation.\n",
    "The initial state of the sliders (in the middle) corresponds to the optimal setting. You can zero a positive coefficient by moving the slider all the way down, zero a negative coefficient by moving it all the way up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load lib/YearPlotter.py\n",
    "from datetime import date\n",
    "from numpy import shape\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "class YearPlotter:\n",
    "    def __init__(self):\n",
    "        start=365*1+1\n",
    "        self.dates=[date.fromordinal(i) for i in range(start,start+365)]\n",
    "        self.monthsFmt = DateFormatter(\"%b\")\n",
    "        self.months = MonthLocator(range(1, 13), bymonthday=1, interval=10)\n",
    "        #self.i=0\n",
    "\n",
    "    def plot(self,T,fig,ax,label='',labels=None,title=None):\n",
    "        #print self.i,'fig=',fig,'ax=',ax\n",
    "        #self.i+=1\n",
    "        shp=shape(T)\n",
    "        if shp[0] != 365:\n",
    "            raise ValueError(\"First dimension of T should be 365. Shape(T)=\"+str(shape(T)))\n",
    "        if len(shp)==1:\n",
    "            #print 'one'\n",
    "            ax.plot(self.dates,T,label=label);\n",
    "        else:\n",
    "            #print 'more than 1'\n",
    "            if labels is None:\n",
    "                labels=[str(i) for i in range(shp[1])]\n",
    "            for i in range(shp[1]):\n",
    "                ax.plot(self.dates,T[:,i],label=labels[i])\n",
    "        ax.xaxis.set_major_locator(self.months)\n",
    "        ax.xaxis.set_major_formatter(self.monthsFmt)\n",
    "        if not title is None:\n",
    "            ax.set_title(title)\n",
    "        # rotate and align the tick labels so they look better\n",
    "        fig.autofmt_xdate()\n",
    "        ax.grid()\n",
    "        ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile lib/recon_plot.py\n",
    "import numpy as np\n",
    "from YearPlotter import YearPlotter\n",
    "from Eigen_decomp import Eigen_decomp\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "class recon_plot:\n",
    "    \"\"\"A class for creating an interactive demonstration of approximating \n",
    "    a function with an orthonormal set of function\"\"\"\n",
    "    def __init__(self,eigen_decomp,year_axis=False,fig=None,ax=None,interactive=True,Title=None):\n",
    "        \"\"\" \n",
    "        Initialize the plot widget\n",
    "        :param: eigen_decomp: An Eigen_Decomp object\n",
    "        :param: year_axis: set to true if X axis should correspond to the months of the year.\n",
    "\n",
    "        \"\"\"\n",
    "        self.eigen_decomp=eigen_decomp\n",
    "        self.interactive=interactive\n",
    "        self.fig=fig\n",
    "        self.ax=ax\n",
    "        self.Title=Title\n",
    "        \n",
    "        self.year_axis=year_axis\n",
    "        self.yearPlotter=None\n",
    "        if year_axis:\n",
    "            self.yearPlotter=YearPlotter()\n",
    "        self.plot_combination(**self.eigen_decomp.coeff)\n",
    "        return None\n",
    "\n",
    "    def get_widgets(self):\n",
    "        \"\"\"return the slider widget that are to be used\n",
    "\n",
    "        :returns: widget_list: the list of widgets in order\n",
    "                  widget_dict: a dictionary of the widget to be used in `interact\n",
    "\n",
    "        :todo: make the sliders smaller: http://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Styling.html\n",
    "        \"\"\"\n",
    "        coeff=self.eigen_decomp.C\n",
    "        widge_dict={}\n",
    "        widge_list=[]\n",
    "        for i in range(self.eigen_decomp.n):\n",
    "            if coeff[i]>0:\n",
    "                r=[0,coeff[i]*2]\n",
    "            else:\n",
    "                r=[coeff[i]*2,0]\n",
    "\n",
    "            widge_list.append(widgets.FloatSlider(min=r[0],max=r[1],step=coeff[i]/10.,\\\n",
    "                                                  value=coeff[i],orientation='vertical',decription='v'+str(i)))\n",
    "            widge_dict['c'+str(i)]=widge_list[-1]\n",
    "\n",
    "        return widge_list,widge_dict\n",
    "\n",
    "    def plot(self,y,label=''):\n",
    "        if self.year_axis:\n",
    "            self.yearPlotter.plot(y,self.fig,self.ax,label=label)\n",
    "        else:\n",
    "            self.ax.plot(self.eigen_decomp.x,y,label=label);\n",
    "\n",
    "    def plot_combination(self,**coeff):\n",
    "        \"\"\"the plotting function that is called by `interactive`\n",
    "           generates the plot according the the parameters set by the sliders\n",
    "\n",
    "        :returns: None\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.interactive or self.fig is None:\n",
    "            self.fig=plt.figure(figsize=(8,6))\n",
    "            self.ax=self.fig.add_axes([0,0,1,1])\n",
    "\n",
    "        A=self.eigen_decomp.mean\n",
    "        self.plot(A,label='mean')\n",
    "\n",
    "        for i in range(self.eigen_decomp.n):\n",
    "            g=self.eigen_decomp.v[i]*coeff['c'+str(i)]\n",
    "            A=A+g\n",
    "            self.plot(A,label='c'+str(i))\n",
    "        self.plot(self.eigen_decomp.f,label='target')\n",
    "        self.ax.grid(figure=self.fig)        \n",
    "        self.ax.legend()\n",
    "        self.ax.set_title(self.Title)\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ipywidgets import interactive,widgets\n",
    "eigen_decomp=Eigen_decomp(x,f,np.zeros(len(f)),v)\n",
    "plotter=recon_plot(eigen_decomp,year_axis=True);\n",
    "widge_list,widge_dict = plotter.get_widgets()\n",
    "interactive(plotter.plot_combination, **widge_dict)\n",
    "widgets.VBox([widgets.HBox(widge_list)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from recon_plot import recon_plot\n",
    "from Eigen_decomp import Eigen_decomp\n",
    "from YearPlotter import YearPlotter\n",
    "import numpy as np\n",
    "from ipywidgets import interactive,widgets\n",
    "#from recon_plot import recon_plot\n",
    "plotter=recon_plot(eigen_decomp,year_axis=True)#,interactive=True,Title='something')\n",
    "widge_list,widge_dict = plotter.get_widgets()\n",
    "interactive(plotter.plot_combination, **widge_dict)\n",
    "widgets.VBox([widgets.HBox(widge_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Process whole dataframe to find best and worse residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Query=\"SELECT * FROM weather\\n\\tWHERE measurement='%s'\"%(m)\n",
    "print Query\n",
    "df1 = sqlContext.sql(Query)\n",
    "print df1.count(),'rows'\n",
    "df1.show(2)\n",
    "rows=df1.rdd.map(lambda row:unpackArray(row['vector'],np.float16)).collect()\n",
    "T=np.vstack(rows)\n",
    "shape(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Add to each row in the dataframe a residual values \n",
    "Residuals are after subtracting in sequence: the mean, the projection on the first eigen-vector the projection on the second eigen-vector etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "`decompose(row)` axtracts the series from the row, computes the residuals and constructs a new row that is reassembled into a dataframe.\n",
    "\n",
    "A more efficient solution would be to use UDFs (user defined functions) but I could not make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def decompose(row):\n",
    "    Series=np.array(unpackArray(row.vector,np.float16),dtype=np.float64)\n",
    "    recon=Eigen_decomp(None,Series,Mean,v);\n",
    "    total_var,residuals,reductions,coeff=recon.compute_var_explained()\n",
    "    #print coeff\n",
    "    residuals=[float(r) for r in residuals[1]]\n",
    "    coeff=[float(r) for r in coeff[1]]\n",
    "    D=row.asDict()\n",
    "    D['total_var']=float(total_var[1])\n",
    "    D['res_mean']=residuals[0]\n",
    "    for i in range(1,len(residuals)):\n",
    "        D['res_'+str(i)]=residuals[i]\n",
    "        D['coeff_'+str(i)]=coeff[i-1]\n",
    "    return Row(**D)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import numpy\n",
    "rdd2=df1.rdd.map(decompose)\n",
    "df2=sqlContext.createDataFrame(rdd2)\n",
    "df2.select('res_mean','res_1','res_2','res_3','total_var','coeff_1','coeff_2','coeff_3').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_decomp(row,Mean,v,fig=None,ax=None,Title=None):\n",
    "    target=np.array(unpackArray(row.vector,np.float16),dtype=np.float64)\n",
    "    eigen_decomp=Eigen_decomp(None,target,Mean,v)\n",
    "    recon_plot(eigen_decomp,year_axis=True,fig=fig,ax=ax,interactive=False,Title=Title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row=df2.first()\n",
    "plot_decomp(row,Mean,v,Title='title44')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print 'before filter',df2.count()\n",
    "df3=df2.filter(df2.total_var!=0)\n",
    "print 'after filter',df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_recon_grid(rows,column_n=4, row_n=3, figsize=(15,10)):\n",
    "    fig,axes=plt.subplots(row_n,column_n, sharex='col', sharey='row',figsize=figsize);\n",
    "    k=0\n",
    "    for i in range(row_n):\n",
    "        for j in range(column_n):\n",
    "            row=rows[k]\n",
    "            k+=1\n",
    "            plot_decomp(row,Mean,v,fig=fig,ax=axes[i,j],Title=str(row['res_3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3=df3.sort(df3.res_3,ascending=True)\n",
    "rows=df3.take(12)\n",
    "plot_recon_grid(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3=df3.sort(df3.res_3,ascending=False)\n",
    "rows=df3.take(12)\n",
    "plot_recon_grid(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res3=df3.select('res_3').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R3=[r['res_3'] for r in res3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(R3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(R3[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row=rows[0]\n",
    "Series=np.array(unpackArray(row.vector,np.float16),dtype=np.float64)\n",
    "recon=Eigen_decomp(None,Series,Mean,v);\n",
    "recon.compute_var_explained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df3.count(),\n",
    "df4=df3.filter(df3.res_3<0.5)\n",
    "print '->',df4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c=df4.select('coeff_1').collect()\n",
    "c1=[x['coeff_1'] for x in c]\n",
    "c=df4.select('coeff_2').collect()\n",
    "c2=[x['coeff_2'] for x in c]\n",
    "c1[:4],c2[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(8,8))\n",
    "scatter(c1,c2,marker='.')\n",
    "xlabel('coeff 1')\n",
    "ylabel('coeff 2')\n",
    "grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType,NumericType,DataType,FloatType,DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=3\n",
    "m='SNWD'\n",
    "EigVec=np.matrix(STAT[m]['eigvec'][:,:k])\n",
    "v=[np.array(EigVec[:,i]).flatten() for i in range(shape(EigVec)[1])]\n",
    "Mean=STAT[m]['Mean']\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "YearPlotter().plot(EigVec,fig,ax,title='snow depth',labels=['eig'+str(i+1) for i in range(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive,widgets\n",
    "from recon_plot import recon_plot\n",
    "\n",
    "rows=df3.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row=rows[2]\n",
    "target=np.array(unpackArray(row.vector,np.float16),dtype=np.float64)\n",
    "eigen_decomp=Eigen_decomp(None,target,Mean,v)\n",
    "plotter=recon_plot(eigen_decomp,year_axis=True)\n",
    "widge_list,widge_dict = plotter.get_widgets()\n",
    "interactive(plotter.plot_combination, **widge_dict)\n",
    "widgets.VBox([widgets.HBox(widge_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for m in ['TMIN', 'TOBS', 'TMAX', 'SNOW', 'SNWD', 'PRCP']:\n",
    "    print 'Reconstruction Plots for '+ m\n",
    "    create_reconstructions(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "118px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
