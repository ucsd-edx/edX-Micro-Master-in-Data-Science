{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataframes \n",
    "* Dataframes are a special type of RDDs. \n",
    "* Dataframes store two dimensional data, similar to the type of data stored in a spreadsheet. \n",
    "   * Each column in a dataframe can have a different type.\n",
    "   * Each row contains a `record`.\n",
    "* Similar to, but not the same as, [pandas dataframes](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) and [R dataframes](http://www.r-tutor.com/r-introduction/data-frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master=\"local[4]\")\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x104741a58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just like using Spark requires having a SparkContext, using SQL requires an SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Constructing a DataFrame from an RDD of Rows\n",
    "Each Row defines it's own  fields, the schema is *inferred*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=19, name='John'),\n",
       " Row(age=23, name='Smith'),\n",
       " Row(age=18, name='Sarah')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One way to create a DataFrame is to first define an RDD from a list of rows\n",
    "some_rdd = sc.parallelize([Row(name=u\"John\", age=19),\n",
    "                           Row(name=u\"Smith\", age=23),\n",
    "                           Row(name=u\"Sarah\", age=18)])\n",
    "some_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The DataFrame is created from the RDD or Rows\n",
    "# Infer schema from the first row, create a DataFrame and print the schema\n",
    "some_df = sqlContext.createDataFrame(some_rdd)\n",
    "some_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'> <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "some_df = [Row(age=19, name='John'), Row(age=23, name='Smith'), Row(age=18, name='Sarah')]\n",
      "some_rdd= [Row(age=19, name='John'), Row(age=23, name='Smith'), Row(age=18, name='Sarah')]\n"
     ]
    }
   ],
   "source": [
    "# A dataframe is an RDD of rows plus information on the schema.\n",
    "# performing **collect()* on either the RDD or the DataFrame gives the same result.\n",
    "print(type(some_rdd),type(some_df))\n",
    "print('some_df =',some_df.collect())\n",
    "print('some_rdd=',some_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Defining the Schema explicitly\n",
    "The advantage of creating a DataFrame using a pre-defined schema allows the content of the RDD to be simple tuples, rather than rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person_name: string (nullable = false)\n",
      " |-- person_age: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this case we create the dataframe from an RDD of tuples (rather than Rows) and provide the schema explicitly\n",
    "another_rdd = sc.parallelize([(\"John\", 19), (\"Smith\", 23), (\"Sarah\", 18)])\n",
    "# Schema with two fields - person_name and person_age\n",
    "schema = StructType([StructField(\"person_name\", StringType(), False),\n",
    "                     StructField(\"person_age\", IntegerType(), False)])\n",
    "\n",
    "# Create a DataFrame by applying the schema to the RDD and print the schema\n",
    "another_df = sqlContext.createDataFrame(another_rdd, schema)\n",
    "another_df.printSchema()\n",
    "# root\n",
    "#  |-- age: binteger (nullable = true)\n",
    "#  |-- name: string (nullable = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading DataFrames from disk\n",
    "There are many maethods to load DataFrames from Disk. Here we will discuss three of these methods\n",
    "1. JSON \n",
    "2. CSV\n",
    "3. Parquet\n",
    "\n",
    "In addition, there are API's for connecting Spark to an external database. We will not discuss this type of connection in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading dataframes from JSON files\n",
    "[JSON](http://www.json.org/) is a very popular readable file format for storing structured data.\n",
    "Among it's many uses are **twitter**, `javascript` communication packets, and many others. In fact this notebook file (with the extension `.ipynb` is in json format. JSON can also be used to store tabular data and can be easily loaded into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":\"Michael\"}\r\n",
      "{\"name\":\"Andy\", \"age\":30}\r\n",
      "{\"name\":\"Justin\", \"age\":19}\r\n"
     ]
    }
   ],
   "source": [
    "# when loading json files you can specify either a single file or a directory containing many json files.\n",
    "path = \"../../Data/people.json\"\n",
    "!cat $path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people is a <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the file(s) pointed to by path\n",
    "people = sqlContext.read.json(path)\n",
    "print('people is a',type(people))\n",
    "# The inferred schema can be visualized using the printSchema() method.\n",
    "people.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Excercise: Loading csv files into dataframes\n",
    "\n",
    "Spark 2.0 includes a facility for reading csv files. In this excercise you are to create similar functionality using your own code.\n",
    "\n",
    "You are to write a class called `csv_reader` which has the following methods:\n",
    "\n",
    "* `__init__(self,filepath):` recieves as input the path to a csv file. It throws an exeption `NoSuchFile` if the file does not exist.\n",
    "* `Infer_Schema()` opens the file, reads the first 10 lines (or less if the file is shorter), and infers the schema. The first line of the csv file defines the column names. The following lines should have the same number of columns and all of the elements of the column should be of the same type. The only types allowd are `int`,`float`,`string`. The method infers the types of the columns, checks that they are consistent, and defines a dataframe schema of the form:\n",
    "```python\n",
    "schema = StructType([StructField(\"person_name\", StringType(), False),\n",
    "                     StructField(\"person_age\", IntegerType(), False)])\n",
    "```\n",
    "If everything checks out, the method defines a `self.` variable that stores the schema and returns the schema as it's output. If an error is found an exception `BadCsvFormat` is raised.\n",
    "* `read_DataFrame()`: reads the file, parses it and creates a dataframe using the inferred schema. If one of the lines beyond the first 10 (i.e. a line that was not read by `InferSchema`) is not parsed correctly, the line is not added to the Dataframe. Instead, it is added to an RDD called `bad_lines`.\n",
    "The methods returns the dateFrame and the `bad_lines` RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parquet files\n",
    "[Parquet](http://parquet.apache.org/) is a columnar format that is supported by many other data processing systems. Spark SQL provides support for both reading and writing Parquet files that automatically preserves the schema of the original data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### More about Parquet\n",
    "Parquet is a column-based file format and uses disk-resident data structure that support efficient access to subsets of the records. As a result, loading a subset of the records from a Parquet file is much more efficient than loading the same subset of records from a csv or json file. In addition, parquet is compatible with HDFS which further accelerates record retrieval in a distributed system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby-Dick.txt   \u001b[35mOldData\u001b[m\u001b[m         kmeans_data.txt people.json     users.parquet\r\n"
     ]
    }
   ],
   "source": [
    "dir='../../Data'\n",
    "parquet_file=dir+\"/users.parquet\"\n",
    "!ls $dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Data/users.parquet\n",
      "+------+--------------+----------------+\n",
      "|  name|favorite_color|favorite_numbers|\n",
      "+------+--------------+----------------+\n",
      "|Alyssa|          null|  [3, 9, 15, 20]|\n",
      "|   Ben|           red|              []|\n",
      "+------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load a Parquet file\n",
    "print(parquet_file)\n",
    "df = sqlContext.read.load(parquet_file)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|  name|favorite_color|\n",
      "+------+--------------+\n",
      "|Alyssa|          null|\n",
      "|   Ben|           red|\n",
      "+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=df.select(\"name\", \"favorite_color\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x  6 yoavfreund  staff  192 Feb 12 19:01 \u001b[34m../../Data/namesAndFavColors.parquet\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "outfilename=\"namesAndFavColors.parquet\"\n",
    "!rm -rf $dir/$outfilename\n",
    "df2.write.save(dir+\"/\"+outfilename)\n",
    "!ls -ld $dir/$outfilename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A new interface object has been added in **Spark 2.0** called **SparkSession**. A spark session is initialized using a `builder`. For example\n",
    "```python\n",
    "spark = SparkSession.builder \\\n",
    "         .master(\"local\") \\\n",
    "         .appName(\"Word Count\") \\\n",
    "         .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "         .getOrCreate()\n",
    "```\n",
    "\n",
    "Using a SparkSession a Parquet file is read [as follows:](http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.parquet):\n",
    "```python\n",
    "df = spark.read.parquet('python/test_support/sql/parquet_partitioned')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading a dataframe from a pickle file\n",
    "Here we are loading a dataframe from a pickle file stored on S3. The pickle file contains meterological data that we will work on in future classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making /Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/Data/Weather\n"
     ]
    }
   ],
   "source": [
    "from os.path import split,join,exists\n",
    "from os import mkdir,getcwd,remove\n",
    "from glob import glob\n",
    "\n",
    "# create directory if needed\n",
    "\n",
    "notebook_dir=getcwd()\n",
    "data_dir=join(split(split(notebook_dir)[0])[0],'Data')\n",
    "weather_dir=join(data_dir,'Weather')\n",
    "\n",
    "if exists(weather_dir):\n",
    "    print('directory',weather_dir,'already exists')\n",
    "else:\n",
    "    print('making',weather_dir)\n",
    "    mkdir(weather_dir)\n",
    "\n",
    "file_index='BBSSBBSS'\n",
    "zip_file='US_Weather_%s.csv.gz'%file_index #the .csv extension is a mistake, this is a pickle file, not a csv file.\n",
    "old_files='%s/%s*'%(data_dir,zip_file[:-3])\n",
    "for f in glob(old_files):\n",
    "    print('removing',f)\n",
    "    remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl https://mas-dse-open.s3.amazonaws.com/Weather/small/US_Weather_BBSSBBSS.csv.gz > /Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/Data/US_Weather_BBSSBBSS.csv.gz\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3350k  100 3350k    0     0  1675k      0  0:00:02  0:00:02 --:--:-- 1595k\n",
      "-rw-r--r--  1 yoavfreund  staff   3.3M Feb 12 20:16 /Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/Data/US_Weather_BBSSBBSS.csv.gz\n"
     ]
    }
   ],
   "source": [
    "command=\"curl https://mas-dse-open.s3.amazonaws.com/Weather/small/%s > %s/%s\"%(zip_file,data_dir,zip_file)\n",
    "print(command)\n",
    "!$command\n",
    "!ls -lh $data_dir/$zip_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 yoavfreund  staff    12M Feb 12 20:16 /Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/Data/US_Weather_BBSSBBSS.csv\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12373"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!gunzip --keep $data_dir/$zip_file\n",
    "filename='%s/US_Weather_%s.csv'%(data_dir,file_index)\n",
    "!ls -lh $filename\n",
    "import pickle\n",
    "List=pickle.load(open(filename,'rb'))\n",
    "len(List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12373\n",
      "+---------+--------+---------+-----------+-----------+------+--------------------+------+--------+\n",
      "|elevation|latitude|longitude|measurement|    station|undefs|              vector|  year|   label|\n",
      "+---------+--------+---------+-----------+-----------+------+--------------------+------+--------+\n",
      "|    181.4| 41.0092| -87.8242|       PRCP|USC00111458|     8|[00 00 00 00 00 0...|1991.0|BBSSBBSS|\n",
      "+---------+--------+---------+-----------+-----------+------+--------------------+------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#List is a list of Rows. Stored as a pickle file.\n",
    "df=sqlContext.createDataFrame(List)\n",
    "print(df.count())\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-----------+\n",
      "|    station|  year|measurement|\n",
      "+-----------+------+-----------+\n",
      "|USC00111458|1991.0|       PRCP|\n",
      "|USC00111458|1994.0|       PRCP|\n",
      "|USC00111458|1995.0|       PRCP|\n",
      "|USC00111458|1996.0|       PRCP|\n",
      "|USC00111458|1997.0|       PRCP|\n",
      "+-----------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#selecting a subset of the rows so it fits in slide.\n",
    "df.select('station','year','measurement').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "### Save dataframe as Parquet repository\n",
    "filename='%s/US_Weather_%s.parquet'%(data_dir,file_index)\n",
    "!rm -rf $filename\n",
    "df.write.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Parquet repositories are usually directories with many files.\n",
    "* Parquet uses its column based format to compress the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2M\t/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/Data/US_Weather_BBSSBBSS.parquet\n",
      "4.1M\t/Users/yoavfreund/projects/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/Data/US_Weather_BBSSBBSS.csv.gz\n"
     ]
    }
   ],
   "source": [
    "!du -sh $filename\n",
    "!du -sh $data_dir/$zip_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataframe operations\n",
    "Spark DataFrames allow operations similar to pandas Dataframes. We demonstrate some of those.\n",
    "For more, see [this article](https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----------+\n",
      "|    station|         elevation|measurement|\n",
      "+-----------+------------------+-----------+\n",
      "|      12373|             12373|      12373|\n",
      "|       null|205.64884021660063|       null|\n",
      "|       null|170.84234175167742|       null|\n",
      "|US1ILCK0069|            -999.9|       PRCP|\n",
      "|USW00014829|             305.1|       TOBS|\n",
      "+-----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().select('station','elevation','measurement').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+--------------+\n",
      "|measurement|min(year)|count(station)|\n",
      "+-----------+---------+--------------+\n",
      "|       TMIN|   1893.0|          1859|\n",
      "|       TOBS|   1901.0|          1623|\n",
      "|       TMAX|   1893.0|          1857|\n",
      "|       SNOW|   1895.0|          2178|\n",
      "|       SNWD|   1902.0|          1858|\n",
      "|       PRCP|   1893.0|          2998|\n",
      "+-----------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('measurement').agg({'year': 'min', 'station':'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# THis command will load the python module that defines the SQL functions\n",
    "#%load ls ~/spark-latest/python/pyspark/sql/functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using SQL queries on DataFrames\n",
    "\n",
    "There are two main ways to manipulate  DataFrames:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Imperative manipulation\n",
    "Using python methods such as `.select` and `.groupby`.\n",
    "* Advantage: order of operations is specified.\n",
    "* Disrdavantage : You need to describe both **what** is the result you want and **how** to get it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Declarative Manipulation (SQL)\n",
    "* Advantage: You need to describe only **what** is the result you want.\n",
    "* Disadvantage: SQL does not have primitives for common analysis operations such as **covariance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Spark supports a [subset](https://spark.apache.org/docs/latest/sql-programming-guide.html#supported-hive-features) of the Hive SQL query language.\n",
    "\n",
    "For example, You can use [Hive `select` syntax](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select) to select a subset of the rows in a dataframe.\n",
    "\n",
    "To use sql on a dataframe you need to first `register` it as a `TempTable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justin\n"
     ]
    }
   ],
   "source": [
    "# Register this DataFrame as a table.\n",
    "people.registerTempTable(\"people\")\n",
    "\n",
    "# SQL statements can be run by using the sql methods provided by sqlContext\n",
    "teenagers = sqlContext.sql(\"SELECT name FROM people WHERE age >= 13 AND age <= 19\")\n",
    "for each in teenagers.collect():\n",
    "    print(each[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Counting the number of occurances of each measurement, imparatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TOBS', 1623),\n",
       " ('TMAX', 1857),\n",
       " ('SNWD', 1858),\n",
       " ('TMIN', 1859),\n",
       " ('SNOW', 2178),\n",
       " ('PRCP', 2998)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L=df.groupBy('measurement').count().collect()\n",
    "D=[(e.measurement,e['count']) for e in L]\n",
    "sorted(D,key=lambda x:x[1], reverse=False)[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Counting the number of occurances of each measurement, declaratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT measurement,COUNT(measurement) AS count FROM weather GROUP BY measurement ORDER BY count\n",
      "+-----------+-----+\n",
      "|measurement|count|\n",
      "+-----------+-----+\n",
      "|       TOBS| 1623|\n",
      "|       TMAX| 1857|\n",
      "|       SNWD| 1858|\n",
      "|       TMIN| 1859|\n",
      "|       SNOW| 2178|\n",
      "|       PRCP| 2998|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.registerDataFrameAsTable(df,'weather') #using older sqlContext instead of newer (V2.0) sparkSession\n",
    "query='SELECT measurement,COUNT(measurement) AS count FROM weather GROUP BY measurement ORDER BY count'\n",
    "print(query)\n",
    "sqlContext.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Performing a map command\n",
    "In order to perform map, you need to first transform the dataframe into an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-87.8242, 41.0092),\n",
       " (-87.8242, 41.0092),\n",
       " (-87.8242, 41.0092),\n",
       " (-87.8242, 41.0092),\n",
       " (-87.8242, 41.0092)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.map(lambda row:(row.longitude,row.latitude)).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Approximately counting the number of distinct elements in column\n",
    "\n",
    "**Aggregation** can be used to compute statistics of a dataframe\n",
    "\n",
    "* `count()`, countDistinct(), avg(), max(), min()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'max(year)'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.max(df.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------------+\n",
      "|min(year)|approx_count_distinct(station)|\n",
      "+---------+------------------------------+\n",
      "|   1893.0|                           213|\n",
      "+---------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "F.max(df.year)\n",
    "#F.approx_count_distinct?\n",
    "df.agg({'station':'approx_count_distinct','year':'min'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Approximate Quantile\n",
    "The method `.approxQuantile` computes the approximate quantiles.\n",
    "\n",
    "Recall that this is how we computed the pivots for the distributed bucket sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with accuracy 0.1:  [1893.0, 1951.0, 1958.0, 1967.0, 1979.0, 1979.0, 1993.0, 2003.0, 2012.0]\n",
      "with accuracy 0.01:  [1928.0, 1946.0, 1956.0, 1964.0, 1974.0, 1983.0, 1993.0, 2000.0, 2008.0]\n"
     ]
    }
   ],
   "source": [
    "print('with accuracy 0.1: ',df.approxQuantile('year', [0.1*i for i in range(1,10)], 0.1))\n",
    "print('with accuracy 0.01: ',df.approxQuantile('year', [0.1*i for i in range(1,10)], 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Lets collect the exact number of rows for each year\n",
    "This will take much longer than ApproxQuantile on a large file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT year,COUNT(year) AS count FROM weather GROUP BY year ORDER BY year\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets collect the exact number of rows for each year ()\n",
    "query='SELECT year,COUNT(year) AS count FROM weather GROUP BY year ORDER BY year'\n",
    "print(query)\n",
    "counts=sqlContext.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1893.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1894.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1895.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1897.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  count\n",
       "0  1893.0      4\n",
       "1  1894.0      9\n",
       "2  1895.0     12\n",
       "3  1896.0     12\n",
       "4  1897.0     15"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=counts.toPandas()\n",
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd81EX++PHXpFdSSQip9N6LNBXE\niueB7cSCnHiiZ73ytd797s47PU+989RTT1GwHCr23kEC0nsLCISQBiG9beomO78/9pOYQMom2exu\nNu/n47GPbOYzn9mZfOCdyXzmM6O01gghhHBfHs6ugBBCiO4lgV4IIdycBHohhHBzEuiFEMLNSaAX\nQgg3J4FeCCHcnAR6IYRwcxLohRDCzUmgF0IIN+fl7AoAREZG6qSkJLuVV1FRQWBgoN3KczXSvp7P\n3dso7XOMnTt3Fmit+7aXzyUCfVJSEjt27LBbecnJycyePdtu5bkaaV/P5+5tlPY5hlIqw5Z8MnQj\nhBBuTgK9EEK4OQn0Qgjh5lxijL4lZrOZ7OxsqqurO3xuSEgIhw4d6oZaOYafnx9xcXF4e3s7uypC\nCDfgsoE+Ozub4OBgkpKSUEp16Nzy8nKCg4O7qWbdS2tNYWEh2dnZDBgwwNnVEUK4AZcduqmuriYi\nIqLDQb6nU0oRERHRqb9khBCiJS4b6IFeF+Qb9NZ2CyG6h0sHeiGE6E2+PnCK3DL7/zUvgd6Jnn76\naSorK51dDSGEC6g21/PrN3eyYuNxu5ctgd6JJNALIRrkldWgNWQU2D8mSKBvxxtvvMHYsWMZN24c\nixYtIiMjg7lz5zJ27Fjmzp1LZmYmAL/85S95//33G88LCgoCfnpU+qqrrmL48OFcf/31aK159tln\nOXnyJHPmzGHOnDlOaZsQwnXklVuHbDKK7B/oXXZ6ZVMPf5bCwZNlNuevr6/H09OzzTwj+/fhz5eN\najNPSkoKjz76KBs3biQyMpKioiIWL17MjTfeyOLFi1mxYgV33303H3/8cZvl7N69m5SUFPr378/M\nmTPZuHEjd999N0899RRr164lMjLS5rYJIdxTXnkNAJmFFWit7TopQ3r0bfj++++56qqrGgNxeHg4\nmzdv5rrrrgNg0aJFbNiwod1ypk6dSlxcHB4eHowfP5709PTurLYQogfKM27CVtTWU1hRa9eye0SP\nvr2e9+ns9cCULb9VG457eXlhsVgaz6ut/elC+fr6Nr739PSkrq6uy3UTQriXhh49QEZhJZFBvm3k\n7hjp0bdh7ty5vPvuuxQWFgJQVFTEjBkzWLVqFQBvvvkms2bNAqxLLe/cuROATz75BLPZ3G75wcHB\nlJeXd1PthRA9SX55DR5GvzKjsMKuZfeIHr2zjBo1ij/84Q+ce+65eHp6MmHCBJ599lmWLFnCk08+\nSd++fXn11VcBuOWWW5g/fz5Tp05l7ty5Nm1KsHTpUi655BJiYmJYu3ZtdzdHCOHC8sprGBodzOHc\ncjIK7XtDVgJ9OxYvXszixYubpX3//fdn5IuOjmbLli2N3z/22GMAzJ49u9kGBc8991zj+7vuuou7\n7rrLzjUWQvREeeU1xIb6U15dR6adZ97I0I0QQriA/PJqovr4khAeYPehGwn0QgjhZHX1Fgoraukb\n7EdiRIDde/QuPXRj77mkPYXW2tlVEEI4UIGpFq0hKtgXP28PCky1mGrqCPK1T4h22R69n58fhYWF\nvS7oNaxH7+fn5+yqCCEcpOGp2KhgX5IirBM57Dl847I9+ri4OLKzs8nPz+/wudXV1T06UDbsMCWE\n6B3yyqxz6KP6+OFlzLHMLKxkVP8Qu5TvsoHe29u70zssJScnM2HCBDvXSAghukfDw1JRwb4E+1nD\nsj3XvHHZQC+EEL1Fw9BNZJAvPl4ehAf62HUuvcuO0QshRG+RX15DeKAPPl7WkJwQHkBmkf3G6CXQ\nCyGEk+WV19C3ydo2iREBpNtxXXoJ9EII4WR55TVE9Wka6APJKa2its5il/Il0AshhJPll1XTN7hJ\noA8PwKIhu9g+vXoJ9EII4URaa/JNNUQF/zQlPCkyAIBDOfZZ3bbdQK+UildKrVVKHVJKpSil7jHS\n/6KUOqGU2mO85jU550GlVKpS6rBS6iK71FQIIdxQcaUZc70mqkmPfmxcKHFh/iz7Ic0uD43a0qOv\nA36vtR4BTAPuUEqNNI79W2s93nh9CWAcWwiMAi4GXlBKtb2vnxBC9FKNT8U2GaP39vTgjjmD2ZtV\nQvKRjj80erp2A73WOkdrvct4Xw4cAmLbOGU+sEprXaO1Pg6kAlO7XFMhhHBDjU/FBjd/mv/KiXHE\nhvrzzOqjXe7Vq44UoJRKAtYDo4HfAb8EyoAdWHv9xUqp54AtWuuVxjnLga+01u+fVtZSYClAdHT0\npIZdm+zBZDIRFBRkt/JcjbSv53P3Nkr7bLfhhJlX9tfy+Nn+RAc273snZ5l5LaWW303yZWzfM59v\nnTNnzk6t9eR2P0RrbdMLCAJ2AlcY30cDnlj/KngUWGGkPw/c0OS85cCVbZU9adIkbU9r1661a3mu\nRtrX87l7G6V9tnt+7VGdeP/nuqLGfMaxGnO9nvHYGr3g+Q3aYrGccRzYoW2I3zbNulFKeQMfAG9q\nrT80fkHkaq3rtdYW4GV+Gp7JBuKbnB4HnLTlc4QQorfJL68hyNeLAJ8ze+w+Xh7cPmcQuzNL2JxW\n2OzYU98etvkzbJl1o7D2yg9prZ9qkh7TJNvlwAHj/afAQqWUr1JqADAE2GZzjYQQohfJK69pNuPm\ndFdOjCMi0IcVG443Oaeal9an2fwZtixqNhNYBOxXSu0x0h4CrlVKjQc0kA7cCqC1TlFKvQscxDpj\n5w6tdb3NNRJCiF4kv6yGyDYCvZ+3J9dPS+Q/3x/leEEFAyIDWbYuDXO97U/N2jLrZoPWWmmtx+om\nUym11ou01mOM9J9rrXOanPOo1nqQ1nqY1vorm2sjhBC9TGFFDZFBPm3mWTQtEW8PD17deJz88hpW\nbs1gwYS2Jj82J8sUCyGEE5lq6gj29W4zT99gX34+vj/v7cim2lxPbZ2Fu84bwr9t/AxZAkEIIZyo\nvLqucbORttw8awBV5nre3ZHNgvGxDIgMtPkzJNALIYST1Fs0lbX1BNkQ6EfE9GHm4Ag8FNx53uAO\nfY4M3QghhJOYauoACPK1LRQ/dvlYjhWYGNi3Yw9rSaAXQggnKa82A9DHr+0x+gYJEQEkRAR0+HNk\n6EYIIZyksUdvw9BNV0igF0IIJymv7tjQTWdJoBdCCCcxGYHellk3XSGBXgghnKS8RgK9EEK4tYab\nscE23oztLAn0QgjhJCYZoxdCCPdmqqnDQ0GAT/futiqBXgghnKS8uo4gXy+sq8F3Hwn0QgjhJNZ1\nbrp3fB4k0AshhNOYaszdPj4PEuiFEMJpbF25sqsk0AshhJOYauq6ffkDkEAvhBBO03AztrtJoBdC\nCCeRm7FCCOHmTDVmGaMXQgh3Za63UG22ECxDN0II4Z4alz+QHr0QQrinjm4j2BUS6IUQwgnKHLRy\nJUigF0IIp3DUpiMggV4IIZzCUdsIgg2BXikVr5Raq5Q6pJRKUUrdY6SHK6W+U0odNb6GGelKKfWs\nUipVKbVPKTWxuxshhBA9jclBu0uBbT36OuD3WusRwDTgDqXUSOABYI3Wegiwxvge4BJgiPFaCvzX\n7rUWQogermEbQZeYdaO1ztFa7zLelwOHgFhgPvC6ke11YIHxfj7whrbaAoQqpWLsXnMhhOjBGrcR\n9HWxm7FKqSRgArAViNZa54D1lwEQZWSLBbKanJZtpAkhhDCYquvw8lD4eXf/rVKb/2ZQSgUBHwC/\n0VqXtbEjSksHdAvlLcU6tEN0dDTJycm2VqVdJpPJruW5Gmlfz+fubZT2te9wWg2+npp169bZp1Jt\nsCnQK6W8sQb5N7XWHxrJuUqpGK11jjE0k2ekZwPxTU6PA06eXqbWehmwDGDy5Ml69uzZnWtBC5KT\nk7Fnea5G2tfzuXsbpX3t+yR3D2HlRQ75Odky60YBy4FDWuunmhz6FFhsvF8MfNIk/UZj9s00oLRh\niEcIIYSVo1auBNt69DOBRcB+pdQeI+0h4B/Au0qpm4FM4Grj2JfAPCAVqARusmuNhRDCDZhqzA5Z\n0AxsCPRa6w20PO4OMLeF/Bq4o4v1EkIIt1ZeXUe/Pn4O+Sx5MlYIIZzAUdsIggR6IYRwCkdtIwgS\n6IUQwilMDrwZK4FeCCEcrKauntp6i0PWuQEJ9EII4XCOXLkSJNALIUS7tNYcL6igrt5il/IcuRY9\ndGAJBCGE6K2eXn2UZ9YcJcjXiylJYQzxrWN2F8pz5DaCID16IYRo03cHc3lmzVEuGBnNggn9SSuo\nYNm+Gg6fKu90mQ3bCMr0SiGEcLLUPBO/fWcPY+NC+M+1E3hkwRg+vn0mPh6wfENas7wHTpRyqrTa\npnIbhm76yKwbIYRwnmpzPbf+bwe+Xh68eMMk/Lw9AQgL9GFmrBcf7zlJgakGsP5CuOK/m/jTJwds\nKltuxgohhAv49mAux/IrePzKsfQP9W927MJEb2rrLKzckkG9RXPv+3uprbOw/mg+VbX17ZbtyG0E\nQQK9EEK06KNd2cSE+HHe8KgzjsUEeXDe8ChWbsnghbWp7M4s4ReT46g2W9iYWtBu2SYHbiMIEuiF\nEOIMBaYa1h8tYP74WDw8Wl7T8eZZAygw1fKv745w4choHlkwhmBfL747mNtu+WXVZnw8PfD18rR3\n1VskgV4IIU7z2d6T1Fs0V0xsfRfUGYMiGBHThxB/bx65fDQ+Xh6cO6wva37MxWI5Y1O9ZqzLHzhu\ndrvMoxdCiNN8tPsEo/r3YWh0cKt5lFK8vmQKNWYLUcHW5YYvGBnN5/ty2J1VwqTEsFbPLa6sJcTf\nMTNuQHr0QgjRTGqeiX3ZpVw+ofXefIOoYD/iwwMav589NAovD8XqQ20P32QUVjY7r7tJoBdCiCY+\n3n0CDwU/H9e/w+eGBHgzdUB4m+P0WmsyCytJjJBAL4QQDqe15uM9J5g1pC9Rndz96YKR0aTmmThe\nUNHi8eJKM+U1dSRGBHalqh0igV4IIQx7skrILq7qVG++wfkjogH43+aMFo+nF1p/ASTK0I0QQjje\nl/tz8PZUXDAyutNlxIcHcN1ZCby66Tg7M4rOOJ5ZWAkgQzdCCOFoWmu+3H+KWYMjuzwj5qF5I+gf\n4s+97++j2tz8SdkMI9DLzVghhHCwvdmlnCipYt6YmC6XFeTrxeNXjiUtv4J/rz7S7FhGUQX9+vg1\nrp3jCDKPXgjh1rTWbD5WyIbUArakFVJUUcvHd8wkNMCnWb6GYZsLR/azy+fOGhLJtVMTeHl9GldP\nimdwVBBgHbpJcOCwDUiPXgjhxsqqzdz51m6ue2Ury9anUVtvIb2wkm9STjXLp7Xmi305zBwcSUiA\n/R5kuuu8wVg0/HA0vzEto6iSJAn0QgjRdQdOlHLZfzbwdcop7r94OPv+ciGf3TmLhPAAvtjfPNDv\nM4ZtLrXDsE1T/UP9iQ31Z0d6MQAVNXXkl9c4dGolSKAXQrihkspaFi7bQo3Zwqql0/j17EEE+Hih\nlGLemBg2pRZQUlnbmN/ewzZNTU4KY3t6kfVBqSLrjdgEB96IBRsCvVJqhVIqTyl1oEnaX5RSJ5RS\ne4zXvCbHHlRKpSqlDiulLuquigshRGs+3HUCU00dryyezJSk8GbHLh0TQ51F822K9enV0koz7+7I\n4tyhfe06bNNgclI4eeU1ZBVVNc64ceTUSrCtR/8acHEL6f/WWo83Xl8CKKVGAguBUcY5LyilHHdr\nWQg3c7Kkitwy27anE1Zaa97elsm4+FBGx4accXx0bB/iw/35Yn8OAM9+f5SSKjO/u2BYt9RnSpJ1\ncbPt6UVkFjU8LOViQzda6/XAmbP+WzYfWKW1rtFaHwdSgaldqJ8QvdpNr27nvH8m88meE41pR3LL\neezLQ6zckkFqngmt214St7fZmVHM0TwT102Nb/F4w/DNxtQCdmUW8/qmdBZOiWdk/z7dUp+hUcEE\n+3mxI6OIjMJKQvy9u+Uvh7Z0ZXrlnUqpG4EdwO+11sVALLClSZ5sI00I0UE5pVUczi0nxN+be1bt\nYfOxQspr6vhyfw4KaFjyfGBkIO/dNp2IIF+n1tdVvLUtkyBfLy5rYxmDS8fE8NK6NG5+bTt+3p7d\n1psH8PBQTE4MY3t6MTEhfg6fcQOdD/T/Bf4GaOPrv4AlQEtbsbTY3VBKLQWWAkRHR5OcnNzJqpzJ\nZDLZtTxXI+3r+Wxp44YTZgB+O96Tbadg1fYs/DzhZwO8uSjJmwqzZn9BPSsPVfD4u+uYN9CnzfIc\nyVnXsMKs+WxPJWfHerFt04ZW82mtifRXFFSauXqoNyk7N3foczravghLLWvzzJwqNjEqwtPxPxut\ndbsvIAk40N4x4EHgwSbHvgGmt1f+pEmTtD2tXbvWruW5Gmlfz2dLG+95e5ee9LdvdX29RWutdcqJ\nUl1kqjkj39UvbtLnPvF9Yz5X4KxruGJDmk68/3N94ERJu3n/m5yq5z2zXlfV1nX4czravq1phTrx\n/s914v2f6ye//rHDn9caYIe2IYZ3anqlUqrpZNPLgYYZOZ8CC5VSvkqpAcAQYFtnPkOI3kxrzYbU\nQmYMimzcs3Rk/z6EBZ7Za79uagLphZVsSSt0dDVdys6MIl5IPsbYuBBG9T/zJuzpbjt3EF/cfbZD\nliIYGxeCj6c13Dr6qViwbXrl28BmYJhSKlspdTPwhFJqv1JqHzAH+C2A1joFeBc4CHwN3KG1rm+l\naCFEK47kmigw1TBrcGS7eS8e3Y8Qf2/e2pbpgJq5HotF89K6Y/zipS34e3vyxFVjnV2lM/h5ezIm\nzvrLx5HLEzdod4xea31tC8nL28j/KPBoVyolhDs7XlBBXTubR29ILQBg5pD2A72ftydXTozjf1vS\nKTTV9Lqbsk99d4Tn1qZyyeh+PH7VWPr4OXZGi60mJ4WxM6OYpEjHTq0EeTJWCIcqMNVw4b/X8eLe\nmjanRW5MLWBAZCCxof42lXvt1HjM9ZoPdmW3msdi0by68Th55e41L//TvSc5Z2hfXrh+ossGeYCb\nZw3gyavGEt3Jnau6QgK9EA606Vgh5nrNjtx6Xlqf1mIec72FLWmFzBwcYXO5Q6KDmZIUxptbM6mt\ns7SYZ82PeTz82UFeTG75c3uizMJKMosqmTs8CqVamvTnOqKC/bh6cstz+7ubBHohHGjj0QL6+Hkx\npZ8nT3z9I+uP5J+RZ09WCZW19TaNzzf169mDyCis5Pm1qS0ef+UHa4D/dO9J6upb/mXQ02w8Zgxx\ndfBn1dvIevRCOIh1Jk0BMwZFcnlMGeV4csdbuxgfH9os38mSKpSC6QM7FrzOGx7N5RNieX5tKheO\nim428+TAiVK2Hi/irAHhbD1exIbUAmYPi7JLu5xpQ2oB/fr4Maiv48e9exLp0QvhIBmFlZwoqWLm\nkEh8vRTLFk1mUmIYFTV1zV4h/t78ataATj0m/+fLRhIW6MP/vbcPc5Ne+/INxwn08eT56ycS4u/N\nR7tPtFFKz2CxaDalFjBzcKTLD9s4m/ToRa+0fMNxZg6OYHi/7lnfpCUNM2lmDY4k48BxEiICeO0m\n+y4FFRrgw98vH8Mtb+zg4c9SePCSEZRX1/HZ3pMsmp5IZJAvl46N4cNd2Zhq6gjy9SLlZClb0opY\nMjOpRwXMgzllFFeamTXE9nsZvZUEetHrlFeb+dvnB0mKCOCre87B36ftB2Yqa+vwUKrdB2vq6i08\nvfoo3x48xdi4UKYPjGDO8CjCjYecNqYWEBvqT1JEABl2a82ZLhgZzY3TE3ljcwZf7j/FkKggLFpz\n04wBAFwxIZa3tmbyzYFTDI4K4oblWymvrmNETDAzBvWcse6NDVNQe1CdnUWGbkSvk1VUBUB6YSX/\n/PZwm3m11lz38lYufno9pZXmVvOdKq3mupe38tzaVIL9vFl9KJffv7eXS55ZT15ZNfUWzaZj1pk0\njug1/3X+aD749QxGx4aw9XgRF43q1/hE5qTEMOLD/Vm2Po0blm8lNMCbiEAfVmw43u31sqcNqQUM\njQ4iygnTFXsaCfSi18kqtm7+MDkxjBUbj7MjvfVVuFcfymNPVgnphZXc885u6lt40Ol4QQXznv2B\nAydLefqa8Xzw6xns+uMFrFo6jbKqOm5/cxd7sooprTI7dHbIpMQw3lgylW9/ew6PN3laVCnF5eNj\nOZxbTmiAN6uWTueGaYmsPpRHWr6pQ59haefBr+5Sba5ne3qRzLaxkQR60etkGdu5/fua8cSG+nPv\n+/s4klt+xgNMWmueXn2ExIgA/jp/FMmH8/n3d0fOKO+/yalU1tbx6Z0zWTDBuiq3h4di2sAInrhq\nLDsyirn9zV0AThkaGRodfMaDRIumJ3HDtARWLZ1ObKg/N0xLxMfTg1c3pttc7uf7TjLur9+2+ZdO\nd9mVWUy12dLhKai9lQR60etkF1cR6ONJXJg/T1w5lqyiSi7893omP7Ka36zazalS65Ojaw7lkXKy\njDvnDGbRtEQWTonnubWpfJPy08bS+eU1fLz7JFdNimNwVPAZn3XZuP7ces5AcstqGN4vmL7BrrE8\nQd9gXx5ZMKbxydu+wb7MH9+f93dmN9tLtS3vbM+ivLqOnZm27ktkPzuNzbanDghvJ6cACfSiF8oq\nqiQ+PAClFDMGR7Luvjk8ceVYzh3al29Scrn02R9YdySfp9dYe/OXT4hFKcXD80cxJjaEBz/cT6Gp\nBoCVWzKorbdw08wBrX7evRcN4+pJcdw0M8lBLeycm88eQJW5vsXF0VLzTM2maxZV1LLpmHW1zF0Z\nJc3yPvDBPt44WNOtdT2WbyI21J9gF17ywJVIoBe9TlZxJXFhP60gGBvqzy+mxPPUNeP57K6ZRAT5\nsHjFNg6cKOOOOYPxMpaX9fXy5J9Xj8NUXcefPk2h2lzPyi0ZnDc8ikF9g1r9PC9PD568ehzXTEno\n9rZ1xfB+fTh7SCT//OYwv31nD8fyTWw7XsR1L2/h/KfW8fhXPzbm/TblFPUWTYi/N7syixvTq831\nfLj7BGsz6zh8qrzb6nosv4KB8pCUzSTQi15Fa012cRXx4S0vFjY4KphP7pjFtVMTmDYwnMsnNN8J\nc1i/YO45fwhf7MvhnlW7Kayo5VezWu/N9zT/uXYCt5w9kK8PnOL8p9bxi5c2cyTXxLj4UP63JaNx\nQbQv9ueQEB7Az8f1Z29WSeNN6p0ZxdTWWdBYN93uDlpr0vJNbf5yFc3JPHrRqxRV1FJZW9+sR386\nfx9PHrtiTKvHbz3HGgi/SclleL9gpg9ynwd2QgN8eHDeCG45ZyArt2QQ4u/NwikJ5JZVM/epdSxb\nl8Ydcwaz6Vght5w9kGH9gvjflgyO5JYzIqYPG1IL8PJQzIn35Mv9ORzJLWdo9Jn3Lroir7yGitp6\n6dF3gPToRa+SVWydQx8fZtvyvy2xDsWMJTLIh9+cP6RHPU1qq8ggX35z/lBumjkAfx9PkiIDmT++\nPyu3ZvDWtkzqLZpLx8QwMSEMoHH4ZmNqARMTwpg/yIcAb0+eXXNmr/7AiVJ+986eDk/lbHAsz3re\nwEjp0dtKAr3oVRqmVsZ3cZef4f36sO2h87l4dEz7md3EXecNobbOwr++PUx8uD+jY/uQEB5ARKAP\nuzNLKKmsZf+JUmYOjiTIR7F4RhJf7M/hx1NljWXszy7lupe38OHuE1z2nw18uvdkh+txrKACgEFR\n0qO3lQR60as0PCzV1UAPNO7l2lsMiAxkwYRYLBrmjYlBKYVSigkJoezKLGbzsUK0pnHtmV+dPZAg\nXy8uf34Tf//yEOuP5HPD8q0E+3nz3m3TGR7Th7vf3s1fPk1pcxOW06Xlmwjw8aSfPBFrMwn0olfJ\nKqoiLMCbIF+5PdUZv5k7lHFxIfyiyQYaExLCSMuv4PP9OQT5ejE2zrrscnigD5/eOYtLRvfjlR/S\nuHHFNoJ8vVi1dBpTksJZtXQai6Yl8tqmdJIPn7kuf2vS8isYEBnolkNm3UX+tYteJbu40i69+d4q\nISKAT+6c1SytYZz+y/05zB0ehbfnT/3HAZGBPHXNeO44bzAf7TrBNVPiG3/+3p4e/L+fjWRDagF/\n++Igs4ZENju3NcfyTUwwPlPYRnr0olfJKqokvo0ZN6LjxsWH4KFA69Z3ehrUN4j/u2jYGb9kfbw8\n+MO8EaTlV7ByS/trelab6zlRUiUbjXSQBHrRa9RbNCdKqohrZQ696JwAH6/Gdf07s/bM3BFRzBoc\nydOrj7a7/EJ6YQVaw0CZQ98hEuhFr5FbVo25XkuPvhucO6wvAyMDGRzV8QCslOKPPxtBebWZp1e3\n/ZBVWr51xs3ASOnRd4QEetFr2GtqpTjT/104jC/vObvTN0iH9+vDLybH89bWTHJKq1rN1ziHXoZu\nOkQCveg17PGwlGiZp0f7O3C1587zBmPRmv8mH2tMq6u38MbmdE6WWK9dWkEF/UP8CPCReSQdIYFe\n9BrZxZUoBbES6F1SXFgAV0+OY9W2rMZe/ZPfHuZPn6Sw5LXtVNbWkZZvkvH5Tmg30CulViil8pRS\nB5qkhSulvlNKHTW+hhnpSin1rFIqVSm1Tyk1sTsrL0RHZBVVER3sh69X13qeovvcPtvaq38x+Rif\n7zvJS+vSmDU4kiO55dz3/j7SZNXKTrGlR/8acPFpaQ8Aa7TWQ4A1xvcAlwBDjNdS4L/2qaYQXZdV\nXNnqqpXCNcSHB3DVpDje3pbFve/tY1JiGCt+OYV7LxrO5/tyKK+pkxuxndBuoNdarwdO30JmPvC6\n8f51YEGT9De01RYgVCnVexYDES7LVFPHnqwSRvUPcXZVRDvumGPt1Qf7efHf6yfi4+XBbecOZN6Y\nfgAM6sTMnt6us3c0orXWOQBa6xylVJSRHgtkNcmXbaTldL6KQnTdmkO51NZZuGR0P2dXRbQjPjyA\n15dMpX+oP1HGejZKKf559ThmD41i+kD3WRbaUex967qluVUtrlaklFqKdXiH6OhokpOT7VYJk8lk\n1/JcjbSv497YXU2or6IiYx+0BaZxAAAWtUlEQVTJmc5fI0WuYfsysuH0Z2WjgA0/HGspu0P1tOvX\n2UCfq5SKMXrzMUCekZ4NxDfJFwe0uA6p1noZsAxg8uTJevbs2Z2sypmSk5OxZ3muRtrXMRU1dRxY\n/R0LpyRw3pzRdiu3K+Qa9mw9rX2dnV75KbDYeL8Y+KRJ+o3G7JtpQGnDEI8QzrLmxzxq6izMGyO3\ni0Tv1G6PXin1NjAbiFRKZQN/Bv4BvKuUuhnIBK42sn8JzANSgUrgpm6osxAd8uW+HPoG+zI5KdzZ\nVRHCKdoN9Frra1s5NLeFvBq4o6uVEqI1uWXVvLoxncmJYZw/MroxPa+smheSj7FoemKzTaMraupY\neziPa6bE49nLNgoRooE8Ryx6hPzyGp5fm8pb2zKprbPg6+XB+7fNYExcCLV1Fm5buZNdmSW8uyOL\nx64Yw/zxsQB8feCUDNuIXk8CvXB5ZdVmrnlpMxlFlVw1MY5rz0rg9pU7uW3lTj69cyZPfXeEXZkl\nPPzzUXy+7yT3rNrDuzuyyCisJLu4ithQf6bIsI3oxSTQC5dmsWh+u2oPmUWVvPmrs5hmzKF+adFk\nrnxxEwte2EhWURW3nTuIxTOSuP6sBJ767gif7DnJmNgQfjVrABeN7ifDNqJXk0AvXNoza46y5sc8\n/jp/VGOQBxgTF8Jjl4/h9+/t5ewhkdx70TAAvDw9uO/i4dx38XBnVVkIlyOBXris7w7m8syao1w1\nKY5F0xLPOH7lpDiSIgMYEdNHeuxCtEECvXBJqXkmfvvOHsbEhvDIgtGtbmgxKVHG3oVoj6xHL1xO\nVZ3m1v/twNfLg5cWTeryhhZC9HbSoxcuxWLRvLyvhvRCCytvPov+obKssBBdJT164VJWbc9iV149\nD80bwfRBskqhEPYggV64jLJqM//69jDDwjxYMjPJ2dURwm1IoBcu4/nvUymqrOXa4T6t3nwVQnSc\nBHrhEtILKlix8ThXTYwjKURuvgphTxLohdNVm+t55ItDeHt6ND74JISwH5l1I5zm3e1ZfLg7m12Z\nJdTWWbj3omFE9fHjoLMrJoSbkUAvnOLAiVLu+2Afg6OCuHFaIjMGRzBnWFT7JwohOkwCvXCKZ9cc\nJdjPiw9+PYMQf29nV0cItyZj9MLhUk6W8u3BXJbMHCBBXggHkEAvuuxobjmVtXU252/ozS+ZNaAb\nayWEaCCBXnTJrsxiLnp6PQuXbaG0ytxu/oMny/gmJZebpDcvhMNIoBctyiqqpK7e0maeanM99763\nl/BAHw7llLFo+dZ2g/1za48S7OvFzTOlNy+Eo8jNWHGGVzce5+HPDhLo48mUAeHMGRbF9Wcl4OXZ\nvF/w9OqjHMuv4I0lUzHXW/dtvXH5Vt68ZRpBvmf+08osrOSrA6e47dxBhARIb14IR5EevWhmS1oh\nj3xxiLOHRHLFxDiyi6v486cpXPfyVk6VVjfm25NVwrL1x1g4JZ5zhvZl7ohonr9uInuzS3l7a2aL\nZb+66TieSrF4epKDWiOEAOnR93r7s0upqatnbFwoBaYa7nhzF4kRAbxw/USC/ay97o93n+Chj/Yz\n79kf+MXkePZmlbArs5joPn48dOmIxrIuHNWPyYlhvL0tk1+dPaDZejVl1Wbe3Z7Fz8bG0C/Ez+Ht\nFKI3k0DfS5nrLTz5zWGWrU8DwM/bg2A/b2rqLCxbNLkxyAMsmBDL6NgQ7nhzFy+tP8bImD7cMC2R\na6cm0Mev+RDMtVMT+P17e9mSVtRsmeF3tmVRUVvPzbMGOqaBQohGEuh7Ga01x/JN3P/BfnZmFHPD\ntARmDe7LlrRC9maXcPd5QxgcFXTGeYOjgvjqnrOpMtcT2ML4e4NLx8bw8GcpvL0tszHQ19VbeG1T\nOlMHhDMmLqTb2iaEaJkE+l4ivaCCp1cfYUtaEafKqgn08eTZayfw83H9Abh4dL92y/DwUG0GeQA/\nb0+umBjHW1szKaqoJTzQh0/2nORESRV/vmykXdoihOgYCfS9gNaa+97fR8rJUuYMj2LawAjmjogi\nJqR7tulbODWe1zal8/7OLMz1mn99e5iRMX2YOyK6Wz5PCNG2LgV6pVQ6UA7UA3Va68lKqXDgHSAJ\nSAd+obUu7lo1RVdsTitkW3oRD/98FItnJHX75w3v14eJCaH846sfsWi4bFx/HrtiDJ4espmIEM5g\njx79HK11QZPvHwDWaK3/oZR6wPj+fjt8jmiF1pq/fn6QY/kVAPh6eXDP3CGMjrWOhz+9+ijRfXy5\nZkq8w+p0y9kD+f17e3lo3giuPytBdowSwom6Y+hmPjDbeP86kIwE+m6VfCSfVzemMzQ6iAAfL7KK\nKrnu5S28+atpmGrq2Ha8iL9cNhI/b8ft3HTJmBguGtUPD+nFC+F0Smvd+ZOVOg4UAxp4SWu9TClV\norUObZKnWGsd1sK5S4GlANHR0ZNWrVrV6XqczmQyERR05swRV3K4qJ6ias30/h3/Xdu0fVpr/ral\nmtIazePn+OPlocivtPD49mqq6jThfh6U12qeOMcfH8+eEXR7wvXrKndvo7TPMebMmbNTaz253Yxa\n606/gP7G1yhgL3AOUHJanuL2ypk0aZK2p7Vr19q1vO5w6bPr9ZCHvtRFppoOn9u0fWt/zNWJ93+u\n39yS0SxPZmGFnvHYGp14/+d6xYa0rlbXoXrC9esqd2+jtM8xgB3ahljdpSUQtNYnja95wEfAVCBX\nKRUDYHzN68pnuKOc0ioOnCijtt7CB7uymx37+kAOJ0uqbCpHa80za44SG+rPVZPimh2LDw/gnVun\ncd/Fw7h2aoLd6i6E6Hk6HeiVUoFKqeCG98CFwAHgU2CxkW0x8ElXK+mqsooq+ePH+3lm9dEOnbf6\nYC4AsaH+vL0ts+EvH5IP53Hbyl1c9d9NZBZWtlvO+qMF7M4s4fY5g/DxOvNSxoUFcPvswQ4dmxdC\nuJ6u3IyNBj4yZlN4AW9prb9WSm0H3lVK3QxkAld3vZquJauokheSU3lvRzZ1FmuQHhcfwmwb9zz9\n7lAeAyID+fW5g7jvg31sTy9mYkIoj3xxiNhQfypq61i4bDOrlk4nISKg2bknS6r47Fgty49tZXt6\nEf1D/Lh6kuNm0wghep5O9+i11mla63HGa5TW+lEjvVBrPVdrPcT4WmS/6jpXdnElD364nzn/TOaD\nnSe4/qwE1t07myFRQTz44X7KqtvfeKO82szmYwWcPyKKn42LIdjXi7e3ZfLWtkxS80z86bKRvPmr\ns6g017Nw2WZ+OJrf2OP/JuUUFz+9ng+Omskvr2HhlARevWlqi715IYRoIE/G2mhTagGLX92GQnHd\nWQn8evagxidLn7x6HFe8sJG/f3GI//ezkbyxOYM3t2YQ3cePaQPDOXtIX84aEI5SivVHCjDXay4Y\n2Y8AHy8WTIjlnR1ZrD2cx/SBEVw4MhqlFCtvPoulb+xg0fJtTE4MY0h0EG9vy2JMbAg3DKzlmkvP\ncfJPRAjRU0igt4HWmse//pHoPn68d9v0M5YOGB8fytJzBvHiumN8deAUpVVmZgyKoLK2nhfXpfH8\n2mPcPnsQ9140jO8OniIswJuJCdYZqNdOTeB/WzIw11v4489GND5YNDo2hLX3zubdHdm8sDaVHRnF\nLJ6eyEOXjmDzhh8c/jMQQvRcEuhPU1JZy33v72PemBgWTIgFIPlwPnuzS3n8yjGtrg/zm/OHsCuj\nmABfT+6eO4SJCdZHB0w1dfz9y0O8kHwMi4bvf8zjgpH9GndrGtm/DxeNiiYpIpBR/Zuv7Ojr5cmi\naYn8YnIcmYWVDIkO7saWCyHclQT6Jkoqa7n+la2knCxj7eE84sP9mZgQxtNrjhIX5s8VE+NaPdfP\n25N3b5t+RnqQrxePzB+N1vDiumMAXDCy+U3blxa1/byDr5enBHkhRKfJXTxDQ5A/mmvi2Wsn0D/U\nn9tW7uLdHVnszSrhzjmD8fbs3I/Lw0Px6ILR3DAtgf4hfpw9pK+day+EEK3rNT3673/MJflwPpuP\nFVJUUcs7t05jcJS1l1xtrueXr27naK6Jl26cxJxhUQyLDubyFzZy/wf7iQ1tuzdvCw8PxSMLxmD5\nuZb1X4QQDtUrevRfH8hhyWs7eH9nNjGh1jH2pW/spKzajNaaP31ygD1ZJTyzcDxzjLnww/oF8+RV\n41DKOv5urymMEuSFEI7WK3r0L/9wnITwAFb/7lx8vDzYmlbI9a9s5Xfv7OHcoX15d0c2d84ZzCVj\nYpqdd+nYGGYOvoDQAB8n1VwIIbrO7Xv0uzOL2ZlRzE0zkxp75WcNjOCPl45g9aE8/t8nKcwe1pff\nXjC0xfMlyAshejq36NF/tDub9ILKFoP18g3HCfb14urJzZcJWDwjidR8E7sySnjmmgmy+5EQwm31\n+EBfUVPHnz9Joay6jqHRwVw69qfhlxMlVXx14BRLZiYRdNqm1kpZb45qrWX3IyGEW+vxQzfv78ym\nrLqO2FB//vTJAQpNNY3HXt+UDtDmPqkS5IUQ7q5HB3qLRfPqxuOMjw9lxS+nUFZt5s+fplBbr3nl\nhzRWbsng4tH9iAsLaL8wIYRwUz166GbNj3mkF1by3EXDGNYvmHvmDuGf3x5hrTdUmA8xY1AED1w8\n3NnVFEIIp+rRgf6VH9KIDfXn4lH9ALj13EFsPV5EYVERf75yKmcNjHByDYUQwvl67NDNgROlbD1e\nxOIZiY0LhHl7evC/m8/ivin+EuSFEMLQIwN9TmkVd7y1ixB/b66ZIvuhCiFEW3pcoM8prWLhsi0U\nmWp57aYphPh7O7tKQgjh0nrUGH1GYQWLV2yj0FTLGzdPZYKx5rsQQojW9ZhA/9X+HO57fx9KwRs3\nT23c2EMIIUTbXDLQa635fF8OGYUVAKQXVvL+zmzGxYfy3LUTiA+XefFCCGErlwv0pVVm7n9/H1+n\nnGpM8/RQLJk5gAcuGW635YKFEKK3cKlAf+BEKbe/uYsTJVU8NG84v5wxAKVAQeMUSiGEEB3jMoE+\nu7iSRcu3WvdevXUakxLDnV0lIYRwCy4R6LWGW/+3kzqL5q1bpjEgMtDZVRJCCLfhEoE+u6SSopwy\nli+eLEFeCCHsrNsGvpVSFyulDiulUpVSD7SVt6TSzG/PH8p5w6O7qzpCCNFrdUugV0p5As8DlwAj\ngWuVUiNbyx8a4M2dcwZ3R1WEEKLX664e/VQgVWudprWuBVYB81vLHB8WgIds5SeEEN2iuwJ9LJDV\n5PtsI00IIYSDddfN2Ja657pZBqWWAksBoqOjSU5OttuHm0wmu5bnaqR9PZ+7t1Ha51q6K9BnA/FN\nvo8DTjbNoLVeBiwDmDx5sp49e7bdPjw5ORl7ludqpH09n7u3UdrnWrpr6GY7MEQpNUAp5QMsBD7t\nps8SQgjRhm7p0Wut65RSdwLfAJ7ACq11Snd8lhBCiLZ12wNTWusvgS+7q3whhBC2kZXChBDCzUmg\nF0IIN6e01u3n6u5KKJUPZNixyEigwI7luRppX8/n7m2U9jlGota6b3uZXCLQ25tSaofWerKz69Fd\npH09n7u3UdrnWmToRggh3JwEeiGEcHPuGuiXObsC3Uza1/O5exulfS7ELcfohRBC/MRde/RCCCEM\nPSLQK6VWKKXylFIHmqSNU0ptVkrtV0p9ppTq0+TYg8bOVoeVUhc1Sbd51ytH60gblVIXKKV2Guk7\nlVLnNTlnkpGeqpR6VinlEgv9d/QaGscTlFImpdT/NUlzyWvYiX+jY41jKcZxPyO9x18/pZS3Uup1\nI/2QUurBJue46vWLV0qtNeqbopS6x0gPV0p9p5Q6anwNM9KVcX1SlVL7lFITm5S12Mh/VCm12Flt\nakZr7fIv4BxgInCgSdp24Fzj/RLgb8b7kcBewBcYABzDut6Op/F+IOBj5Bnp7LZ1so0TgP7G+9HA\niSbnbAOmY10q+ivgEme3raPta3L8A+A94P+M7132Gnbw+nkB+4BxxvcRgKe7XD/gOmCV8T4ASAeS\nXPz6xQATjffBwBEjljwBPGCkPwA8bryfZ1wfBUwDthrp4UCa8TXMeB/m7Pb1iB691no9UHRa8jBg\nvfH+O+BK4/18rP/IarTWx4FUrDtedWjXK0frSBu11ru11g3LPqcAfkopX6VUDNBHa71ZW//VvQEs\n6P7at6+D1xCl1AKs/0maLobnstewg+27ENintd5rnFuota53o+ungUCllBfgD9QCZbj29cvRWu8y\n3pcDh7BuljQfeN3I9jo/XY/5wBvaagsQaly/i4DvtNZFWutirD+Xix3YlBb1iEDfigPAz433V/PT\n+vet7W7VE3e9aq2NTV0J7NZa12BtT3aTY67exhbbp5QKBO4HHj4tf0+7hq1dv6GAVkp9o5TapZS6\nz0h3i+sHvA9UADlAJvBPrXURPeT6KaWSsP7VvBWI1lrngPWXARBlZOtRcaYnB/olwB1KqZ1Y/9Sq\nNdJb292q3V2vXFBrbQRAKTUKeBy4tSGphTJcuY2tte9h4N9aa9Np+d2lfV7ALOB64+vlSqm5uE/7\npgL1QH+sw6e/V0oNpAe0TykVhHXI8Dda67K2sraQ5rJxptuWKe5uWusfsf4JjFJqKHCpcait3a3a\n3PXK1bTRRpRSccBHwI1a62NGcjbWdjVw6Ta20b6zgKuUUk8AoYBFKVUN7KQHXcN2/o2u01oXGMe+\nxDr+vRL3uH7XAV9rrc1AnlJqIzAZa0/XZa+fUsoba5B/U2v9oZGcq5SK0VrnGEMzeUZ6a3EmG5h9\nWnpyd9bbFj22R6+UijK+egB/BF40Dn0KLDTGrAcAQ7De4Opxu1611kalVCjwBfCg1npjQ37jT8ty\npdQ0Y7bGjcAnDq+4jVprn9b6bK11ktY6CXga+LvW+jl62DVs49/oN8BYpVSAMY59LnDQXa4f1uGa\n84yZKYFYb1b+iAtfP+PnvRw4pLV+qsmhT4GGmTOL+el6fArcaLRxGlBqXL9vgAuVUmHGDJ0LjTTn\ncvbdYFtewNtYx/vMWH9j3gzcg/XO+BHgHxgPfxn5/4D17v5hmsxawHqn/Ihx7A/Obldn24j1P1UF\nsKfJK8o4Nhnr2Okx4LmmP5ee0r7TzvsLxqwbV76Gnfg3egPWG80HgCeapPf46wcEYZ0tlQIcBO7t\nAddvFtYhln1N/k/Nwzojag1w1PgabuRXwPNGO/YDk5uUtQTrJJBU4CZnt01rLU/GCiGEu+uxQzdC\nCCFsI4FeCCHcnAR6IYRwcxLohRDCzUmgF0IINyeBXggh3JwEeiHsRCnl6ew6CNESCfSiV1JK/a1h\nzXHj+0eVUncrpe5VSm031hh/uMnxj5V17f8UpdTSJukmpdRflVJbsS4vLITLkUAveqvlGI+2G4/w\nLwRysS6ZMRUYD0xSSp1j5F+itZ6E9cnVu5VSEUZ6INY12s/SWm9wZAOEsFWPXdRMiK7QWqcrpQqV\nUhOAaGA3MAXr2iS7jWxBWAP/eqzB/XIjPd5IL8S6SuMHjqy7EB0lgV70Zq8AvwT6ASuAucBjWuuX\nmmZSSs0Gzgema60rlVLJgJ9xuFprXe+oCgvRGTJ0I3qzj7Du/jMF6wqD3wBLjDXJUUrFGis0hgDF\nRpAfjnU1RiF6DOnRi15La12rlFoLlBi98m+VUiOAzdZVazFhXWXya+A2pdQ+rCuibnFWnYXoDFm9\nUvRaxk3YXcDVWuujzq6PEN1Fhm5Er6SUGol1vfA1EuSFu5MevRBCuDnp0QshhJuTQC+EEG5OAr0Q\nQrg5CfRCCOHmJNALIYSbk0AvhBBu7v8DogN8FSPptUMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107f1e048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "A.plot.line('year','count')\n",
    "grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reading rows selectively\n",
    "Suppose we are only interested in snow measurements. We can apply an SQL query directly to the \n",
    "parquet files. As the data is organized in columnar structure, we can do the selection efficiently without loading the whole file to memory.\n",
    "\n",
    "Here the file is small, but in real applications it can consist of hundreds of millions of records. In such cases loading the data first to memory and then filtering it is very wasteful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT station,measurement,year FROM weather WHERE measurement=\"SNOW\"\n",
      "2178 ['station', 'measurement', 'year']\n",
      "+-----------+-----------+------+\n",
      "|    station|measurement|  year|\n",
      "+-----------+-----------+------+\n",
      "|USC00111458|       SNOW|1991.0|\n",
      "|USC00111458|       SNOW|1994.0|\n",
      "|USC00111458|       SNOW|1995.0|\n",
      "|USC00111458|       SNOW|1996.0|\n",
      "|USC00111458|       SNOW|1997.0|\n",
      "+-----------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query='SELECT station,measurement,year FROM weather WHERE measurement=\"SNOW\"'\n",
    "print(query)\n",
    "df2 = sqlContext.sql(query)\n",
    "print(df2.count(),df2.columns)\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## References\n",
    "* For an introduction to Spark SQL and Dataframes see: [Spark SQL, DataFrames](https://spark.apache.org/docs/latest/sql-programming-guide.html#spark-sql-dataframes-and-datasets-guide)\n",
    "* Also [spark-dataframe-and-operations](https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/) from [analyticsvidhya.com](https://www.analyticsvidhya.com)\n",
    "\n",
    "For complete API reference see\n",
    "* [SQL programming guide](https://spark.apache.org/docs/latest/sql-programming-guide.html) For Java, Scala and Python (Implementation is first in Scala and Python, later pyspark)\n",
    "* [pyspark API for the DataFrame class](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame) \n",
    "* [pyspark API for the pyspark.sql module](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark-sql-module)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Exercise\n",
    "Perform join on two data frames, \n",
    "* using .join method \n",
    "* using SQL.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "263px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
