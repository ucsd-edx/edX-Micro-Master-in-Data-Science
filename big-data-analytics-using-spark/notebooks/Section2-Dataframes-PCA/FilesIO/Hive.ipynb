{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hive\n",
    "[Hive](https://hive.apache.org/): a data warehouse software that facilitates reading, \n",
    "writing, and managing large datasets residing in distributed storage using SQL.\n",
    "\n",
    "Unlike Parquet, Hive is not just a file format (in fact, Hive and use the Parquet format for it's file).\n",
    "Hive provides [a full array of SQL-like (HQL) commands](https://hortonworks.com/wp-content/uploads/2013/05/hql_cheat_sheet.pdf)\n",
    "\n",
    "Spark Does not come with Hive built-in. Before using Hive, it has to be installed and configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# %load LoadHive.py\n",
    "# A simple hive demo. \n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import HiveContext\n",
    "import json\n",
    "import sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        print \"Error usage: LoadHive [sparkmaster] [inputtable]\"\n",
    "        sys.exit(-1)\n",
    "    master = sys.argv[1]\n",
    "    inputTable = sys.argv[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Query Hive\n",
    "Here is a code snippet that connects to a hive server and queries for the key,value pairs in a given table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "    # Connect to Hive Server\n",
    "    sc = SparkContext(master, \"LoadHive\")\n",
    "    hiveCtx = HiveContext(sc)\n",
    "\n",
    "    # Query hive\n",
    "    input = hiveCtx.sql(\"FROM \" + inputTable + \" SELECT key, value\")\n",
    "    print \"result of query\"\n",
    "    print input.collect()\n",
    "    data = input.map(lambda x: x[0] * x[0])\n",
    "    result = data.collect()\n",
    "    for element in result:\n",
    "        print \"Got data \" + str(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create Hive Table\n",
    "Code for creating a new Hive table and for loading data into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "    sc = SparkContext(master, \"LoadHive\")\n",
    "    hiveCtx = HiveContext(sc)\n",
    "\n",
    "    # Create a new table in Hive\n",
    "    hiveCtx.sql(\n",
    "        \"CREATE TABLE IF NOT EXISTS \" +\n",
    "        inputTable + \" (key INT, value STRING)\")\n",
    "\n",
    "    # Load some data into hive\n",
    "    hiveCtx.sql(\n",
    "        \"LOAD DATA LOCAL INPATH '\" + inputFile + \"' INTO TABLE \" + inputTable)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
