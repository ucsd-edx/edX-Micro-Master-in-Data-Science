{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T01:50:37.772322Z",
     "start_time": "2018-04-26T01:50:37.769662Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/workspace/edX-Micro-Master-in-Data-Science/big-data-analytics-using-spark/notebooks/Section2-PCA/PCA/data_preparation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set to True if running notebook on AWS/EMR\n",
    "EMR=True\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T01:50:49.977854Z",
     "start_time": "2018-04-26T01:50:46.393200Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('spark.logConf', 'True'), ('spark.default.parallelism', '10'), ('spark.cores.max', '4'), ('spark.app.name', 'Weather_PCA'), ('spark.executor.memory', '10g'), ('spark.executor.cores', '4')])\n"
     ]
    }
   ],
   "source": [
    "if not EMR:\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "from pyspark import SparkContext,SparkConf\n",
    "\n",
    "def create_sc(pyFiles):\n",
    "    sc_conf = SparkConf()\n",
    "    sc_conf.setAppName(\"Weather_PCA\")\n",
    "    sc_conf.set('spark.executor.memory', '10g')\n",
    "    sc_conf.set('spark.executor.cores', '4')\n",
    "    sc_conf.set('spark.cores.max', '4')\n",
    "    sc_conf.set('spark.default.parallelism','10')\n",
    "    sc_conf.set('spark.logConf', True)\n",
    "    print(sc_conf.getAll())\n",
    "\n",
    "    sc = SparkContext(conf=sc_conf,pyFiles=pyFiles)\n",
    "\n",
    "    return sc \n",
    "\n",
    "sc = create_sc(pyFiles=['lib/numpy_pack.py','lib/spark_PCA.py','lib/computeStatistics.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T01:50:50.117124Z",
     "start_time": "2018-04-26T01:50:49.979720Z"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType,FloatType, DoubleType, StringType, IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "import numpy as np\n",
    "from lib.computeStatistics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list=!aws s3 ls mas-dse-open/Weather/by_state/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NY.tgz',\n",
       " 'NaN.tgz',\n",
       " 'OH.tgz',\n",
       " 'OK.tgz',\n",
       " 'ON.tgz',\n",
       " 'OR.tgz',\n",
       " 'PA.tgz',\n",
       " 'QC.tgz',\n",
       " 'RI.tgz',\n",
       " 'SC.tgz',\n",
       " 'SD.tgz',\n",
       " 'SK.tgz',\n",
       " 'STAT_AB.pickle',\n",
       " 'STAT_AL.pickle',\n",
       " 'STAT_AR.pickle',\n",
       " 'STAT_NY.pickle',\n",
       " 'STAT_NY.pickle.gz',\n",
       " 'STAT_RI.pickle.gz',\n",
       " 'TN.tgz',\n",
       " 'TX.tgz',\n",
       " 'UT.tgz',\n",
       " 'VA.tgz',\n",
       " 'VT.tgz',\n",
       " 'WA.tgz',\n",
       " 'WI.tgz',\n",
       " 'WV.tgz',\n",
       " 'WY.tgz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames=[l.split()[3] for l in file_list]\n",
    "len(filenames)\n",
    "filenames[36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by_state  US_stations.parquet  US_weather.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/workspace/Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://mas-dse-open/Weather/by_state/AB.tgz to ../../../../../../Data/by_state/AB.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/BC.tgz to ../../../../../../Data/by_state/BC.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/CT.tgz to ../../../../../../Data/by_state/CT.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/AR.tgz to ../../../../../../Data/by_state/AR.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/DC.tgz to ../../../../../../Data/by_state/DC.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/DE.tgz to ../../../../../../Data/by_state/DE.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/AL.tgz to ../../../../../../Data/by_state/AL.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/CO.tgz to ../../../../../../Data/by_state/CO.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/AZ.tgz to ../../../../../../Data/by_state/AZ.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/GA.tgz to ../../../../../../Data/by_state/GA.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/IA.tgz to ../../../../../../Data/by_state/IA.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/ID.tgz to ../../../../../../Data/by_state/ID.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/CA.tgz to ../../../../../../Data/by_state/CA.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/KY.tgz to ../../../../../../Data/by_state/KY.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/MB.tgz to ../../../../../../Data/by_state/MB.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/LA.tgz to ../../../../../../Data/by_state/LA.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/FL.tgz to ../../../../../../Data/by_state/FL.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/IL.tgz to ../../../../../../Data/by_state/IL.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/KS.tgz to ../../../../../../Data/by_state/KS.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/IN.tgz to ../../../../../../Data/by_state/IN.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/MA.tgz to ../../../../../../Data/by_state/MA.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/MD.tgz to ../../../../../../Data/by_state/MD.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/MS.tgz to ../../../../../../Data/by_state/MS.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/NB.tgz to ../../../../../../Data/by_state/NB.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/MO.tgz to ../../../../../../Data/by_state/MO.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/MN.tgz to ../../../../../../Data/by_state/MN.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/MT.tgz to ../../../../../../Data/by_state/MT.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/ME.tgz to ../../../../../../Data/by_state/ME.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/MI.tgz to ../../../../../../Data/by_state/MI.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/NC.tgz to ../../../../../../Data/by_state/NC.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/NH.tgz to ../../../../../../Data/by_state/NH.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/NJ.tgz to ../../../../../../Data/by_state/NJ.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/NE.tgz to ../../../../../../Data/by_state/NE.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/NV.tgz to ../../../../../../Data/by_state/NV.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/NY.tgz to ../../../../../../Data/by_state/NY.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/ON.tgz to ../../../../../../Data/by_state/ON.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/NM.tgz to ../../../../../../Data/by_state/NM.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/OH.tgz to ../../../../../../Data/by_state/OH.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/QC.tgz to ../../../../../../Data/by_state/QC.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/NaN.tgz to ../../../../../../Data/by_state/NaN.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/RI.tgz to ../../../../../../Data/by_state/RI.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/ND.tgz to ../../../../../../Data/by_state/ND.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/SK.tgz to ../../../../../../Data/by_state/SK.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/OK.tgz to ../../../../../../Data/by_state/OK.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/SC.tgz to ../../../../../../Data/by_state/SC.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/PA.tgz to ../../../../../../Data/by_state/PA.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/STAT_NY.pickle.gz to ../../../../../../Data/by_state/STAT_NY.pickle.gz\n",
      "download: s3://mas-dse-open/Weather/by_state/STAT_RI.pickle.gz to ../../../../../../Data/by_state/STAT_RI.pickle.gz\n",
      "download: s3://mas-dse-open/Weather/by_state/OR.tgz to ../../../../../../Data/by_state/OR.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/SD.tgz to ../../../../../../Data/by_state/SD.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/STAT_NY.pickle to ../../../../../../Data/by_state/STAT_NY.pickle\n",
      "download: s3://mas-dse-open/Weather/by_state/VT.tgz to ../../../../../../Data/by_state/VT.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/VA.tgz to ../../../../../../Data/by_state/VA.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/TN.tgz to ../../../../../../Data/by_state/TN.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/UT.tgz to ../../../../../../Data/by_state/UT.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/WA.tgz to ../../../../../../Data/by_state/WA.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/WV.tgz to ../../../../../../Data/by_state/WV.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/TX.tgz to ../../../../../../Data/by_state/TX.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/WY.tgz to ../../../../../../Data/by_state/WY.tgz\n",
      "download: s3://mas-dse-open/Weather/by_state/WI.tgz to ../../../../../../Data/by_state/WI.tgz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive s3://mas-dse-open/Weather/by_state/ /mnt/workspace/Data/by_state/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/Data/by_state\n"
     ]
    }
   ],
   "source": [
    "data_dir='/mnt/workspace/Data/by_state/'\n",
    "hdfs_dir='/weather/by_state/'\n",
    "%cd $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "for filename in glob('*.tgz'):\n",
    "    !tar -xzf $filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: `/weather/by_state': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mkdir $hdfs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in glob('*.parquet'):\n",
    "    hdfs_fullname=hdfs_dir+filename\n",
    "    !hdfs dfs -copyFromLocal $filename $hdfs_fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AB,AL,AR,AZ,BC,CA,CO,CT,DC,DE,FL,GA,IA,ID,IL,IN,KS,KY,LA,MA,MB,MD,ME,MI,MN,MO,MS,MT,NaN,NB,NC,ND,NE,NH,NJ,NM,NV,NY,OH,OK,ON,OR,PA,QC,RI,SC,SD,SK,TN,TX,UT,VA,VT,WA,WI,WV,WY'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NM',\n",
       " 'NV',\n",
       " 'NY',\n",
       " 'OH',\n",
       " 'OK',\n",
       " 'ON',\n",
       " 'OR',\n",
       " 'PA',\n",
       " 'QC',\n",
       " 'RI',\n",
       " 'SC',\n",
       " 'SD',\n",
       " 'SK',\n",
       " 'TN',\n",
       " 'TX',\n",
       " 'UT',\n",
       " 'VA',\n",
       " 'VT',\n",
       " 'WA',\n",
       " 'WI',\n",
       " 'WV',\n",
       " 'WY']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_files=!ls -d /mnt/workspace/Data/by_state/*.parquet\n",
    "state_names=[a[29:-8] for a in parquet_files]\n",
    "state_names[35:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Count_nan(V):\n",
    "    A=unpackArray(V,data_type=np.float16)\n",
    "    return int(sum(np.isnan(A)))  # the int() is important, sparksql does not accept numpy ints\n",
    "Count_nan_udf = udf(Count_nan,IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NM',\n",
       " 'NV',\n",
       " 'NY',\n",
       " 'OH',\n",
       " 'OK',\n",
       " 'ON',\n",
       " 'OR',\n",
       " 'PA',\n",
       " 'QC',\n",
       " 'RI',\n",
       " 'SC',\n",
       " 'SD',\n",
       " 'SK',\n",
       " 'TN',\n",
       " 'TX',\n",
       " 'UT',\n",
       " 'VA',\n",
       " 'VT',\n",
       " 'WA',\n",
       " 'WI',\n",
       " 'WV',\n",
       " 'WY']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_names[35:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 hadoop hadoop 28749915 Apr 26 05:25 /mnt/workspace/Data/by_state/STAT_AB.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 28749949 Apr 26 05:32 /mnt/workspace/Data/by_state/STAT_AL.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 29337474 Apr 26 05:41 /mnt/workspace/Data/by_state/STAT_AR.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31631094 Apr 26 05:54 /mnt/workspace/Data/by_state/STAT_AZ.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 23019414 Apr 26 05:55 /mnt/workspace/Data/by_state/STAT_BC.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 33578888 Apr 26 06:19 /mnt/workspace/Data/by_state/STAT_CA.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 33775498 Apr 26 06:31 /mnt/workspace/Data/by_state/STAT_CO.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 29177399 Apr 26 06:34 /mnt/workspace/Data/by_state/STAT_CT.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 29177399 Apr 26 06:34 /mnt/workspace/Data/by_state/STAT_DC.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 27853245 Apr 26 06:35 /mnt/workspace/Data/by_state/STAT_DE.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 27499127 Apr 26 06:44 /mnt/workspace/Data/by_state/STAT_FL.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 29140214 Apr 26 06:54 /mnt/workspace/Data/by_state/STAT_GA.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31239289 Apr 26 07:05 /mnt/workspace/Data/by_state/STAT_IA.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 32838448 Apr 26 07:17 /mnt/workspace/Data/by_state/STAT_ID.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31738075 Apr 26 07:28 /mnt/workspace/Data/by_state/STAT_IL.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30549306 Apr 26 07:37 /mnt/workspace/Data/by_state/STAT_IN.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31489508 Apr 26 07:49 /mnt/workspace/Data/by_state/STAT_KS.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 29654018 Apr 26 07:56 /mnt/workspace/Data/by_state/STAT_KY.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 28056393 Apr 26 08:03 /mnt/workspace/Data/by_state/STAT_LA.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30312769 Apr 26 08:07 /mnt/workspace/Data/by_state/STAT_MA.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30312769 Apr 26 08:07 /mnt/workspace/Data/by_state/STAT_MB.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30138637 Apr 26 08:13 /mnt/workspace/Data/by_state/STAT_MD.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30539691 Apr 26 08:17 /mnt/workspace/Data/by_state/STAT_ME.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 32182560 Apr 26 08:28 /mnt/workspace/Data/by_state/STAT_MI.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31342689 Apr 26 08:39 /mnt/workspace/Data/by_state/STAT_MN.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30441830 Apr 26 08:49 /mnt/workspace/Data/by_state/STAT_MO.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 28449218 Apr 26 08:57 /mnt/workspace/Data/by_state/STAT_MS.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 33726563 Apr 26 09:13 /mnt/workspace/Data/by_state/STAT_MT.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 25988825 Apr 26 09:22 /mnt/workspace/Data/by_state/STAT_NaN.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 25988824 Apr 26 09:23 /mnt/workspace/Data/by_state/STAT_NB.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30987072 Apr 26 09:33 /mnt/workspace/Data/by_state/STAT_NC.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 32069534 Apr 26 09:42 /mnt/workspace/Data/by_state/STAT_ND.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 32298730 Apr 26 09:54 /mnt/workspace/Data/by_state/STAT_NE.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31593808 Apr 26 09:57 /mnt/workspace/Data/by_state/STAT_NH.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 29631185 Apr 26 10:01 /mnt/workspace/Data/by_state/STAT_NJ.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 32368060 Apr 26 20:57 /mnt/workspace/Data/by_state/STAT_NM.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31907267 Apr 26 21:03 /mnt/workspace/Data/by_state/STAT_NV.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31373293 Apr 26 21:14 /mnt/workspace/Data/by_state/STAT_NY.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30569799 Apr 26 21:22 /mnt/workspace/Data/by_state/STAT_OH.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30424176 Apr 26 21:33 /mnt/workspace/Data/by_state/STAT_OK.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30424176 Apr 26 21:33 /mnt/workspace/Data/by_state/STAT_ON.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 33506791 Apr 26 21:45 /mnt/workspace/Data/by_state/STAT_OR.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31089379 Apr 26 21:56 /mnt/workspace/Data/by_state/STAT_PA.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 21088366 Apr 26 21:56 /mnt/workspace/Data/by_state/STAT_QC.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 27462378 Apr 26 21:57 /mnt/workspace/Data/by_state/STAT_RI.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 28986060 Apr 26 22:03 /mnt/workspace/Data/by_state/STAT_SC.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 32243649 Apr 26 22:13 /mnt/workspace/Data/by_state/STAT_SD.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 32243649 Apr 26 22:13 /mnt/workspace/Data/by_state/STAT_SK.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30192001 Apr 26 22:21 /mnt/workspace/Data/by_state/STAT_TN.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30980054 Apr 26 22:45 /mnt/workspace/Data/by_state/STAT_TX.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 33192309 Apr 26 22:56 /mnt/workspace/Data/by_state/STAT_UT.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 33192309 Apr 26 23:05 /mnt/workspace/Data/by_state/STAT_VA.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30674616 Apr 26 23:07 /mnt/workspace/Data/by_state/STAT_VT.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 33572191 Apr 26 23:18 /mnt/workspace/Data/by_state/STAT_WA.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 31572356 Apr 26 23:29 /mnt/workspace/Data/by_state/STAT_WI.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 30834494 Apr 26 23:37 /mnt/workspace/Data/by_state/STAT_WV.pickle.gz\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 33196027 Apr 26 23:45 /mnt/workspace/Data/by_state/STAT_WY.pickle.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /mnt/workspace/Data/by_state/*.pickle.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path= /weather/by_state//NM.parquet\n",
      "dataframe length= 189718\n",
      "   Measurement  count\n",
      "0         PRCP  17414\n",
      "1     PRCP_s20  17414\n",
      "2         SNOW  17056\n",
      "3     SNOW_s20  17056\n",
      "4         SNWD  15558\n",
      "5     SNWD_s20  15558\n",
      "6         TMAX  15748\n",
      "7     TMAX_s20  15748\n",
      "8         TMIN  15757\n",
      "9     TMIN_s20  15757\n",
      "10        TOBS  13326\n",
      "11    TOBS_s20  13326\n",
      "(12, 2)\n",
      "before removing >= 50 nans 189718\n",
      "after removing >= 50 nans 157360\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'SNWD'\n",
      "SNWD : shape of mdf is  8984\n",
      "time for SNWD is 47.07102656364441\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'TOBS'\n",
      "TOBS : shape of mdf is  9882\n",
      "time for TOBS is 47.90512728691101\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'SNWD_s20'\n",
      "SNWD_s20 : shape of mdf is  11554\n",
      "time for SNWD_s20 is 73.73382449150085\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'TOBS_s20'\n",
      "TOBS_s20 : shape of mdf is  12203\n",
      "time for TOBS_s20 is 63.62606453895569\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'TMIN'\n",
      "TMIN : shape of mdf is  12623\n",
      "time for TMIN is 61.00734877586365\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'TMAX'\n",
      "TMAX : shape of mdf is  12654\n",
      "time for TMAX is 60.26525282859802\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'SNOW'\n",
      "SNOW : shape of mdf is  13334\n",
      "time for SNOW is 64.208247423172\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'PRCP'\n",
      "PRCP : shape of mdf is  14696\n",
      "time for PRCP is 70.33579349517822\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'TMAX_s20'\n",
      "TMAX_s20 : shape of mdf is  14738\n",
      "time for TMAX_s20 is 74.66302490234375\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'TMIN_s20'\n",
      "TMIN_s20 : shape of mdf is  14753\n",
      "time for TMIN_s20 is 76.19911313056946\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'SNOW_s20'\n",
      "SNOW_s20 : shape of mdf is  15571\n",
      "time for SNOW_s20 is 75.14089441299438\n",
      "SELECT * FROM weather\n",
      "\tWHERE measurement = 'PRCP_s20'\n",
      "PRCP_s20 : shape of mdf is  16368\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump\n",
    "\n",
    "for state in state_names[35:]:\n",
    "    parquet=state+'.parquet'\n",
    "    parquet_path = hdfs_dir+'/'+parquet\n",
    "    print('path=',parquet_path)\n",
    "    \n",
    "    df=sqlContext.read.parquet(parquet_path)\n",
    "    print('dataframe length=',df.cache().count())\n",
    "\n",
    "    sqlContext.registerDataFrameAsTable(df,'table')\n",
    "\n",
    "    #find all measurements (should be 6x2 = 12)\n",
    "    Query=\"\"\"\n",
    "    SELECT Measurement,count(Measurement) as count \n",
    "    FROM table \n",
    "    GROUP BY Measurement\n",
    "    ORDER BY Measurement\n",
    "    \"\"\"\n",
    "    counts=sqlContext.sql(Query).toPandas()\n",
    "    measurements=list(counts['Measurement'])\n",
    "    print(counts)\n",
    "    print(counts.shape)\n",
    "\n",
    "    # Remove rows with more than 50 nans\n",
    "    df=df.withColumn(\"nan_no\", Count_nan_udf(df.Values))\n",
    "    count_nans=df.select('nan_no').toPandas()\n",
    "    count_nans.plot.hist('nan_no',bins=100);\n",
    "    print('before removing >= 50 nans',df.count())\n",
    "    df=df.filter(df.nan_no < 50)\n",
    "    print('after removing >= 50 nans',df.count())\n",
    "\n",
    "    ### This is the main cell, where all of the statistics are computed.\n",
    "    try:\n",
    "        STAT=computeStatistics(sqlContext,df)\n",
    "    except:\n",
    "        print('error computing statistics for '+state)\n",
    "\n",
    "    ## Dump STAT and STAT_Descriptions into a pickle file.\n",
    "    filename='STAT_%s.pickle'%state\n",
    "    fullname=data_dir+filename\n",
    "    s3_path='s3://mas-dse-open/Weather/by_state/'\n",
    "    gzipped_name=fullname+'.gz'\n",
    "    s3_fullname=s3_path+filename+'.gz'\n",
    "\n",
    "    print(fullname,s3_fullname)\n",
    "    dump((STAT,STAT_Descriptions),open(fullname,'wb'))\n",
    "    !gzip -f $fullname\n",
    "    \n",
    "    \n",
    "    #copy pickle file to S3\n",
    "    #!aws s3 rm $s3_fullname\n",
    "    #!aws s3 cp $fullname $s3_fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T18:03:50.513142Z",
     "start_time": "2018-04-24T18:03:50.506731Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOBS 0.0\n",
      "TOBS_s20 0.0\n",
      "TMAX 0.0\n",
      "TMAX_s20 0.0\n",
      "TMIN_s20 0.0\n",
      "TMIN 0.0\n",
      "SNWD_s20 0.0\n",
      "SNWD 0.0\n",
      "SNOW_s20 0.0\n",
      "SNOW 0.0\n",
      "PRCP_s20 0.0\n",
      "PRCP 0.0\n"
     ]
    }
   ],
   "source": [
    "X=STAT['TMAX']['Var']\n",
    "for key in STAT.keys():\n",
    "    Y=STAT[key]['Var']\n",
    "    print(key,sum(abs(X-Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 yoavfreund  staff  25684524 Apr  1 14:31 ../../Data/Weather/STAT_NY.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../../Data/Weather/STAT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 yoavfreund  staff  14948011 Apr  1 14:31 ../../Data/Weather/STAT_NY.pickle.gz\r\n"
     ]
    }
   ],
   "source": [
    "!gzip -f -k ../../Data/Weather/STAT*.pickle\n",
    "!ls -l ../../Data/Weather/STAT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3  cp ../../Data/Weather/STAT_NY.pickle.gz s3://mas-dse-open/Weather/by_state/STAT_NY.pickle.gz\n",
      "upload: ../../Data/Weather/STAT_NY.pickle.gz to s3://mas-dse-open/Weather/by_state/STAT_NY.pickle.gz\n"
     ]
    }
   ],
   "source": [
    "for state in ['NY']:\n",
    "    command=\"aws s3  cp ../../Data/Weather/STAT_%s.pickle.gz s3://mas-dse-open/Weather/by_state/STAT_%s.pickle.gz\"%(state,state)\n",
    "    print(command)\n",
    "    !$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-01 14:32:56   14948011 STAT_NY.pickle.gz\r\n",
      "2018-03-18 20:33:54   11717259 STAT_RI.pickle.gz\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3  ls s3://mas-dse-open/Weather/by_state/ | grep STAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "* We discussed how to compute the covariance matrix and the expectation matrix when there are `nan` entries.\n",
    "* The details are all in `computeStatistics`, which is defined in python files you can find in the directory `lib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "name": "PCA_using_numpy for HW3",
  "notebookId": 85286,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "116px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
