{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-601b4a206f8f71fd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## CSE 255 Programming Assignment 1: Collinear points\n",
    "\n",
    "For this problem set, we'll be using a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1f0aaa1b0eeb62ff",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### In this programming assignment, you will write python3 code using pyspark to find sets of collinear points given arbitrary number of 2D points.\n",
    "\n",
    "Definition of collinearity[1]: In geometry, collinearity of a set of points is the property of their lying on a single line. A set of points with this property is said to be collinear.\n",
    "\n",
    "![](non-collinear-points.jpg)\n",
    "\n",
    "Here, points P,Q,R and A,R,B are collinear. However, points A,B,C are non-collinear. For more, refer [2].\n",
    "\n",
    "Given an input file with a set of co-ordinates, your task is to use pyspark library functions to write a program to find if three or more points are collinear.\n",
    "\n",
    "For instance, if given these points: {(1,1), (0,1), (2,2), (3,3), (0,5), (3,4), (5,6), (0,-3), (-2,-2)}\n",
    "\n",
    "Sets of collinear points are: {((-2,-2), (1,1), (2,2), (3,3)), ((0,1), (3,4), (5,6)), ((0,-3), (0,1), (0,5))}. Note that the ordering of the points in a set or the order of the sets does not matter. \n",
    "\n",
    "Note: Every set of collinear points has to have atleast three points (single point or a pair of points always lie on a line).\n",
    "\n",
    "1. https://en.wikipedia.org/wiki/Collinearity\n",
    "2. http://www.mathcaptain.com/geometry/collinear-points.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize spark context using 4 local cores as workers.\n",
    "Note that we can create a SparkConf() object and use it to initialize the spark context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5f266efcf9bf6846",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=Collinear Points, master=local[4]) created by __init__ at <ipython-input-1-3702202da879>:3 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3702202da879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetAppName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Collinear Points\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetMaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local[4]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/cse255/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m~/.virtualenvs/cse255/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    294\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 296\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=Collinear Points, master=local[4]) created by __init__ at <ipython-input-1-3702202da879>:3 "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"Collinear Points\").setMaster(\"local[4]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines for implementation\n",
    "\n",
    "The goal of this assignment is to make you familiar with programming using pyspark. There are many ways to find sets of collinear points from a list of points. For the purposes of this assignment, we shall stick with the below approach:\n",
    "\n",
    "1. Find the cartesian product of the list of points with itself. For example, given three points [(1,0), (2,0), (3,0)], we first construct [((1,0), (2,0)), ((2,0), (1,0)), ((1,0), (3,0)), ((3,0), (1,0)), ((2,0), (3,0)), ((3,0), (2,0))]. Note that pairs ((1,0),(1,0)), ((2,0),(2,0)) and ((3,0),(3,0)) are deliberately not included in the result of cartesian product, since they all have duplicate points.\n",
    "\n",
    "2. Use the above intermediary result to find slope (of the line segment connecting) each pair of points in the cartesian product. If two pairs of points have the same slope, and if they have one point in common, the three points have to be collinear. For example, in [((1,0), (2,0)), ((2,0), (1,0)), ((1,0), (3,0)), ((3,0), (1,0)), ((2,0), (3,0)), ((3,0), (2,0))], slope between (1,0) and (2,0) is 0, and slope between (1,0) and (3,0) is also 0. Since (1,0) is common to both of these pairs of points, ((1,0), (2,0), (3,0)) must be collinear.\n",
    "\n",
    "\n",
    "Keeping the above technique in mind, you will complete the leftover parts of this notebook. You are required to use pyspark's map, reduce, groupby and other library functions to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-773a47aa41687e4f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Below are some helper functions that will be used in your implementations. You are neither required to nor encouraged to change the definitions of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2092dc2190e469ef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def to_tuple(x):\n",
    "    \"\"\"\n",
    "    Converts each point of form 'Ax, Ay' into a point of form (Ax, Ay) for further processing.\n",
    "    \"\"\"\n",
    "    arr = x.split()\n",
    "    return tuple([int(element) for element in arr])\n",
    "\n",
    "def non_duplicates(x):\n",
    "    \"\"\"  \n",
    "    input: Pair (A,B) where A and B are of form (Ax, Ay) and (Bx, By) respectively.\n",
    "    Returns True if A == B, False otherwise.\n",
    "    \n",
    "    Use this function inside the get_cartesian() function to filter out pairs with duplicate points. \n",
    "    \"\"\"\n",
    "    return x[0] != x[1]\n",
    "\n",
    "def format_result(x):\n",
    "    \"\"\"\n",
    "    input: ((A,slope), [C1,..., Ck]) where each of A, C1,..., Ck is a point of form (Ax, Ay) and slope is a float.\n",
    "    output: (C1,..., Ck, A)\n",
    "    \n",
    "    Concatenates collinear points.\n",
    "    \"\"\"\n",
    "    x[1].append(x[0][0])\n",
    "    return tuple(x[1])\n",
    "\n",
    "def to_sorted_points(x):\n",
    "    \"\"\"\n",
    "    Sorts and returns a tuple of points for further processing.\n",
    "    \"\"\"\n",
    "    return tuple(sorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "collinear-preprocess",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_cartesian(rdd):\n",
    "    \"\"\"\n",
    "    Does a Cartesian product of an RDD with itself and returns an RDD with DISTINCT pairs of points.\n",
    "    \n",
    "    Refer:  http://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=cartesian#pyspark.RDD.cartesian\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    rdd = rdd.cartesian(rdd)\n",
    "    \n",
    "    # To remove duplicates points, example ((1,0), (1,0))\n",
    "    rdd = rdd.filter(non_duplicates)\n",
    "    \n",
    "    return rdd\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Collinear-slope",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_slope(x):\n",
    "    \"\"\"\n",
    "    input: Pair (A,B) where A and B are of form (Ax, Ay) and (Bx, By) respectively.\n",
    "    output: Pair ((A,slope), B). Where, A and B have the same definition as input, and slope refers to the slope of the line segment connecting point A and B.\n",
    "    \n",
    "    Computes slope between points A and B.\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    if x[1][0] - x[0][0] == 0:\n",
    "        slope = \"inf\"\n",
    "    else:\n",
    "        slope = 1.0 * (x[1][1] - x[0][1])/(x[1][0] - x[0][0])\n",
    "    return ((x[0], slope), (x[1]))\n",
    "    ### END SOLUTION\n",
    "\n",
    "\n",
    "\n",
    "def find_collinear(rdd):\n",
    "    \n",
    "    \"\"\"\n",
    "    1. Find the slope of the line between all pairs of points A = (Ax, Ay) and B = (Bx, By).\n",
    "    2. For each (A, B), find all points C = ((C1x, C1y), (C2x, C2y), ... (Cnx, Cny)) \n",
    "       where slope of (A,B) = slope of (A, Ci).\n",
    "    3. Return (A, B, Ck) where Ck = all points of C which satisfy the condition 1.\n",
    "    \n",
    "    Call func format_result() from inside this function.\n",
    "    TODO: to see if definition can be improved.\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    rdd = rdd.map(find_slope).groupByKey().mapValues(list).filter(lambda x: len(x[1]) > 1)\n",
    "    \n",
    "    rdd = rdd.map(format_result)\n",
    "    ### END SOLUTION\n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell below runs all of the above functions step by step. You are again neither required to nor encouraged to change the definitions of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Collinear-main",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_sorted(x):\n",
    "    return tuple(sorted(x))\n",
    "\n",
    "def execute(filename):\n",
    "    \"\"\"\n",
    "    Computes the set of collinear points\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the data file into an RDD\n",
    "    rdd = sc.textFile(filename)\n",
    "    \n",
    "    # Transform the loaded points into tuples\n",
    "    rdd = rdd.map(to_tuple)\n",
    "    \n",
    "    # Transform the RDD to now have the cartesian product of the RDD with itself\n",
    "    rdd = get_cartesian(rdd)\n",
    "    \n",
    "    # Transform the RDD to now just have the Collinear Points \n",
    "    rdd = find_collinear(rdd)\n",
    "    \n",
    "    # Sorting each of your returned sets of collinear points. This is for grading purposes. You may ignore this.\n",
    "    rdd = rdd.map(to_sorted_points)\n",
    "    \n",
    "    # Collecting the collinear points in a set. This is for grading purposes. You may ignore this.\n",
    "    res = set(rdd.collect())\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "Collinear_soln",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(((0, 1), 'inf'), [(0, 5), (0, -3)]), (((0, 5), 'inf'), [(0, 1), (0, -3)]), (((0, 1), 1.0), [(3, 4), (5, 6)]), (((3, 4), 1.0), [(0, 1), (5, 6)]), (((5, 6), 1.0), [(0, 1), (3, 4)]), (((0, -3), 'inf'), [(0, 1), (0, 5)]), (((1, 1), 1.0), [(2, 2), (3, 3), (-2, -2)]), (((3, 3), 1.0), [(1, 1), (2, 2), (-2, -2)]), (((2, 2), 1.0), [(1, 1), (3, 3), (-2, -2)]), (((-2, -2), 1.0), [(1, 1), (2, 2), (3, 3)])]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check that the get_collinear function returns the correct output for several all input files\"\"\"\n",
    "assert execute(\"data.txt\") == {((-2, -2), (1, 1), (2, 2), (3, 3)), ((0, 1), (3, 4), (5, 6)), ((0, -3), (0, 1), (0, 5))}\n",
    "# assert execute(\"test.txt\") == {((1, 0), (2, 0), (3, 0))}\n",
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "Collinear_invalid_input",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(((0, 1), 'inf'), [(0, 5), (0, -3)]), (((0, 5), 'inf'), [(0, 1), (0, -3)]), (((0, 1), 1.0), [(3, 4), (5, 6)]), (((3, 4), 1.0), [(0, 1), (5, 6)]), (((5, 6), 1.0), [(0, 1), (3, 4)]), (((0, -3), 'inf'), [(0, 1), (0, 5)]), (((1, 1), 1.0), [(2, 2), (3, 3), (-2, -2)]), (((3, 3), 1.0), [(1, 1), (2, 2), (-2, -2)]), (((2, 2), 1.0), [(1, 1), (3, 3), (-2, -2)]), (((-2, -2), 1.0), [(1, 1), (2, 2), (3, 3)])]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "did not raise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-1ca03efcf42a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"did not raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: did not raise"
     ]
    }
   ],
   "source": [
    "\"\"\"Check that the get_collinear function raises an error for invalid input files\"\"\"\n",
    "try:\n",
    "    execute(\"data.txt\")\n",
    "except ValueError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"did not raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
