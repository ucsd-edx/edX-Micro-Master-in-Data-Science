{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CSE 255 Programming Assignment 7 - Data Analysis using XGBoost\n",
    "\n",
    "------needs to be put in theory------ \n",
    "\n",
    "We are going to use boosted trees. The question is: why don't we use the gradient boosted in Spark?\n",
    "\n",
    "THe reason is that, in our experience, XGBoost running on a single machine is much faster than Spark running on 10 machines. So we use XGBoost and am showing you how to use it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statment\n",
    "\n",
    "The code above computes the average ranges for each example.\n",
    "\n",
    "Your Task is to generate a range for **individual examples**.\n",
    "\n",
    "More specifically, you are to write a function that takes in as input:\n",
    "\n",
    "1. **Training set**\n",
    "1. **Test set**\n",
    "1. **n_bootstrap** Number of bootstrap samples on which you will run XGBoost.\n",
    "1. **minR, maxR** two numbers such that $0 < minR < maxR < 1$ that define the fractions of the `n_bootstrap` scores that define the range.\n",
    "\n",
    "The output should be a confidence interval for each example in the test set. Together with a prediction that is `Gervais / Cuviers / Unsure`. THe prediction `unsure` is to be output if the confidence interval contains the point 0.\n",
    "\n",
    "**Note:** The output from your program depends on the random bootstrap samples, and is therefor not deterministic. Don't try to get the test cases exactly correct. Instead, you should aim for the endpoints that you calculate to be close to the endpoints given in the test's assert command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from lib import XGBHelper as xgbh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The data files were preprocessed on PySpark (10 nodes) cluster. The code for the same can be found [here](Data_Processing_Whales.ipynb). The preprocessed is a numpy array with `4175` rows (for the 10mb file) with following columns (zero-indexed):\n",
    "* Col 0-9: projections on first 10 eigen vectors\n",
    "* Col 10: rmse\n",
    "* Col 11: peak2peak\n",
    "* Col 12: label (`0 if row.species==u'Gervais' else 1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Use Data/processed_data_150mb.np for a slightly bigger file\n",
    "data  = np.load(\"Data/processed_data_15mb.np\")\n",
    "X = data[:, :-1]\n",
    "y = np.array(data[:, -1], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Setting Parameters for XG Boost\n",
    "* Maximum Depth of the Tree = 3 _(maximum depth of each decision trees)_\n",
    "* Step size shrinkage used in update to prevents overfitting = 0.3 _(how to weigh trees in subsequent iterations)_\n",
    "* Evaluation Criterion= Maximize Loglikelihood according to the logistic regression _(logitboost)_\n",
    "* Maximum Number of Iterations = 1000 _(total number trees for boosting)_\n",
    "* Early Stop if score on Validation does not improve for 5 iterations\n",
    "\n",
    "[Full description of options](https://xgboost.readthedocs.io/en/latest//parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def xgboost_setup():\n",
    "    param = {}\n",
    "    param['max_depth']= 3   # depth of tree\n",
    "    param['eta'] = 0.3      # shrinkage parameter\n",
    "    param['silent'] = 0     # not silent\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param['nthread'] = 7 # Number of threads used\n",
    "    param['eval_metric'] = 'logloss'\n",
    "\n",
    "    plst = param.items()\n",
    "    return plst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(margin_scores):\n",
    "    score_mean = np.mean(margin_scores, axis=1)\n",
    "    score_std = np.std(margin_scores, axis=1)\n",
    "    min_score = score_mean + 2*score_std\n",
    "    max_score = score_mean - 2*score_std\n",
    "    return min_score, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_pred(X_train, X_test, y_train, y_test, n_bootstrap, minR, maxR):\n",
    "    score_list = []\n",
    "    bootstrap_size = 500\n",
    "    plst = xgboost_setup()\n",
    "    for i in range(n_bootstrap):\n",
    "        samp_indices = np.random.randint(len(X_train), size=bootstrap_size)\n",
    "        \n",
    "        X_samp = X_train[samp_indices]\n",
    "        y_samp = np.array(y_train[samp_indices], dtype=int)\n",
    "        \n",
    "        num_round = 100\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_samp, label=y_samp)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "        \n",
    "        evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "        \n",
    "        bst = xgb.train(plst, dtrain, num_round, evallist, verbose_eval=False)\n",
    "        \n",
    "        y_pred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit, output_margin=True)\n",
    "        \n",
    "        scores = sorted(np.round(y_pred, 2))\n",
    "        \n",
    "        normalizing_factor = (max(scores) - min(scores))\n",
    "        scores = scores/normalizing_factor\n",
    "        score_list.append(scores)\n",
    "        \n",
    "    margin_scores = np.sort(np.array(score_list), axis=0).T\n",
    "    min_ind = int(minR * n_bootstrap)\n",
    "    max_ind = int(maxR * n_bootstrap)\n",
    "    margin_scores = margin_scores[:, min_ind:max_ind]\n",
    "    \n",
    "    min_scr, max_scr = calc_stats(margin_scores)    \n",
    "    print(min_scr)\n",
    "    print(max_scr)\n",
    "    pred = prediction(min_scr, max_scr)\n",
    "    print(pred)\n",
    "#     pred = np.zeros(margin_scores.shape[0], dtype=int)\n",
    "    \n",
    "#     pred[np.intersect1d(np.where(min_scr < 0), np.where(max_scr > 0))] = 0\n",
    "#     pred[np.intersect1d(np.where(min_scr < 0), np.where(max_scr < 0))] = -1\n",
    "#     pred[np.intersect1d(np.where(min_scr > 0), np.where(max_scr > 0))] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(min_scr, max_scr):\n",
    "    pred = np.zeros(min_scr.shape, dtype=int)\n",
    "    pred[np.intersect1d(np.where(min_scr < 0), np.where(max_scr > 0))] = 0\n",
    "    pred[np.intersect1d(np.where(min_scr < 0), np.where(max_scr < 0))] = -1\n",
    "    pred[np.intersect1d(np.where(min_scr > 0), np.where(max_scr > 0))] = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1076   14 1206  101 1144  862  315  858  756  912]\n",
      "[-0.49037403 -0.39128804 -0.33350122 -0.25335822 -0.20072483 -0.10861206\n",
      " -0.04009901  0.10376799  0.29661256  0.50962585]\n",
      "[-0.7791341  -0.68435764 -0.6014159  -0.53394866 -0.46818763 -0.4171182\n",
      " -0.31703883 -0.20936123 -0.06620912  0.22086589]\n",
      "[-1 -1 -1 -1 -1 -1 -1  0  0  1]\n"
     ]
    }
   ],
   "source": [
    "#Sampling Random indices for selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "#samp_indices = np.random.randint(len(X_test), size=10)\n",
    "print(samp_indices)\n",
    "#Test data and labels\n",
    "X_test = X_test[samp_indices]\n",
    "y_test = np.array(y_test[samp_indices], dtype=int)\n",
    "\n",
    "\n",
    "bootstrap_pred(X_train, X_test, y_train, y_test, n_bootstrap=100, minR=0.1, maxR=0.9)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
