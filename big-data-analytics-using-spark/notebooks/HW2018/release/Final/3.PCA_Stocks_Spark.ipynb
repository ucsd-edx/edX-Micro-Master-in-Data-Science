{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "71c1ed9046e969d3aaf9fe5f735ff2f4",
     "grade": false,
     "grade_id": "cell-a6332b577a8684aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Analysis of stock prices using Principal Component Analysis \n",
    "\n",
    "In notebook1, you computed for each stock a `Diffs` sequence in which $d(t)=\\log \\frac{p(t+1)}{p(t)}$ where $p(t)$ is the price at time $t$ and $d(t)$ is the price diff or the price ratio. In this notebook, your task is to perform PCA on the `Diffs` sequences for all the stocks\n",
    "\n",
    "In this notebook you will read the file `SP500.csv` that you prepared in notebook 1 into a `Spark` dataframe and then use the code in `lib/spark_PCA.py` to perform PCA on the diff sequences.\n",
    "\n",
    "We start by starting a spark Context and reading the file into a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c4a1807a0d3d570dc5559e014c0a596b",
     "grade": false,
     "grade_id": "cell-85a6dd47d585c643",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Create a Spark context and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:19:32.806887Z",
     "start_time": "2018-06-08T20:19:27.417743Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55a5087ab94f362fcca1bc2230b61032",
     "grade": false,
     "grade_id": "cell-9be28728ef4b0d92",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(master=\"local\",pyFiles=['lib/spark_PCA.py'])\n",
    "\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "%pylab inline\n",
    "import sys\n",
    "sys.path.append('./lib')\n",
    "\n",
    "import numpy as np\n",
    "from spark_PCA import computeCov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "017d89ecf2098cec9cd7a24397be6954",
     "grade": false,
     "grade_id": "cell-4a1e362d55bce0fe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Read data\n",
    "\n",
    "Read the file `SP500.csv` into a `Spark` dataframe. The file contains `_D` (diff) and `_P` (stock price) values for all tickers, for all the `13422` dates for which we have stock measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:19:44.009073Z",
     "start_time": "2018-06-08T20:19:35.688821Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "30b0b979e3440eec48c0cf1e60d7a906",
     "grade": false,
     "grade_id": "cell-3c016db12c0521cc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read the file in a dataframe.\n",
    "df=sqlContext.read.csv('data/SP500.csv',header='true',inferSchema='true')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:19:45.585782Z",
     "start_time": "2018-06-08T20:19:45.581307Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "729524f0e53d98645326e2c9aabd3c22",
     "grade": false,
     "grade_id": "cell-ae9ae1f5d37b14f3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "columns=df.columns\n",
    "col=[c for c in columns if '_D' in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "77566c58272e45f5d32d314cd26c7d93",
     "grade": false,
     "grade_id": "cell-2f2a19d9ce2bff65",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Partition Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4324b420bf7d0f2b3867e2342569f093",
     "grade": false,
     "grade_id": "cell-201eaf7a743e45b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Complete the function `partition_columns` to partition the columns of the dataframe `df` into `train` and `test`  set, each of them sorted lexicographically. \n",
    "\n",
    "Input: `df` dataframe read in 1.2\n",
    "\n",
    "Returns: `tickers` - list of tickers \n",
    "\n",
    "Example Output:\n",
    "\n",
    "   ['train/AAPL_D',\n",
    " 'train/ABC_D',\n",
    " 'train/ABT_D',\n",
    " 'train/ACN_D',\n",
    " 'train/ADBE_D',]\n",
    "  \n",
    "Steps:\n",
    "1. Obtain the column names of the given dataframe using `df.columns`\n",
    "2. For each column name with a `_D` suffix, store the ticker name\n",
    "3. Maintain two lists for ticker names - one for training examples and one for test examples\n",
    "3. For each ticker name extracted, check if the ticker is a `train` example. If so, append it to the list of training examples. If not, append it to the test list\n",
    "4. Sort the training and test lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:20:02.173041Z",
     "start_time": "2018-06-08T20:20:02.160764Z"
    },
    "deletable": false,
    "nbgrader": {
     "checksum": "3d815ff9ab8dbb29e53560c40bb790c6",
     "grade": false,
     "grade_id": "cell-3af42f32ef931bce",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def partition_columns(df):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return  train_col+test_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:20:08.465507Z",
     "start_time": "2018-06-08T20:20:07.134577Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dbee1a258c5b1967a1acb35c1d148791",
     "grade": false,
     "grade_id": "cell-e01f448c7c1cea75",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "columns = partition_columns(df)\n",
    "df=df.select(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:20:08.643203Z",
     "start_time": "2018-06-08T20:20:16.311Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6a4856ad0a99f67cd20765c167af933d",
     "grade": true,
     "grade_id": "cell-a2d1862acbdc91b1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(columns) == list, 'Incorrect return type'\n",
    "assert len(columns) == 481, 'Incorrect return value'\n",
    "assert columns[10] == 'train/AEP_D'\n",
    "assert columns[200] == 'train/KMB_D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:20:12.432667Z",
     "start_time": "2018-06-08T20:20:12.428227Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4228151c7b9bec509832fbf88f810c97",
     "grade": true,
     "grade_id": "cell-9942574234a81c68",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9bf19880cbbd3370afa97a81235fe127",
     "grade": false,
     "grade_id": "cell-d20948ea8dab2354",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Create an RDD of numpy arrays\n",
    "In order to use `spark_PCA.py` we need to transform the dataframe into an RDD of numpy vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6aa844c3e4057a0914e92de3f0b7b699",
     "grade": false,
     "grade_id": "cell-54e106524016acfd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Function `make_array`\n",
    "Complete the function `make_array(row)` that takes as input a row of `df` and returns a numpy array (`dtype=np.float64`) that contains the values of the diff rolumns (`_D`). Use `np.nan_to_num` to transform `nan`s into zeros.\n",
    "\n",
    "Input: Row of `df`\n",
    "\n",
    "Output: numpy array of diff columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:20:17.169191Z",
     "start_time": "2018-06-08T20:20:17.163306Z"
    },
    "deletable": false,
    "nbgrader": {
     "checksum": "9a5ddab89ab9d7e5df0a6f5edbd1d321",
     "grade": false,
     "grade_id": "cell-6f8a85c0251142bb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def make_array(row):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9bb8baae51340f4e3788b5bee2c5f55f",
     "grade": false,
     "grade_id": "cell-9ba6651e7349ffdc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Create RDD\n",
    "\n",
    "Use `map` to create an RDD called `Rows` of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:20:20.597082Z",
     "start_time": "2018-06-08T20:20:19.194492Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2049fdd4acd96b00b37268a341102d72",
     "grade": false,
     "grade_id": "cell-9e7d833ef411f491",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Rows= df.select(col).rdd.map(make_array) ### SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:20:35.242795Z",
     "start_time": "2018-06-08T20:20:35.110716Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c7c279b76c3f7598a895335c5a9971d9",
     "grade": true,
     "grade_id": "cell-8e787b229acad106",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "014b5e91dfc7a4d6c9f750e4a26f7497",
     "grade": false,
     "grade_id": "cell-64754023ca2c306f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Compute covariance matrix\n",
    "\n",
    "Here, we compute the covariance matrix of the data using `computeCov` in `spark_PCA.py`. The covariance matrix is of dimension `481 x 481`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:22:09.833672Z",
     "start_time": "2018-06-08T20:20:38.430121Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "05bfc9506c223a1c68a0f2791414205b",
     "grade": false,
     "grade_id": "cell-bd2be8edfe8f14ec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "OUT=computeCov(Rows)\n",
    "OUT.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9859e020d842c2aeb67a99f78eb901ab",
     "grade": false,
     "grade_id": "cell-7e2d48af68ffd647",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Compute eigenvalues and eigenvectors\n",
    "\n",
    "Complete the function `compute_eig` to compute the eigenvalues and eigenvectors of the given covariance matrix. You may make use of the `eigh` function from the `numpy.linalg` library to do the same.\n",
    "\n",
    "Input: \n",
    "\n",
    "cov - covariance matrix\n",
    "\n",
    "Output: \n",
    "\n",
    "eigenval - eigenvalues in descending order\n",
    "        \n",
    "eigenvectors - In the same order as their corresponding eigenvalues\n",
    "        \n",
    "You need to reverse the order of the eigenvalues and eigenvectors returned by the `eigh` function since they are returned in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:46:25.079410Z",
     "start_time": "2018-06-08T20:46:25.071450Z"
    },
    "deletable": false,
    "nbgrader": {
     "checksum": "57cd886b676688a5811d908a7300b38e",
     "grade": false,
     "grade_id": "cell-89514becc24a91ef",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "def compute_eig(cov):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return eigval, eigvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:46:26.909664Z",
     "start_time": "2018-06-08T20:46:26.826264Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ae016efaeadc87d990f6277a5b2e9709",
     "grade": false,
     "grade_id": "cell-7e1e55f377905188",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "eigval, eigvec = compute_eig(OUT['Cov'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "356bdfbcec9a11debcd8aff589bdfd7a",
     "grade": false,
     "grade_id": "cell-e0762fe67a46284b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Function `compute_PCA`\n",
    "\n",
    "Complete the function `compute_PCA` that takes as input a list of tickers and computes the eigenvalues and eigenvectors.\n",
    "\n",
    "Input: `tickers` - list of tickers\n",
    "\n",
    "Output: `eigval`, `eigvec` - numpy arrays of eigenvalues and eigenvectors\n",
    "\n",
    "Steps:\n",
    "1. Given a list of tickers, create an RDD of numpy arrays using the `make_array` function similar to `1.4.2`\n",
    "2. Using the `computeCov` function, compute the covariance matrix of the given list of tickers, similar to `1.5`. The object returned by `computeCov` is a dictionary with the `cov` key containing the covariance matrix.\n",
    "3. Using the `compute_eig` function, compute the eigenvalues and eigenvectors of the covariance matrix obtained in step2 and store them in `eigval` and `eigvec` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a0ab7e88182e8ffb26a6ad94de32c984",
     "grade": false,
     "grade_id": "cell-496fb96036027283",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_PCA(tickers):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return eigval, eigvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e13edee01b1725fe32cc21bcd05f4b19",
     "grade": false,
     "grade_id": "cell-a2252fa4c752ad24",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "columns=df.columns\n",
    "col=[c for c in columns if '_D' in c]\n",
    "eigval, eigvec = compute_PCA(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d672d1a3d4e2d5e2eb61b9d5ba3a4507",
     "grade": true,
     "grade_id": "cell-cd516a08c489078c",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(eigvec.dot(eigvec.T), eye(481), err_msg=\"Incorrect return value\")\n",
    "np.testing.assert_almost_equal(np.sort(eigval)[::-1], eigval, err_msg=\"Incorrect return value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "144ca5015def7a8bd9fed6686fa9979c",
     "grade": true,
     "grade_id": "cell-8355465d7937f6cb",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ca9a01cdc0aec4aab6187068f907e890",
     "grade": false,
     "grade_id": "cell-f6d86585135150fe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Compute percentage-of-variance explained graph\n",
    "\n",
    "In the cell below, write code to plot the percentage of variance explained as a function of the number of top eigen-vectors used.\n",
    "\n",
    "You should get a figure similar to this:\n",
    "\n",
    "![percent-var-explained](figs/percentageOfVarianceExplained.png)\n",
    "\n",
    "Hint:\n",
    "1. Use the eigenvalues computed in `1.6` to plot the explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T16:46:38.597815Z",
     "start_time": "2018-06-08T16:46:38.442009Z"
    },
    "deletable": false,
    "nbgrader": {
     "checksum": "4980492e02d96396e9ee271e5b9623f2",
     "grade": false,
     "grade_id": "cell-2269e44236228a7d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T18:01:22.464524Z",
     "start_time": "2018-06-01T18:01:22.301431Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f186c443bc6563a2469bc6297c23036",
     "grade": false,
     "grade_id": "cell-0204e91185e55cda",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "source": [
    "### Saving the information for the next stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T17:01:05.432831Z",
     "start_time": "2018-06-08T17:01:05.412005Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "547d7e8a8fa108a82927ecb62a7a8336",
     "grade": false,
     "grade_id": "cell-7d5e9fb251541638",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "len(columns),eigvec.shape,eigval.shape\n",
    "from pickle import dump\n",
    "dump({'columns':columns,\n",
    "     'eigvec':eigvec,\n",
    "     'eigval':eigval},\n",
    "    open('data/PCA.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ffba308036a5d0ef789108510302e7aa",
     "grade": false,
     "grade_id": "cell-e4a017293fac3694",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Checking your calculations\n",
    "One good way to check your calculations is to create a scatter-plot projecting the data on two of the largest variance eigen-vectors.\n",
    "\n",
    "In the directory `figs` you will find scatter plots corresponding to the six combinations of the top 4 eigenvectors.\n",
    "\n",
    "In these scatter-plots the ticker is replaced by the sector ID.\n",
    "\n",
    "Stocks from the same sector tend to have similar fluctuations. That is because they have similar sensitivities to costs (labor cost, energy) and profits (income distribution, holiday shopping). For example check out `figs/scatter.2.1.pdf` in which regions that are dominated by Finance, Energy or IT have been marked. \n",
    "\n",
    "In this section, you will create similar scatter plots and compare with those given. Your scatter-plots will be slightly different, because of the stocks you have eliminated, but spectral analysis is pretty robust, so your scatter plots should be quite similar (remember that the inverse of an eigen-vector is also an eigen-vector, so horizontal or vertical reflections of the scatter plot are meaningless)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "515237423986cdcf429d5d9c4e967670",
     "grade": false,
     "grade_id": "cell-18bc6c992877e52a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Read data\n",
    "\n",
    "Here, we read `Tickers.pkl` which is a dictionary with the keys: `Tickers` and `TickerInfo`. \n",
    "\n",
    "`Tickers` contains the ticker names and `TickerInfo` is a Pandas dataframe containing Company name, Sector and SectorID for each ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T16:49:08.634672Z",
     "start_time": "2018-06-08T16:49:08.229957Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d0fbd3026da3fcf8712b4c061224c139",
     "grade": false,
     "grade_id": "cell-6faceb87663f980b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "TickerInfo=pd.read_csv('data/tickerInfo.tsv',sep='\\t')\n",
    "TickerInfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "272011d01782b4048ebad44eaa97656c",
     "grade": false,
     "grade_id": "cell-ed8e59d621aa1607",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Map tickers to Sector IDs\n",
    "\n",
    "Complete the function `map_sectorID` that takes as input `columns` containing ticker names that you extracted in 1.3 and returns a list `sectors` containing the sector ID for each ticker\n",
    "\n",
    "Input: `columns` - list of ticker names\n",
    "\n",
    "Example Input: ['train/RF_D', 'train/TIF_D', 'train/HAL_D']\n",
    "\n",
    "Output: `sectors` - list of sector IDs, `known` - number of tickers with known category, `unknown` - number of tickers with unknown category\n",
    "\n",
    "Example Output: ['FIN', 'CD', 'EN', 'CD', 'IT'], 200, 100\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. In order to keep track of the number of tickers with known and unknown categories, intialise the counters `known` and `unknown` to 0\n",
    "2. Use `.to_records()` on the Pandas dataframe TickerInfo[['Ticker','SECTOR_ID']] to create a dictionary mapping Ticker name to Sector ID\n",
    "3. For each column name in `columns`, extract the ticker name by removing the `train` or `test` prefix and the `_D` suffix\n",
    "3. For the extracted ticker name, check if the ticker is present in the dictionary created in 1\n",
    "4. If yes, append the corresponding sectorID to `sectors` and increment the `known` counter\n",
    "5. Else, append the ticker name to `sectors` and increment the `unknown` counter\n",
    "6. Return `sectors`, `known` and `unknown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T23:42:30.056488Z",
     "start_time": "2018-06-01T23:42:30.038554Z"
    },
    "deletable": false,
    "nbgrader": {
     "checksum": "2a5e56f712bf098778a333a6d9853426",
     "grade": false,
     "grade_id": "cell-037bc5d39cd877b8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def map_sectorID(columns):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return sectors, known, unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4e551069bca98dee1d245e168be0327e",
     "grade": false,
     "grade_id": "cell-f96fce4c0ad6a71b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sectors, known, unknown = map_sectorID(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "45637ebcbc51e8790a616bf6a29f9d6a",
     "grade": true,
     "grade_id": "cell-139dba3e35c96502",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e9a1248eeb65077210c99a29968b3106",
     "grade": false,
     "grade_id": "cell-24a89cafed3a042e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Generate Scatter plots\n",
    "\n",
    "Complete the function `Scatter_Stocks` to generate a scatter plot of the stocks on the given pair of eigenvectors. The function takes as input the indices of the two eigenvectors and generates a scatter plot of the data projected on the pair of eigenvectors.\n",
    "\n",
    "Input: i0, i1 - Eigenvector indices\n",
    "\n",
    "Example Input: i0=0, i1=2 (eigenvectors 0 and 2 - eigvec[:, 0] and eigvec[:, 2])\n",
    "\n",
    "Steps:\n",
    "1. Using the `plt.subplots` function, set the figure size to (20, 20) in order that the stock ticker names are readable. Store the objects returned by `plt.subplots` in `fig` and `ax`\n",
    "2. Set the X and Y axis limits to the minimum and maximum of the eigenvectors to be plotted on each axis using the `plt.xlim` and `plt.ylim` functions\n",
    "3. Label the axes as follows: Coeff 0, Coeff 1, using `plt.xlabel` and `plt.ylabel`\n",
    "4. for each ticker in `columns` that you generated in `1.3`, call the `ax.annotate` function in `matplotlib` using the `ax` object returned in `1` and annotate each point with the respective sectorID in `sectors`\n",
    "5. The figure in `fig` is then saved according to the command given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T23:53:50.727996Z",
     "start_time": "2018-06-01T23:53:50.706177Z"
    },
    "deletable": false,
    "nbgrader": {
     "checksum": "397269c666543796ef58990b37197041",
     "grade": false,
     "grade_id": "cell-78ed0210f4cccd7a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def Scatter_Stocks(i0=0,i1=1):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    fig.savefig('figs/scatter.'+str(i0)+'.'+str(i1)+'.pdf', format='PDF');\n",
    "    # After exporting, we clear the figure so that the plot does not appear in the notebook.\n",
    "    fig.clear();\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T23:53:54.971376Z",
     "start_time": "2018-06-01T23:53:51.594104Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "146dec7e7aed2b71d62878166720935c",
     "grade": false,
     "grade_id": "cell-a79686a5dabed461",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for i0 in range(4):\n",
    "    for i1 in range(i0):\n",
    "        print(i0,i1)\n",
    "        Scatter_Stocks(i0,i1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42a3bb4ffa56a49f4961653d1043d182",
     "grade": false,
     "grade_id": "cell-9e234f32c49c4912",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Check \n",
    "Check that your `scatter.2.1.pdf` is similar to `scatter.2.1.annotated.pdf`. Note that the orientation of the eigen-vectors can be flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
