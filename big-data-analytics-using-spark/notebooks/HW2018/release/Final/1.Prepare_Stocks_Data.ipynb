{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9122f08258692fdb1432163e13b0c81a",
     "grade": false,
     "grade_id": "cell-2ba3b7910255ec68",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size = 6><b>CSE 255 Take Home Final: Analysis of stock prices</b></font>\n",
    "\n",
    "\n",
    "In this take-home final you are to analyze the daily changes in stock prices using PCA and to measure the intrinsic dimension of stock sequences. Later you will also use xgboost to predict stock category from the eigenvectors of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eed0c4b262b8cb8ca535dfe326d4038f",
     "grade": false,
     "grade_id": "cell-1a3df2de8f81dda3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notebook 1: Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:45:56.622101Z",
     "start_time": "2018-06-09T03:45:56.236125Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "nbgrader": {
     "checksum": "b97cc17e4483d7e2ad4c42c9f639896e",
     "grade": false,
     "grade_id": "cell-d594c85f4ed89728",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "!pwd  \n",
    "\n",
    "## should be /home/jovyan/work/Final if you're using docker. If you're not using docker,\n",
    "## you should still work inside the `Final` folder before proceeding forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:45:57.157668Z",
     "start_time": "2018-06-09T03:45:56.627444Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b9abb3ae11ef5b4fd9b7085d986e5a0",
     "grade": false,
     "grade_id": "cell-1c454425eff3792a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "## importing some useful python libraries\n",
    "\n",
    "import sys,os\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4a27fcc1ea1c33d31ae7026d0f5d4a9f",
     "grade": false,
     "grade_id": "cell-18e2b62ca91581fe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Download Data\n",
    "\n",
    "We start by downloading data and pre-processing it to make it ready for analysis using Spark.\n",
    "\n",
    "The data is a directory with .csv files, one for each stock. This directory has been tarred and uploaded to S3, at: https://mas-dse-open.s3.amazonaws.com/Stocks/spdata_csv.tgz\n",
    "\n",
    "Download and untar the file to create a subdirectory of the current directory called `spdata_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:45:57.541114Z",
     "start_time": "2018-06-09T03:45:57.161075Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d6f6440957eb656ec8c5df778ad959ef",
     "grade": false,
     "grade_id": "cell-a1e83a7e33b505f3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "!pwd  \n",
    "\n",
    "## should be /home/jovyan/work/Final if you're using docker. If you're not using docker,\n",
    "## you should still work inside the `Final` folder before proceeding forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:46:30.078526Z",
     "start_time": "2018-06-09T03:45:57.547795Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b5f10eac21d966f17a7b9572185ca3d1",
     "grade": false,
     "grade_id": "cell-2e14eb285366f319",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## creating the necessary directory structure and downloading/extracting data \n",
    "\n",
    "%mkdir -p data/\n",
    "%cd data\n",
    "!rm -f spdata_csv.tgz && rm -rf spdata_csv ## Deleting any old copy present\n",
    "!wget https://mas-dse-open.s3.amazonaws.com/Stocks/spdata_csv.tgz ## Downloading data\n",
    "!tar -xf spdata_csv.tgz ## Extracting data\n",
    "## Going back to `Final` directory to keep it as our working directory\n",
    "%cd ../ \n",
    "%ls -al data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:46:30.140055Z",
     "start_time": "2018-06-09T03:46:30.084044Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "97818a5819904518bd9ddd8b48e53749",
     "grade": false,
     "grade_id": "cell-3305f0ecf890052d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## How is the data structured?\n",
    "\n",
    "files=!ls -1 data/spdata_csv/train/\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:46:31.261847Z",
     "start_time": "2018-06-09T03:46:30.143112Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "10ac78212bf4a78f45e5cb2f1f8d07fd",
     "grade": false,
     "grade_id": "cell-eb472367242c6c57",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## How many train and test stocks?\n",
    "\n",
    "!ls -l data/spdata_csv/train/ | wc\n",
    "!ls -l data/spdata_csv/test/ | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "270ade05fff28e53e38ea5b5017d0c8b",
     "grade": false,
     "grade_id": "cell-492d2fbf0848a3e3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Read Data and create a single table\n",
    "\n",
    "Your task in this notebook is to read the stock-information `.csv` files, extract from them the column \n",
    "`Adj. Open` and combine them into a single `.csv` file containing all of the information that is relevant for later analysis.\n",
    "\n",
    "Below we suggest a particular sequence of steps, you can either follow these steps, or do this in your own way.  The end result should be a file called `SP500.csv` which stores the information described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "74d5dd49f0b5855637b517b31f6c2256",
     "grade": false,
     "grade_id": "cell-4ae65d5a84ffc092",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Step 1: files into pandas dataframes\n",
    "\n",
    "In this step we read all of the relevant information into a large dictionary we call `Tables`.\n",
    "\n",
    "The key to this dictionary is the stocks \"ticker\" which corresponds to the file name excluding the `.csv` extension. Hence, we read in all of the files in the directory `spdata_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:46:31.290876Z",
     "start_time": "2018-06-09T03:46:31.267234Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0cc0b87e260a4dcbf33815a62be417ac",
     "grade": false,
     "grade_id": "cell-19cb813c84d0d8b8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cur_dir = !pwd\n",
    "print(\"The current working directory: \", cur_dir)\n",
    "data_dir_rel_path = 'data/spdata_csv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:46:44.609070Z",
     "start_time": "2018-06-09T03:46:31.296088Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e5aed402fca94e2dfd1652fc112e6ce4",
     "grade": false,
     "grade_id": "cell-4d1c95761932f79d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%cd $data_dir_rel_path\n",
    "Tables={}\n",
    "for filename in glob('*/*.csv'):\n",
    "    print('\\r',filename, end=' ')\n",
    "    head, tail = os.path.split(filename)\n",
    "    #stock_name = tail[:-4]\n",
    "    code = filename[:-4]\n",
    "    tbl=pd.read_csv(filename,index_col='Date',parse_dates=True)\n",
    "    if(np.shape(tbl)[1]==12):\n",
    "        Tables[code]=tbl.sort_index()\n",
    "        Tables[code]\n",
    "    else:\n",
    "        print(\"This file does not have the correct number of columns.\")\n",
    "        print(filename,np.shape(tbl))\n",
    "        \n",
    "%cd ../../\n",
    "print(\"The current working directory: \", cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:46:44.655923Z",
     "start_time": "2018-06-09T03:46:44.611542Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ab3cf8a8a7c960e2f70d9689179d2d59",
     "grade": false,
     "grade_id": "cell-01a761988a187278",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Example of an entry in `Tables`\n",
    "print(len(Tables))\n",
    "Tables['train/IBM'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f402d39d18a8387dd9dd3461e4f32ff",
     "grade": false,
     "grade_id": "cell-b36b12c1afaf0cba",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Step 2: Computing diffs and combining into a single table\n",
    "\n",
    "The next step is to extract the relevant prices from each table, compute an additional quantity we call `diff` and create a single combined pandas dataframe called `Diffs` containing info about all stocks.\n",
    "\n",
    "The price we will use is the **Adjusted Open Price** which is the price when the stock exchange opens in the morning. We use the **adjusted** price which eliminates technical adjustments such as stock splits.\n",
    "\n",
    "It is more meaningful to predict *changes* in prices than prices themselves. We therefore compute, for each stock, a `Diffs` sequence in which $d(t)=\\log \\frac{p(t+1)}{p(t)}$ where $p(t)$ is the price at day $t$ and $d(t)$ is the price diff or the price ratio.\n",
    "\n",
    "Obviously, if we have a price sequence of length $T$ then the length of the diff sequence will be $T-1$. To make the price sequence and the diff sequence have the same length we eliminate the last day price for each sequence after we've calculated the `diff` for that stock.\n",
    "\n",
    "Your task in this step is to compute the diff sequence for each stock, and `join` them by date,  and create one large Pandas DataFrame called `Diffs` where the row index is the date, and there are two columns for each ticker. For example for the ticker `IBM`, there would be two columns `IBM_P` and `IBM_D`. The first corresponds to the prices of the IBM stock $p(t)$ and the second to the price difference $d(t)$. In total, the resultant Pandas dataframe should have 962 columns (i.e. 481*2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:46:44.692683Z",
     "start_time": "2018-06-09T03:46:44.660503Z"
    },
    "deletable": false,
    "nbgrader": {
     "checksum": "445af0c837b8bb2f81c422d384109d50",
     "grade": false,
     "grade_id": "cell-7ee8b589fb5ece20",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def construct_df_with_diffs_and_prices(Tables):\n",
    "    ## This is the df you will use to store the required info.\n",
    "    ## You may keep `joining` calculated data for each stock in this DF.\n",
    "    Diffs=pd.DataFrame()\n",
    "    \n",
    "    Indices=set(Tables.keys())\n",
    "    print(len(Indices))\n",
    "    \n",
    "    for code in Indices:\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    return Diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:15.785457Z",
     "start_time": "2018-06-09T03:46:44.696322Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0f67da49ce1a465a280e242503658c59",
     "grade": false,
     "grade_id": "cell-fb782514f0a15f37",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Diffs = construct_df_with_diffs_and_prices(Tables)\n",
    "Diffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:15.798507Z",
     "start_time": "2018-06-09T03:47:15.789335Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da6695d152631ae1c19eba7a00256b66",
     "grade": false,
     "grade_id": "cell-9aefe0ac3ef7109a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert True if 'train/IBM_P' in Diffs else False, \"Please check your implementation.\"\n",
    "assert True if 'train/IBM_D' in Diffs else False, \"Please check your implementation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:15.806849Z",
     "start_time": "2018-06-09T03:47:15.801497Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fdc1866d43d4994a7325823d3da0244b",
     "grade": false,
     "grade_id": "cell-87b452c96dfc296c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(Diffs['train/IBM_P'])==len(Diffs['train/IBM_D'])==Diffs.shape[0], \"The number of rows across stocks should remain fixed.\"\n",
    "assert len(Diffs.columns) == 962, \"The number of columns are not correct. Please check your implementation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:15.818867Z",
     "start_time": "2018-06-09T03:47:15.810750Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "707038187df5fb4a2cda151230e6b9a6",
     "grade": false,
     "grade_id": "cell-a492b5622d2f9ac9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(Diffs['train/IBM_P']) == pd.Series, \"Every column should be a pandas series\"\n",
    "assert type(Diffs['train/IBM_P'][0]) == np.float64, \"Every data point in a series should be np.float64\"\n",
    "assert type(Diffs['train/IBM_D']) == pd.Series, \"Every column should be a pandas series\"\n",
    "assert type(Diffs['train/IBM_D'][0]) == np.float64, \"Every data point in a series should be np.float64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:15.827291Z",
     "start_time": "2018-06-09T03:47:15.822325Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b6a4ce6d447e8d6136f5c294ce837bce",
     "grade": true,
     "grade_id": "cell-bb37a020bb3a04f0",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:15.846947Z",
     "start_time": "2018-06-09T03:47:15.831391Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9c9e08497266f209b27ab34e1f9e8e52",
     "grade": true,
     "grade_id": "cell-9719ba8a4713d723",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:15.858907Z",
     "start_time": "2018-06-09T03:47:15.850791Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b81f99fe83c5a4cb46826510ef036b91",
     "grade": true,
     "grade_id": "cell-c73722a38ba5ae22",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:16.552440Z",
     "start_time": "2018-06-09T03:47:15.862846Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8ac39708ddbc25eca9646d7a3dcf112c",
     "grade": false,
     "grade_id": "cell-b546f7d80f303a69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plot some stocks\n",
    "\n",
    "Diffs[['train/AAPL_P','train/MSFT_P','train/IBM_P','test/8_P']].plot(figsize=(14,10));\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a93e0af15c9f7a6ba9da9eee07bbc51c",
     "grade": false,
     "grade_id": "cell-7ec0552d6b9fb907",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Black Monday\n",
    "\n",
    "One of the biggest crashes in the US stock market happened on\n",
    "**Black Monday:** Oct 19 1987  \n",
    "\n",
    "We will look at the stocks around that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:16.957262Z",
     "start_time": "2018-06-09T03:47:16.555925Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e611f3499865fd4650dbb8f90c8d00b7",
     "grade": false,
     "grade_id": "cell-aff26d651c9b4154",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Focus on \"Black Monday:\" the stock crash of Oct 19 1987\n",
    "\n",
    "import datetime\n",
    "format = \"%b-%d-%Y\"\n",
    "\n",
    "_from = datetime.datetime.strptime('Sep-1-1987', format)\n",
    "_to = datetime.datetime.strptime('Nov-30-1987', format)\n",
    "\n",
    "Diffs.loc[_from:_to,['train/AAPL_P','train/MSFT_P','train/IBM_P']].plot(figsize=(14,10));\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "16c4f1aa027744035abdd5117b756d93",
     "grade": false,
     "grade_id": "cell-493f011fa6223a6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Why does it seems that the price of IBM fell much more than those of Apple and microsoft?**\n",
    "\n",
    "Because IBM's price started so much higher. As explained above it is more informative to consider $\\log(p_{t+1}/p_t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:17.462881Z",
     "start_time": "2018-06-09T03:47:16.960545Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9e94d1e5249c0213eb216522b41c14e4",
     "grade": false,
     "grade_id": "cell-23bc5fa5c83356b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Diffs.loc[_from:_to,['train/AAPL_D','train/MSFT_D','train/IBM_D']].plot(figsize=(14,10));\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6497b7930cd811fa61322dd812fdd1e4",
     "grade": false,
     "grade_id": "cell-9a6ee5fdf4574a4e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Extract column names in lexicographical order\n",
    "\n",
    "Complete the following function to extract the column names from a Pandas dataframe lexicographically, treating train and test tickers separately. The train tickers should be present before the test tickers in the returned list. Consider the Input and example output below.\n",
    "\n",
    "Input: `Diffs` dataframe calculated in 2.2\n",
    "\n",
    "Returns: `dataset/ticker_category` - list of tickers\n",
    "\n",
    "Example Output:\n",
    "\n",
    "   ```\n",
    "  [\n",
    "  'train/AAPL_D',\n",
    "  'train/AAPL_P',\n",
    "  'train/ABC_D',\n",
    "  'train/ABC_P',\n",
    "  'train/ABT_D',\n",
    "  .\n",
    "  .\n",
    "  .\n",
    "  'train/YUM_P',\n",
    "  'train/ZION_D',\n",
    "  'train/ZION_P',\n",
    "  'test/0_D', \n",
    "  'test/0_P', \n",
    "  'test/10_D'\n",
    "  .\n",
    "  .\n",
    "  .\n",
    "  'test/8_P', \n",
    "  'test/9_D', \n",
    "  'test/9_P'\n",
    "  ]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:17.493802Z",
     "start_time": "2018-06-09T03:47:17.466693Z"
    },
    "deletable": false,
    "nbgrader": {
     "checksum": "c2154673319ceacb05c0112ab8cedbed",
     "grade": false,
     "grade_id": "cell-d640d561c1e302c0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def partition_columns(df):\n",
    "    \"\"\"Partition columns of df into train set and test set\n",
    "    Each of them sorted lexicographically.\"\"\"\n",
    "    \n",
    "    train_col=[]\n",
    "    test_col=[]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return  train_col+test_col\n",
    "\n",
    "columns = partition_columns(Diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:17.507313Z",
     "start_time": "2018-06-09T03:47:17.497606Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a41c9ba0443edbab7c9e722d17d386f2",
     "grade": false,
     "grade_id": "cell-3e64b5723b62dc4f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Are they sorted as expected?\n",
    "columns[:5],columns[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:17.525267Z",
     "start_time": "2018-06-09T03:47:17.510424Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b81dd8a29c4467f857cd563388632b6",
     "grade": false,
     "grade_id": "cell-faf79e34a5b02a0f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(columns) == list, 'Incorrect return type'\n",
    "assert len(columns) == 962, 'Incorrect return value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:17.540999Z",
     "start_time": "2018-06-09T03:47:17.531435Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0914ed94af0ac3bf41b4417045790512",
     "grade": true,
     "grade_id": "cell-a27860fc1960972f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Hidden tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:17.616531Z",
     "start_time": "2018-06-09T03:47:17.547394Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "530358a911b4814f42bf5b8d4847ab5f",
     "grade": false,
     "grade_id": "cell-a7c97f9b8af78516",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Diffs=Diffs[columns]\n",
    "\n",
    "## Are the columns of the Diffs dataframe sorted now?\n",
    "Diffs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:18.079355Z",
     "start_time": "2018-06-09T03:47:17.620725Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "608a0dcd3bf592c8109edee341dd9722",
     "grade": false,
     "grade_id": "cell-cf16e02180e2c087",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "!pwd  \n",
    "\n",
    "## should be /home/jovyan/work/Final if you're using docker. If you're not using docker,\n",
    "## you should still work inside the `Final` folder before proceeding forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:34.549956Z",
     "start_time": "2018-06-09T03:47:18.086805Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a5a021dcdb366ae07ee73939049337ec",
     "grade": false,
     "grade_id": "cell-95add1f544bd3891",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## Saving the data to appropriate location for use in next notebooks\n",
    "!rm -rf data/SP500.csv\n",
    "Diffs.to_csv('data/SP500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "10d48ab02bd2e6e6758e032ab94551af",
     "grade": false,
     "grade_id": "cell-dcd19166fa834160",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Note\n",
    "\n",
    "In order to make sure errors in constructing data do not get propagated in other notebooks of the final, you may run the below cell which will download the instructors version of \"SP500.csv\". For next notebooks, you may use either your own version or the one provided by us. Ideally both should have the same contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:52.929780Z",
     "start_time": "2018-06-09T03:47:34.552045Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "14950090906fe856142fdf2b4f6d5b27",
     "grade": false,
     "grade_id": "cell-17b813d7ab8550d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%mkdir -p data/\n",
    "%cd data\n",
    "!rm -f data.tgz && rm -rf data ## Instructor's version of the output from this notebook\n",
    "!wget https://mas-dse-open.s3.amazonaws.com/Stocks/data.tgz\n",
    "!tar -xf data.tgz ## Extracting data\n",
    "%cd ../ \n",
    "## Going back to `Final` directory to keep it as our working directory\n",
    "%ls -al data/\n",
    "\n",
    "## Now the `data` folder should have another `data` folder which contains the instructors version of SP500.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T03:47:54.693365Z",
     "start_time": "2018-06-09T03:47:52.936004Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0e653b667e485ec767c11505999f2d2c",
     "grade": false,
     "grade_id": "cell-4795081e20fe59df",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## How different is your version than the instructors?\n",
    "!diff data/SP500.csv data/data/SP500.csv"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "135px",
    "width": "253px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
