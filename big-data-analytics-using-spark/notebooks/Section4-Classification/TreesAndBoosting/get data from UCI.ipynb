{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higgs data set\n",
    "* **URL:** http://archive.ics.uci.edu/ml/datasets/HIGGS#  \n",
    "* **Abstract:** This is a classification problem to distinguish between a signal process which produces Higgs bosons and a background process which does not.\n",
    "\n",
    "**Data Set Information:**  \n",
    "The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks are presented in the original paper. The last 500,000 examples are used as a test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 ['lepton pT', 'lepton eta', 'lepton phi', 'missing energy magnitude', 'missing energy phi', 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', 'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', 'jet 3 phi', 'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']\n"
     ]
    }
   ],
   "source": [
    "feature_text='lepton pT, lepton eta, lepton phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb'\n",
    "features=[a.strip() for a in feature_text.split(',')]\n",
    "print(len(features),features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/BigData_spring2016/Data\n"
     ]
    }
   ],
   "source": [
    "%cd ~/BigData/Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: HIGGS: File exists\n",
      "/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/BigData_spring2016/Data/HIGGS\n"
     ]
    }
   ],
   "source": [
    "!mkdir HIGGS\n",
    "%cd HIGGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      " 47 2685M   47 1262M    0     0  9796k      0  0:04:40  0:02:12  0:02:28  9.9M^C\n"
     ]
    }
   ],
   "source": [
    "!curl -O http://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gunzip HIGGS.csv.gz ## Takes 5-10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000000000000000e+00,8.692932128906250000e-01,-6.350818276405334473e-01,2.256902605295181274e-01,3.274700641632080078e-01,-6.899932026863098145e-01,7.542022466659545898e-01,-2.485731393098831177e-01,-1.092063903808593750e+00,0.000000000000000000e+00,1.374992132186889648e+00,-6.536741852760314941e-01,9.303491115570068359e-01,1.107436060905456543e+00,1.138904333114624023e+00,-1.578198313713073730e+00,-1.046985387802124023e+00,0.000000000000000000e+00,6.579295396804809570e-01,-1.045456994324922562e-02,-4.576716944575309753e-02,3.101961374282836914e+00,1.353760004043579102e+00,9.795631170272827148e-01,9.780761599540710449e-01,9.200048446655273438e-01,7.216574549674987793e-01,9.887509346008300781e-01,8.766783475875854492e-01\r\n",
      "1.000000000000000000e+00,9.075421094894409180e-01,3.291472792625427246e-01,3.594118654727935791e-01,1.497969865798950195e+00,-3.130095303058624268e-01,1.095530629158020020e+00,-5.575249195098876953e-01,-1.588229775428771973e+00,2.173076152801513672e+00,8.125811815261840820e-01,-2.136419266462326050e-01,1.271014571189880371e+00,2.214872121810913086e+00,4.999939501285552979e-01,-1.261431813240051270e+00,7.321561574935913086e-01,0.000000000000000000e+00,3.987008929252624512e-01,-1.138930082321166992e+00,-8.191101951524615288e-04,0.000000000000000000e+00,3.022198975086212158e-01,8.330481648445129395e-01,9.856996536254882812e-01,9.780983924865722656e-01,7.797321677207946777e-01,9.923557639122009277e-01,7.983425855636596680e-01\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/BigData_spring2016/Data/HIGGS'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!head -2 HIGGS.csv\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=sc.textFile(u'/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/BigData_spring2016/Data/HIGGS/HIGGS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1.000000000000000000e+00,8.692932128906250000e-01,-6.350818276405334473e-01,2.256902605295181274e-01,3.274700641632080078e-01,-6.899932026863098145e-01,7.542022466659545898e-01,-2.485731393098831177e-01,-1.092063903808593750e+00,0.000000000000000000e+00,1.374992132186889648e+00,-6.536741852760314941e-01,9.303491115570068359e-01,1.107436060905456543e+00,1.138904333114624023e+00,-1.578198313713073730e+00,-1.046985387802124023e+00,0.000000000000000000e+00,6.579295396804809570e-01,-1.045456994324922562e-02,-4.576716944575309753e-02,3.101961374282836914e+00,1.353760004043579102e+00,9.795631170272827148e-01,9.780761599540710449e-01,9.200048446655273438e-01,7.216574549674987793e-01,9.887509346008300781e-01,8.766783475875854492e-01'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [0.869293212891,-0.635081827641,0.22569026053,0.327470064163,-0.689993202686,0.754202246666,-0.24857313931,-1.09206390381,0.0,1.37499213219,-0.653674185276,0.930349111557,1.10743606091,1.13890433311,-1.57819831371,-1.0469853878,0.0,0.65792953968,-0.0104545699432,-0.0457671694458,3.10196137428,1.35376000404,0.979563117027,0.978076159954,0.920004844666,0.721657454967,0.988750934601,0.876678347588]),\n",
       " LabeledPoint(1.0, [0.907542109489,0.329147279263,0.359411865473,1.4979698658,-0.313009530306,1.09553062916,-0.55752491951,-1.58822977543,2.1730761528,0.812581181526,-0.213641926646,1.27101457119,2.21487212181,0.499993950129,-1.26143181324,0.732156157494,0.0,0.398700892925,-1.13893008232,-0.000819110195152,0.0,0.302219897509,0.833048164845,0.985699653625,0.978098392487,0.779732167721,0.992355763912,0.798342585564])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LineToLabeledPoint(line):\n",
    "    V = [float(x) for x in line.split(',')]\n",
    "    return LabeledPoint(V[0],V[1:])\n",
    "Data=F.map(LineToLabeledPoint)\n",
    "Data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.util import MLUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingData,testData)=Data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=GradientBoostedTrees.trainClassifier(trainingData,categoricalFeaturesInfo={},numIterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 25 <= 1.0861190557479858)\n",
      "     If (feature 25 <= 0.6328302025794983)\n",
      "      If (feature 27 <= 0.8756244778633118)\n",
      "       Predict: -0.011497738904384089\n",
      "      Else (feature 27 > 0.8756244778633118)\n",
      "       Predict: -0.3049196965656206\n",
      "     Else (feature 25 > 0.6328302025794983)\n",
      "      If (feature 26 <= 0.797487199306488)\n",
      "       Predict: -0.03303820050523515\n",
      "      Else (feature 26 > 0.797487199306488)\n",
      "       Predict: 0.40157295930122033\n",
      "    Else (feature 25 > 1.0861190557479858)\n",
      "     If (feature 22 <= 1.0201389789581299)\n",
      "      If (feature 27 <= 1.0021007061004639)\n",
      "       Predict: -0.2633900638217995\n",
      "      Else (feature 27 > 1.0021007061004639)\n",
      "       Predict: -0.6008335670180185\n",
      "     Else (feature 22 > 1.0201389789581299)\n",
      "      If (feature 25 <= 1.7949312925338745)\n",
      "       Predict: 0.015490085191346656\n",
      "      Else (feature 25 > 1.7949312925338745)\n",
      "       Predict: -0.3979820824348253\n",
      "  Tree 1:\n",
      "    If (feature 27 <= 0.9245960116386414)\n",
      "     If (feature 5 <= 0.887124240398407)\n",
      "      If (feature 26 <= 0.85798579454422)\n",
      "       Predict: -0.27212430914017194\n",
      "      Else (feature 26 > 0.85798579454422)\n",
      "       Predict: 0.20927589496155677\n",
      "     Else (feature 5 > 0.887124240398407)\n",
      "      If (feature 5 <= 1.5715218782424927)\n",
      "       Predict: 0.48197333424386385\n",
      "      Else (feature 5 > 1.5715218782424927)\n",
      "       Predict: 1.1234733103654786\n",
      "    Else (feature 27 > 0.9245960116386414)\n",
      "     If (feature 24 <= 1.0455105304718018)\n",
      "      If (feature 22 <= 1.0621060132980347)\n",
      "       Predict: -0.8859639921374752\n",
      "      Else (feature 22 > 1.0621060132980347)\n",
      "       Predict: -0.10293785462824766\n",
      "     Else (feature 24 > 1.0455105304718018)\n",
      "      If (feature 3 <= 2.2600183486938477)\n",
      "       Predict: 0.0838662144404539\n",
      "      Else (feature 3 > 2.2600183486938477)\n",
      "       Predict: -0.6953710651397899\n",
      "  Tree 2:\n",
      "    If (feature 27 <= 0.9078413844108582)\n",
      "     If (feature 5 <= 0.8382060527801514)\n",
      "      If (feature 26 <= 0.8696780204772949)\n",
      "       Predict: -0.23333067954885722\n",
      "      Else (feature 26 > 0.8696780204772949)\n",
      "       Predict: 0.20742588448962404\n",
      "     Else (feature 5 > 0.8382060527801514)\n",
      "      If (feature 5 <= 1.127135157585144)\n",
      "       Predict: 0.30014139804311385\n",
      "      Else (feature 5 > 1.127135157585144)\n",
      "       Predict: 0.673963522565619\n",
      "    Else (feature 27 > 0.9078413844108582)\n",
      "     If (feature 24 <= 1.0321295261383057)\n",
      "      If (feature 22 <= 1.0428392887115479)\n",
      "       Predict: -0.7450844271818685\n",
      "      Else (feature 22 > 1.0428392887115479)\n",
      "       Predict: -0.08649461061379747\n",
      "     Else (feature 24 > 1.0321295261383057)\n",
      "      If (feature 3 <= 1.9833227396011353)\n",
      "       Predict: 0.0899185146315724\n",
      "      Else (feature 3 > 1.9833227396011353)\n",
      "       Predict: -0.4520216643414143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cover Type\n",
    "* **URL:** http://archive.ics.uci.edu/ml/datasets/Covertype\n",
    "* **Abstract:** Forest CoverType dataset\n",
    "* **Data Set Description:** http://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/BigData_spring2016/Data\n",
      "-rw-r--r--   1 yoavfreund  staff        25 Apr 24 11:05 hw2-files.txt\r\n",
      "-rw-r--r--   1 yoavfreund  staff        31 Apr 24 11:05 hw2-files-5gb.txt\r\n",
      "-rw-r--r--   1 yoavfreund  staff        90 Apr 24 11:05 hw2-files-20gb.txt\r\n",
      "-rw-r--r--   1 yoavfreund  staff        13 Apr 24 11:05 hw2-files-1gb.txt\r\n",
      "-rw-r--r--   1 yoavfreund  staff        43 Apr 24 11:05 example.csv\r\n",
      "drwxr-xr-x   3 yoavfreund  staff       102 Apr 24 11:47 regression\r\n",
      "drwxr-xr-x  16 yoavfreund  staff       544 Apr 27 19:41 Weather\r\n",
      "-rw-r--r--   1 yoavfreund  staff  26877621 Apr 30 12:15 STAT_TAVG_RANGE.pickle\r\n",
      "drwxr-xr-x   4 yoavfreund  staff       136 May  9 11:30 HIGGS\r\n",
      "drwxr-xr-x   3 yoavfreund  staff       102 May  9 11:46 covtype\r\n"
     ]
    }
   ],
   "source": [
    "%cd ~/BigData/Data/\n",
    "!ls -lrt | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: covtype: File exists\n",
      "/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/BigData_spring2016/Data/covtype\n",
      "total 146816\n",
      "-rw-r--r--  1 yoavfreund  staff  75169317 May  9 11:46 covtype.data\n"
     ]
    }
   ],
   "source": [
    "!mkdir covtype\n",
    "%cd covtype\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10.7M  100 10.7M    0     0  3844k      0  0:00:02  0:00:02 --:--:-- 3843k\n"
     ]
    }
   ],
   "source": [
    "!curl -O http://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gunzip: can't stat: covtype.data.gz (covtype.data.gz.gz): No such file or directory\n",
      "total 146816\n",
      "-rw-r--r--  1 yoavfreund  staff  75169317 May  9 11:46 covtype.data\n"
     ]
    }
   ],
   "source": [
    "!gunzip -f covtype.data.gz\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_txt=\"\"\"\n",
    "Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n",
    "Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n",
    "Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n",
    "Horizontal_Distance_To_Fire_Points, Wilderness_Area (4 binarycolumns), \n",
    "Soil_Type (40 binary columns), Cover_Type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'WA_0', 'WA_1', 'WA_2', 'WA_3', 'ST_0', 'ST_1', 'ST_2', 'ST_3', 'ST_4', 'ST_5', 'ST_6', 'ST_7', 'ST_8', 'ST_9', 'ST_10', 'ST_11', 'ST_12', 'ST_13', 'ST_14', 'ST_15', 'ST_16', 'ST_17', 'ST_18', 'ST_19', 'ST_20', 'ST_21', 'ST_22', 'ST_23', 'ST_24', 'ST_25', 'ST_26', 'ST_27', 'ST_28', 'ST_29', 'ST_30', 'ST_31', 'ST_32', 'ST_33', 'ST_34', 'ST_35', 'ST_36', 'ST_37', 'ST_38', 'ST_39', 'Cover_Type']\n"
     ]
    }
   ],
   "source": [
    "cols=[a.strip() for a in cols_txt.split(',')]\n",
    "colDict={a:[a] for a in cols}\n",
    "colDict['Soil_Type (40 binary columns)'] = ['ST_'+str(i) for i in range(40)]\n",
    "colDict['Wilderness_Area (4 binarycolumns)'] = ['WA_'+str(i) for i in range(4)]\n",
    "Columns=[]\n",
    "for item in cols:\n",
    "    Columns=Columns+colDict[item]\n",
    "print(Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2384,170,15,60,5,90,230,245,143,864,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3\r\n",
      "2383,165,13,60,4,67,231,244,141,875,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3\r\n"
     ]
    }
   ],
   "source": [
    "!tail -2 covtype.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>ST_31</th>\n",
       "      <th>ST_32</th>\n",
       "      <th>ST_33</th>\n",
       "      <th>ST_34</th>\n",
       "      <th>ST_35</th>\n",
       "      <th>ST_36</th>\n",
       "      <th>ST_37</th>\n",
       "      <th>ST_38</th>\n",
       "      <th>ST_39</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points     ...      ST_31  ST_32  ST_33  ST_34  \\\n",
       "0                                6279     ...          0      0      0      0   \n",
       "\n",
       "   ST_35  ST_36  ST_37  ST_38  ST_39  Cover_Type  \n",
       "0      0      0      0      0      0           5  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(open('covtype.data','r'),names=Columns,header=None)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['split']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "df.hist(bins=50,figsize=(16,16));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6a4642092433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/BigData_spring2016/Data/covtype'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[9] at textFile at NativeMethodAccessorImpl.java:-2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/Users/yoavfreund/academic.papers/Courses/BigDataAnalytics/BigData_spring2016/Data/covtype/covtype.data'\n",
    "inputRDD=sc.textFile(path)\n",
    "inputRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2596,51,3,258,0,510,221,232,148,6279,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(5.0, [2596.0,51.0,3.0,258.0,0.0,510.0,221.0,232.0,148.0,6279.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data=inputRDD.map(lambda line: [float(x) for x in line.split(',')])\\\n",
    "    .map(lambda V:LabeledPoint(V[-1],V[:-1]))\n",
    "Data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData,testData)=Data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Decision trees\n",
    "Documentation: http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#module-pyspark.mllib.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=GradientBoostedTrees.trainClassifier(trainingData,categoricalFeaturesInfo={},numIterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 0 <= 2558.0)\n",
      "     If (feature 10 <= 0.0)\n",
      "      If (feature 0 <= 2471.0)\n",
      "       Predict: 6.770351720454719\n",
      "      Else (feature 0 > 2471.0)\n",
      "       Predict: 5.740438796307397\n",
      "     Else (feature 10 > 0.0)\n",
      "      If (feature 9 <= 4578.0)\n",
      "       Predict: 2.9670912951167727\n",
      "      Else (feature 9 > 4578.0)\n",
      "       Predict: 4.136960600375234\n",
      "    Else (feature 0 > 2558.0)\n",
      "     If (feature 0 <= 3317.0)\n",
      "      If (feature 0 <= 2918.0)\n",
      "       Predict: 3.3723028053456883\n",
      "      Else (feature 0 > 2918.0)\n",
      "       Predict: 2.1607261897547336\n",
      "     Else (feature 0 > 3317.0)\n",
      "      If (feature 12 <= 0.0)\n",
      "       Predict: 4.217128874388255\n",
      "      Else (feature 12 > 0.0)\n",
      "       Predict: 7.578162967762839\n",
      "  Tree 1:\n",
      "    If (feature 0 <= 2960.0)\n",
      "     If (feature 0 <= 2921.0)\n",
      "      If (feature 0 <= 2898.0)\n",
      "       Predict: 4.090717211786396E-4\n",
      "      Else (feature 0 > 2898.0)\n",
      "       Predict: 0.002271467388852949\n",
      "     Else (feature 0 > 2921.0)\n",
      "      If (feature 3 <= 95.0)\n",
      "       Predict: 0.02125309879260513\n",
      "      Else (feature 3 > 95.0)\n",
      "       Predict: 0.009384123879065138\n",
      "    Else (feature 0 > 2960.0)\n",
      "     If (feature 0 <= 3316.0)\n",
      "      If (feature 0 <= 3053.0)\n",
      "       Predict: 0.018729186703171457\n",
      "      Else (feature 0 > 3053.0)\n",
      "       Predict: 0.034168240106118304\n",
      "     Else (feature 0 > 3316.0)\n",
      "      If (feature 12 <= 0.0)\n",
      "       Predict: 9.84858658898125E-4\n",
      "      Else (feature 12 > 0.0)\n",
      "       Predict: 3.1161709753657683E-4\n",
      "  Tree 2:\n",
      "    If (feature 0 <= 2956.0)\n",
      "     If (feature 0 <= 2916.0)\n",
      "      If (feature 0 <= 2690.0)\n",
      "       Predict: 9.324197799200563E-5\n",
      "      Else (feature 0 > 2690.0)\n",
      "       Predict: 6.888565833247716E-4\n",
      "     Else (feature 0 > 2916.0)\n",
      "      If (feature 3 <= 95.0)\n",
      "       Predict: 0.020258935239689857\n",
      "      Else (feature 3 > 95.0)\n",
      "       Predict: 0.008811674779791903\n",
      "    Else (feature 0 > 2956.0)\n",
      "     If (feature 0 <= 3320.0)\n",
      "      If (feature 0 <= 3056.0)\n",
      "       Predict: 0.0186628607868871\n",
      "      Else (feature 0 > 3056.0)\n",
      "       Predict: 0.03384474044105752\n",
      "     Else (feature 0 > 3320.0)\n",
      "      If (feature 12 <= 0.0)\n",
      "       Predict: 5.869555973526549E-4\n",
      "      Else (feature 12 > 0.0)\n",
      "       Predict: 4.363176342013421E-7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
