{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"18px\" ><strong> helper </strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all the helper functions and data necessary to run the other notebooks for this week. All the functions are stored within the object <font color=\"purple\">helper</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper = type('helper', (), {})()\n",
    "helper.bi  = type('bi', (), {})()\n",
    "helper.hw  = type('hw', (), {})()\n",
    "helper.uni = type('uni', (), {})()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The object 'helper' has been imported into this notebook.\n"
     ]
    }
   ],
   "source": [
    "print \"The object 'helper' has been imported into this notebook.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now load \"wine.data.txt\" data set.\n",
    "# This needs to be in the same directory\n",
    "# 178 lines, each with one point. First value is the label (1,2,3), remaining 13 numbers are features\n",
    "helper.data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "helper.featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "helper.perm = np.array([  4,  93, 103, 152,  77,  81,  14,  58, 139,  53,  40, 167,  20,\n",
    "        80, 130,  16, 110, 158,  42, 135,   8,  69, 153,  94,  91,  51,\n",
    "       117, 146,  72, 142, 137,  88, 165, 106,  33,  67, 133, 113, 171,\n",
    "       129, 141,  21,  12,  44,   3, 164, 169,  41,   6, 177,  17, 174,\n",
    "       104, 176, 168,  26, 173, 122, 159, 111, 163,  50,  15,  37, 114,\n",
    "         2, 109,  68,  39,  96,  36, 149, 151, 124, 156, 108, 107,  30,\n",
    "        43,  28,  54,  59, 154,  78,  92, 157, 140,  73,  34,  49, 160,\n",
    "       118, 125, 126, 127, 145, 144,   9,  24,  90,  84,  55,  19, 148,\n",
    "        25,  61, 123,   0,  38,  97,  32,  85,  29,  45, 128,  75,  66,\n",
    "        86,  47, 102, 175,  63,  82,  83, 115, 136,  98,  46,  62, 150,\n",
    "       162, 134, 138,  76,  87, 170, 105,  65,  89,  71, 112,  56,  74,\n",
    "       132, 100,  27,  64, 166,  22, 155,  57, 119,  99,   7,  23,  13,\n",
    "       121, 101, 116, 172,  95, 131,  10,  35,  11,  60, 161,   1,  18,\n",
    "       147, 143,  31,  79,  48,   5, 120,  52,  70])\n",
    "# Split 178 instances into training set (x, y) of size 130 and test set (tx, ty) of size 48\n",
    "# Also split apart data and labels\n",
    "# perm = np.random.permutation(178)\n",
    "helper.x = helper.data[helper.perm[0:130],1:14]\n",
    "helper.y = helper.data[helper.perm[0:130],0]\n",
    "helper.tx = helper.data[helper.perm[130:178], 1:14]\n",
    "helper.ty = helper.data[helper.perm[130:178],0]\n",
    "\n",
    "x,y,tx,ty = helper.x, helper.y, helper.tx, helper.ty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Univariate Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def densityPlot(feature, label):\n",
    "    plt.hist(x[y==label,feature], normed=True)\n",
    "    #\n",
    "    mu = np.mean(x[y==label,feature]) # mean\n",
    "    var = np.var(x[y==label,feature]) # variance\n",
    "    std = np.sqrt(var) # standard deviation\n",
    "    #\n",
    "    x_axis = np.linspace(mu - 3*std, mu + 3*std, 1000)\n",
    "    plt.plot(x_axis, norm.pdf(x_axis,mu,std), 'r', lw=2)\n",
    "    plt.title(\"Winery \"+str(label) )\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Density', fontsize=14, color='red')\n",
    "    plt.show()\n",
    "    \n",
    "helper.uni.densityPlot = densityPlot\n",
    "del densityPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Assumes y takes on values 1,2,3\n",
    "def fit_generative_model(feature):\n",
    "    k = len(np.unique(y)) # number of classes\n",
    "    mu = np.zeros(k+1) # list of means\n",
    "    var = np.zeros(k+1) # list of variances\n",
    "    pi = np.zeros(k+1) # list of class weights\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label] = np.mean(x[indices,feature])\n",
    "        var[label] = np.var(x[indices,feature])\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, var, pi\n",
    "\n",
    "helper.uni.fit_generative_model = fit_generative_model\n",
    "del fit_generative_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gaussians(feature):\n",
    "    mu, var, pi = helper.uni.fit_generative_model(feature)\n",
    "    pi[1], pi[2], pi[3]\n",
    "\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        m = mu[label]\n",
    "        s = np.sqrt(var[label])\n",
    "        x_axis = np.linspace(m - 3*s, m+3*s, 1000)\n",
    "        plt.plot(x_axis, norm.pdf(x_axis,m,s), colors[label-1], label=\"class \" + str(label))\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Density', fontsize=14, color='red')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "helper.uni.gaussians = gaussians\n",
    "del gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_model(feature):\n",
    "    mu, var, pi = helper.uni.fit_generative_model( feature)\n",
    "\n",
    "    k = len(np.unique(y)) # Labels 1,2,...,k\n",
    "    nt = len(ty) # Number of test points\n",
    "    score = np.zeros((nt,k+1))\n",
    "    for i in range(0,nt):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            norm.logpdf(tx[i,feature], mu[label], np.sqrt(var[label]))\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != ty)\n",
    "    print \"Test error using feature \" + featurenames[feature] + \": \" + str(errors) + \"/\" + str(nt)\n",
    "    return errors/float(nt)\n",
    "    \n",
    "helper.uni.test_model = test_model\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bivariate Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit a Gaussian to a data set using the selected features\n",
    "def fit_gaussian(x, features):\n",
    "    mu = np.mean(x[:,features], axis=0)\n",
    "    covar = np.cov(x[:,features], rowvar=0, bias=1)\n",
    "    return mu, covar\n",
    "\n",
    "helper.bi.fit_gaussian = fit_gaussian\n",
    "del fit_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fit_generative_model(x, y, features):\n",
    "    k = len(np.unique(y)) # number of classes in y\n",
    "    d = len(features) # number of features\n",
    "    mu = np.zeros((k+1,d)) # list of means\n",
    "    covar = np.zeros((k+1,d,d)) # list of covariance matrices\n",
    "    pi = np.zeros(k+1) # list of class weights\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label,:], covar[label,:,:] = helper.bi.fit_gaussian(x[indices,:], features)\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, covar, pi\n",
    "\n",
    "helper.bi.fit_generative_model = fit_generative_model\n",
    "del fit_generative_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def twoFeaturesPlot(f1,f2,label):\n",
    "    # Setting up variables\n",
    "    if f1 == f2: #<-- if f1 == f2 then then we would get an error\n",
    "        print \"Please choose different features for f1 and f2.\"\n",
    "        return  \n",
    "    features = [f1, f2]\n",
    "    mu, covar = helper.bi.fit_gaussian(x[y==label,:], features)\n",
    "    \n",
    "    # Plot the training points along the two selected features\n",
    "    plt.plot(x[y==label,f1], x[y==label,f2], 'ro')\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    # For the plot: obtain limits along the x1-axis and x2-axis\n",
    "    x1_lower = min(x[y==label,f1])\n",
    "    x1_upper = max(x[y==label,f1])\n",
    "    x1_width = x1_upper - x1_lower\n",
    "    x1_lower = x1_lower - 0.2 * x1_width\n",
    "    x1_upper = x1_upper + 0.2 * x1_width\n",
    "    x2_lower = min(x[y==label,f2])\n",
    "    x2_upper = max(x[y==label,f2])\n",
    "    x2_width = x2_upper - x2_lower\n",
    "    x2_lower = x2_lower - 0.2 * x2_width\n",
    "    x2_upper = x2_upper + 0.2 * x2_width\n",
    "    plt.xlim(x1_lower, x1_upper)\n",
    "    plt.ylim(x2_lower, x2_upper)\n",
    "    \n",
    "    # Finally, plot a contour of the Gaussian\n",
    "    res = 200 # resolution\n",
    "    xg = np.linspace(x1_lower, x1_upper, res)\n",
    "    yg = np.linspace(x2_lower, x2_upper, res)\n",
    "    z = np.zeros((res,res))\n",
    "    rv = multivariate_normal(mean=mu, cov=covar)\n",
    "    \n",
    "    for i in range(0,res):\n",
    "        for j in range(0,res):\n",
    "            z[j,i] = rv.logpdf([xg[i], yg[j]]) \n",
    "    sign, logdet = np.linalg.slogdet(covar)\n",
    "    normalizer = -0.5 * (2 * np.log(6.28) + sign * logdet)\n",
    "    for offset in range(0,4):\n",
    "        plt.contour(xg,yg,z, levels=[normalizer - offset], colors='k', linewidths=2.0, linestyles='solid')\n",
    "    # Finally, display\n",
    "    plt.show()\n",
    "\n",
    "helper.bi.twoFeaturesPlot = twoFeaturesPlot\n",
    "del twoFeaturesPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_range(x):\n",
    "    lower = min(x)\n",
    "    upper = max(x)\n",
    "    width = upper - lower\n",
    "    lower = lower - 0.2 * width\n",
    "    upper = upper + 0.2 * width\n",
    "    return lower, upper\n",
    "\n",
    "helper.bi.find_range = find_range\n",
    "del find_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def threeGaussiansPlot(f1,f2):\n",
    "    # Setting up variables\n",
    "    if f1 == f2: #<-- if f1 == f2 then then we would get an error\n",
    "        print \"Please choose different features for f1 and f2.\"\n",
    "        return  \n",
    "    features = [f1,f2] \n",
    "    mu, covar, pi = helper.bi.fit_generative_model(x, y, features)\n",
    "    \n",
    "    # Show the Gaussian fit to each class, using features f1,f2\n",
    "    col = ['r', 'k', 'g']\n",
    "    # Find rough ranges along each feature\n",
    "    x1_lower, x1_upper = helper.bi.find_range(x[:,f1])\n",
    "    x2_lower, x2_upper = helper.bi.find_range(x[:,f2])\n",
    "    plt.xlim(x1_lower,x1_upper)\n",
    "    plt.ylim(x2_lower,x2_upper)\n",
    "    # Plot the training points along the two selected features\n",
    "    plt.plot(x[y==1,f1], x[y==1,f2], 'ro')\n",
    "    plt.plot(x[y==2,f1], x[y==2,f2], 'k^')\n",
    "    plt.plot(x[y==3,f1], x[y==3,f2], 'gs')\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    # Now draw a contour line for each label's Gaussian\n",
    "    res = 200\n",
    "    d = float(len(features))\n",
    "    xg = np.linspace(x1_lower,x1_upper,res)\n",
    "    yg = np.linspace(x2_lower,x2_upper,res)\n",
    "    z = np.zeros((res,res))\n",
    "    for label in range(1,4):\n",
    "        gmean = mu[label,:]\n",
    "        gcov = covar[label,:,:]\n",
    "        rv = multivariate_normal(mean=gmean, cov=gcov)\n",
    "        for i in range(0,res):\n",
    "            for j in range(0,res):\n",
    "                 z[j,i] = rv.logpdf([xg[i], yg[j]]) \n",
    "        sign, logdet = np.linalg.slogdet(gcov)\n",
    "        normalizer = -0.5 * (d * np.log(6.28) + sign * logdet)\n",
    "        plt.contour(xg,yg,z,levels=[normalizer - 4.0],colors=col[label-1],linewidths=2.0,linestyles='solid')\n",
    "    # Finally, display\n",
    "    plt.show()\n",
    "    \n",
    "helper.bi.threeGaussiansPlot = threeGaussiansPlot\n",
    "del threeGaussiansPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_model(f1, f2):\n",
    "    # Setting up variables\n",
    "    if f1 == f2: #<-- if f1 == f2 then then we would get an error\n",
    "        print \"Please choose different features for f1 and f2.\"\n",
    "        return  \n",
    "    features= [f1,f2]\n",
    "    mu, covar, pi = helper.bi.fit_generative_model(x, y, features)\n",
    "    \n",
    "    k = len(np.unique(y))  # Labels 1,2,...,k\n",
    "    nt = len(ty) # Number of test points\n",
    "    score = np.zeros((nt,k+1))\n",
    "    for i in range(0,nt):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            multivariate_normal.logpdf(tx[i,features], mean=mu[label,:], cov=covar[label,:,:])\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != ty)\n",
    "    print \"Test error using feature(s): \",\n",
    "    for f in features:\n",
    "        print \"'\" + featurenames[f] + \"'\" + \" \",\n",
    "    print\n",
    "    # Now test the performance of a predictor based on a subset of features\n",
    "    print \"Errors: \" + str(errors) + \"/\" + str(nt)\n",
    "    return errors/float(nt)\n",
    "\n",
    "helper.bi.test_model = test_model\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_boundary(f1,f2):\n",
    "\n",
    "    features = [f1,f2] \n",
    "    mu, covar, pi = helper.bi.fit_generative_model(x, y, features)\n",
    "    x1_lower, x1_upper = helper.bi.find_range(x[:,f1])      #  <--  Finds rough ranges along each feature\n",
    "    x2_lower, x2_upper = helper.bi.find_range(x[:,f2])\n",
    "\n",
    "    # Plot the decision boundary for a classifier based only on the two selected features\n",
    "    delta = 0.005\n",
    "    x1 = np.arange(x1_lower,x1_upper,delta)\n",
    "    x2 = np.arange(x2_lower,x2_upper,delta)\n",
    "    rv1 = multivariate_normal(mean=mu[1,:], cov = covar[1,:,:])\n",
    "    rv2 = multivariate_normal(mean=mu[2,:], cov = covar[2,:,:])\n",
    "    rv3 = multivariate_normal(mean=mu[3,:], cov = covar[3,:,:])\n",
    "    Z1 = np.zeros((len(x1),len(x2)))\n",
    "    Z2 = np.zeros((len(x1),len(x2)))\n",
    "    Z3 = np.zeros((len(x1),len(x2)))\n",
    "    for i in range(0,len(x1)):\n",
    "        for j in range(0,len(x2)):\n",
    "            v1 = np.log(pi[1]) + rv1.logpdf([x1[i],x2[j]])\n",
    "            v2 = np.log(pi[2]) + rv2.logpdf([x1[i],x2[j]])\n",
    "            v3 = np.log(pi[3]) + rv3.logpdf([x1[i],x2[j]])\n",
    "            m = max([v1,v2,v3])\n",
    "            Z1[i,j] = v1 - m\n",
    "            Z2[i,j] = v2 - m\n",
    "            Z3[i,j] = v3 - m\n",
    "    plt.plot(x[y==1,f1], x[y==1,f2], 'ro')\n",
    "    plt.plot(x[y==2,f1], x[y==2,f2], 'k^')\n",
    "    plt.plot(x[y==3,f1], x[y==3,f2], 'gs')\n",
    "    plt.xlabel(featurenames[f1], fontsize=14, color='red')\n",
    "    plt.ylabel(featurenames[f2], fontsize=14, color='red')\n",
    "    plt.contour(x1,x2,Z1.T,[-0.001])\n",
    "    plt.contour(x1,x2,Z2.T,[-0.001])\n",
    "    plt.contour(x1,x2,Z3.T,[-0.001])\n",
    "    plt.xlim([x1_lower,x1_upper])\n",
    "    plt.ylim([x2_lower,x2_upper])\n",
    "    plt.show()\n",
    "    \n",
    "helper.bi.plot_boundary = plot_boundary\n",
    "del plot_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# HW_2 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ites = np.array([129,  40, 126,   4,  23, 147,  65,  93,  79, 117,  77,  27,  68,\n",
    "        24,  50, 115, 144,  37,  85,  86,  14,  49,  54, 105, 135,  83,\n",
    "        44,  99, 112,  61,  57,  64,  84,  36, 111,  69,  87,  80,  91,\n",
    "       118,  47,  39,  26,  29,  51,   8,   7,  92,  97,  33,  70,  12,\n",
    "       100,  53, 106,  71,  48,  25,  60,  20,  62, 143, 119,  32,  18,\n",
    "       109,  52,  31, 116,  74,   2,  96,  94,  42,   6, 137,  88,   5,\n",
    "        66, 131,  95, 133,  13,  58, 114, 130,  90,  11, 120,  45, 128,\n",
    "       124,  73, 122, 125, 108,  43,  35, 148,  55, 145,  76,  75,  67,\n",
    "       103,   1,   0, 107, 136, 113,  21,  98,  17, 102, 123, 104, 101,139,  10,  59 ])\n",
    "\n",
    "tites = np.array([ 138, 141,  30,  81, 140,  28,  56,  41,  89, 134,\n",
    "            16, 142,  63, 132,  72, 149,  15,  34,  46,  38,  78,  22,  19,\n",
    "           121,   3, 127,   9, 146, 110,  82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "helper.hw.y  = iris.target[ites]+1\n",
    "helper.hw.x  = iris.data[ites]\n",
    "helper.hw.ty = iris.target[tites]+1\n",
    "helper.hw.tx = iris.data[tites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "helper.hw.featurenames = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
